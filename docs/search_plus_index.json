{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction https://qgao233.github.io/qgaoMajorKnowledge/ Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section1/":{"url":"chapter1/section1/","title":"1.1 常量与变量","keywords":"","body":"﻿ 常量与变量 String a = “123”; a是变量，“123”是字符串常量。 int b = 123; b是变量，123是整型常量。 final String a = “123”; final将变量a变为了编译期可识别的常量，也就是说如果有其它地方要使用到a,如：String c = a; a将被直接替换为“123”，而此时c是变量。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section2/":{"url":"chapter1/section2/","title":"1.2 成员变量初始化时机","keywords":"","body":"成员变量初始化时机 static 任何时候都可以初始化 final只能 饿汉 语句块 构造方法 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section3/":{"url":"chapter1/section3/","title":"1.3 继承","keywords":"","body":"继承 接口可以多继承。 如果一个接口继承了多个接口，表示这个接口拓展了更多的功能。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section4/":{"url":"chapter1/section4/","title":"1.4 多态","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 类的重构 重写：一大 两小 多态 多态即：父类类型的引用指向子类的对象 该引用只能调用父类中定义的方法和变量； 如果子类中重写了父类中的一个方法，那么在调用这个方法的时候，将会调用子类中的这个方法；（动态连接、动态调用） 变量不能被重写（覆盖），”重写“的概念只针对方法，如果在子类中”重写“了父类中的变量，那么在编译时会报错。 注：在父类与子类的关系中，调用哪个类的方法由引用决定 如果子类继承父类，并重写父类中的方法，但在使用时，并不如多态般使用，而是用父类引用指向父类对象，那么当使用父类引用调用子类重写过的方法时，实际上，此时，子类重写与否，对现在的情况无用，执行时会调用父类中的方法，而不会调用子类中的重写方法。 类的重构 开放-封闭原则，如果在实际生产环境下，当修改功能时需要去修改原来的类时，就违背了此原则， 此时需要根据单一职责原则，考虑抽象出功能类，而具体的功能类则继承抽象类，此时，修改（增加或删除）时只需要删除对应的具体功能类。 当然，正确的抽象类创建应对针对频繁变化的部分，不应盲目抽象。 重写：一大 两小 public Integer hello(int a) throws RuntimeException{} Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section5/":{"url":"chapter1/section5/","title":"1.5 枚举enum","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 语法（定义） 向枚举中添加新方法 实现接口 枚举enum 枚举方式定义的常量使代码更具可读性，允许进行编译时检查，预先记录可接受值的列表，并避免由于传入无效值而引起的意外行为。 == 运算符可提供枚举变量编译时和运行时的安全性：即编译时若为null，则无法通过编译；运行时为null，正常运行，不会报错。 语法（定义） 创建枚举类型要使用 enum 关键字，隐含了所创建的类型都是 java.lang.Enum 类的子类（java.lang.Enum 是一个抽象类）。枚举类型符合通用模式 Class Enum>，而 E 表示枚举类型的名称。枚举类型的每一个值都将映射到protected Enum(String name, int ordinal) 构造函数中，在这里，每个值的名称都被转换成一个字符串，并且序数设置表示了此设置被创建的顺序。 package com.hmw.test; public enum EnumTest { MON, TUE, WED, THU, FRI, SAT, SUN; } 上述代码实际上调用了7次 Enum(String name, int ordinal)： new Enum(\"MON\",0); new Enum(\"TUE\",1); new Enum(\"WED\",2); ... ... 向枚举中添加新方法 如果打算自定义自己的方法，那么必须在enum实例序列的最后添加一个分号。而且 Java 要求必须先定义 enum 实例。 Java代码 public enum Color { RED(\"红色\", 1), GREEN(\"绿色\", 2), BLANK(\"白色\", 3), YELLO(\"黄色\", 4); // 成员变量 private String name; private int index; // 构造方法 private Color(String name, int index) { this.name = name; this.index = index; } // 普通方法 public static String getName(int index) { for (Color c : Color.values()) { if (c.getIndex() == index) { return c.name; } } return null; } // get set 方法 public String getName() { return name; } public void setName(String name) { this.name = name; } public int getIndex() { return index; } public void setIndex(int index) { this.index = index; } } 实现接口 所有的枚举都继承自java.lang.Enum类。由于Java 不支持多继承，所以枚举对象不能再继承其他类。 Java代码 public interface Behaviour { void print(); String getInfo(); } public enum Color implements Behaviour{ RED(\"红色\", 1), GREEN(\"绿色\", 2), BLANK(\"白色\", 3), YELLO(\"黄色\", 4); // 成员变量 private String name; private int index; // 构造方法 private Color(String name, int index) { this.name = name; this.index = index; } //接口方法 @Override public String getInfo() { return this.name; } //接口方法 @Override public void print() { System.out.println(this.index+\":\"+this.name); } } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section6/":{"url":"chapter1/section6/","title":"1.6 接口/抽象类","keywords":"","body":"接口/抽象类 抽象类继承接口时 抽象类和接口都不能直接实例化，如果要实例化，抽象类变量必须指向实现所有抽象方法的子类对象，接口变量必须指向实现所有接口方法的类对象。 抽象类要被子类继承，接口要被类实现。 接口只能做方法申明，抽象类中可以做方法申明，也可以做方法实现 接口里定义的变量只能是公共的静态的常量，抽象类中的变量是普通变量。 抽象类里的抽象方法必须全部被子类所实现，如果子类不能全部实现父类抽象方法，那么该子类只能是抽象类。同样，一个实现接口的时候，如不能全部实现接口方法，那么该类也只能为抽象类。 抽象方法只能申明，不能实现。abstract void abc();不能写成abstract void abc(){}。 抽象类里可以没有抽象方法 如果一个类里有抽象方法，那么这个类只能是抽象类 抽象方法要被实现，所以不能是静态的，也不能是私有的。 接口可继承接口，并可多继承接口，但类只能单根继承。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section7/":{"url":"chapter1/section7/","title":"1.7 内部类","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 普通成员内部类 静态成员内部类 方法内部类 匿名内部类 内部类 普通成员内部类 从上面的代码中我们可以看到，成员内部类的使用方法： Inner 类定义在 Outer 类的内部，相当于 Outer 类的一个成员变量的位置，Inner 类可以使用任意访问控制符，如 public 、 protected 、 private 等; Inner 类中定义的 test() 方法可以直接访问 Outer 类中的数据，而不受访问控制符的影响，如直接访问 Outer 类中的私有属性a; 定义了成员内部类后，必须使用外部类对象来创建内部类对象，而不能直接去 new 一个内部类对象，即：内部类 对象名 = 外部类对象.new 内部类( ); 编译上面的程序后，会发现产生了两个 .class 文件: 其中，第二个是外部类的 .class 文件，第一个是内部类的 .class 文件，即成员内部类的 .class 文件总是这样：外部类名$内部类名.class 另外，友情提示哦： 外部类是不能直接使用内部类的成员和方法滴 可先创建内部类的对象，然后通过内部类的对象来访问其成员变量和方法。 如果外部类和内部类具有相同的成员变量或方法，内部类默认访问自己的成员变量或方法，如果要访问外部类的成员变量，可以使用 this 关键字。如： 运行结果： 静态成员内部类 静态内部类是 static 修饰的内部类，这种内部类的特点是： 静态内部类不能直接访问外部类的非静态成员，但可以通过 new 外部类().成员 的方式访问; 如果外部类的静态成员与内部类的成员名称相同，可通过“类名.静态成员”访问外部类的静态成员；如果外部类的静态成员与内部类的成员名称不相同，则可通过“成员名”直接调用外部类的静态成员; 创建静态内部类的对象时，不需要外部类的对象，可以直接创建 内部类 对象名= new 内部类(); 运行结果 ： 在外面初始化 普通成员内部类：Inner inner = new Outer().new Inner(); 静态成员内部类：Souter.Sinner inner = new Souter.Sinner(); 方法内部类 方法内部类就是内部类定义在外部类的方法中，方法内部类只在该方法的内部可见，即只在该方法内可以使用。 一定要注意哦： 由于方法内部类不能在外部类的方法以外的地方使用，因此方法内部类不能使用访问控制符和 static 修饰符。 方法中的内部类可以访问外部类成员。对于方法的参数和局部变量，必须有final修饰才可以访问。 static方法中定义的内部类可以访问外部类定义的static成员 匿名内部类 定义类的最终目的是创建一个类的实例，但是如果某个类的实例只是用一次，则可以将类的定义与类的创建，放到一起完成，或者说在定义类的同时就创建一个类。 以这种方法定义的没有名字的类成为匿名内部类。 声明和构造匿名内部类的一般格式如下： new ClassOrInterfaceName(){ /\\*类体\\*/ } 匿名内部类可以继承一个类或实现一个接口，这里的ClassOrInterfaceName是匿名内部类所继承的类名或实现的接口名。但匿名内部类不能同时实现一个接口和继承一个类，也不能实现多个接口。如果实现了一个接口，该类是Object类的直接子类，匿名类继承一个类或实现一个接口，不需要extends和implements关键字。 由于匿名内部类没有名称，所以类体中不能定义构造方法，由于不知道类名也不能使用关键字来创建该类的实例。实际上匿名内部类的定义、构造、和第一次使用都发生在同样一个地方。此外，上式是一个表达式，返回的是一个对象的引用，所以可以直接使用或将其复制给一个对象变量。例：TypeName obj=new Name(){ /\\*此处为类体\\*/ } 同样，也可以将构造的对象作为调用的参数。例：someMethod(new Name(){ /\\*此处为类体\\*/ }); 程序代码：public class NiMing { private int size=5; public Object makeInner(int localVar){ final int finalLocalVar=localVar; return new Object(){ //使用匿名内部类 public String toString(){ return \"OuterSize=\"+size+\"nfinalLocalVar=\"+finalLocalVar; } } ; } /** * @param args */ public static void main(String args[]) { Object obj=new NiMing().makeInner(47); System.out.println(obj.toString()); } } 程序运行结果：OuterSize=5 finalLocalVar=47 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section8/":{"url":"chapter1/section8/","title":"1.8 注解","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 元注解： @Target： @Retention： @Documented: @Inherited： 自定义注解： 注解元素的默认值： 注解处理器类库(java.lang.reflect.AnnotatedElement)： 总结 ﻿# 注解 要深入学习注解，我们就必须能定义自己的注解，并使用注解，在定义自己的注解之前，我们就必须要了解Java为我们提供的元注解和相关定义注解的语法。 元注解： 元注解的作用就是负责注解其他注解。Java5.0定义了4个标准的meta-annotation类型，它们被用来提供对其它 annotation类型作说明。Java5.0定义的元注解： @Target, @Retention, @Documented, @Inherited 这些类型和它们所支持的类在java.lang.annotation包中可以找到。下面我们看一下每个元注解的作用和相应分参数的使用说明。 @Target： @Target说明了Annotation所修饰的对象范围：Annotation可被用于 packages、 types（类、接口、枚举、Annotation类型）、 类型成员（方法、构造方法、成员变量、枚举值）、 方法参数和本地变量（如循环变量、catch参数）。 在Annotation类型的声明中使用了target可更加明晰其修饰的目标。 作用：用于描述注解的使用范围（即：被描述的注解可以用在什么地方） 取值(ElementType)有： CONSTRUCTOR:用于描述构造器 FIELD:用于描述域 LOCAL_VARIABLE:用于描述局部变量 METHOD:用于描述方法 PACKAGE:用于描述包 PARAMETER:用于描述参数 TYPE:用于描述类、接口(包括注解类型) 或enum声明 使用实例： @Target(ElementType.TYPE) public @interface Table { /** * 数据表名称注解，默认值为类名称 * @return */ public String tableName() default \"className\"; } @Target(ElementType.FIELD) public @interface NoDBColumn { } 注解Table 可以用于注解类、接口(包括注解类型) 或enum声明,而注解NoDBColumn仅可用于注解类的成员变量。 @Retention： @Retention定义了该Annotation被保留的时间长短： 某些Annotation仅出现在源代码中，而被编译器丢弃；而另一些却被编译在class文件中； 编译在class文件中的Annotation可能会被虚拟机忽略，而另一些在class被装载时将被读取（请注意并不影响class的执行，因为Annotation与class在使用上是被分离的）。使用这个meta-Annotation可以对 Annotation的“生命周期”限制。 作用： 表示需要在什么级别保存该注释信息，用于描述注解的生命周期（即：被描述的注解在什么范围内有效） 取值（RetentionPoicy）有： 1.SOURCE:在源文件中有效（即源文件保留） 2.CLASS:在class文件中有效（即class保留） 3.RUNTIME:在运行时有效（即运行时保留） Retention meta-annotation类型有唯一的value作为成员，它的取值来自java.lang.annotation.RetentionPolicy的枚举类型值。 具体实例如下： @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) public @interface Column { public String name() default \"fieldName\"; public String setFuncName() default \"setField\"; public String getFuncName() default \"getField\"; public Boolean defaultDBValue() default false; } Column注解的的RetentionPolicy的属性值是RUTIME,这样注解处理器可以通过反射，获取到该注解的属性值，从而去做一些运行时的逻辑处理。 @Documented: @Documented用于描述其它类型的annotation应该被作为被标注的程序成员的公共API，因此可以被例如javadoc此类的工具文档化。Documented是一个标记注解，没有成员。 @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Column { public String name() default \"fieldName\"; public String setFuncName() default \"setField\"; public String getFuncName() default \"getField\"; public Boolean defaultDBValue() default false; } @Inherited： @Inherited 元注解是一个标记注解，@Inherited阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited修饰的annotation类型被用于一个class，则这个annotation将被用于该class的子类。 注意： @Inherited annotation类型是被标注过的class的子类所继承。类并不从它所实现的接口继承annotation，方法并不从它所重载的方法继承annotation。 当@Inherited annotation类型标注的annotation的Retention是RetentionPolicy.RUNTIME，则反射API增强了这种继承性。如果我们使用java.lang.reflect去查询一个@Inherited annotation类型的annotation时，反射代码检查将展开工作：检查class和其父类，直到发现指定的annotation类型被发现，或者到达类继承结构的顶层。 实例代码： @Inherited public @interface Greeting { public enum FontColor{ BULE,RED,GREEN } ; String name(); FontColor fontColor() default FontColor.GREEN; } 自定义注解： 使用@interface自定义注解时，自动继承了java.lang.annotation.Annotation接口，由编译程序自动完成其他细节。在定义注解时，不能继承其他的注解或接口。@interface用来声明一个注解，其中的每一个方法实际上是声明了一个配置参数。方法的名称就是参数的名称，返回值类型就是参数的类型（返回值类型只能是基本类型、Class、String、enum）。可以通过default来声明参数的默认值。 定义注解格式： public @interface 注解名 { 定义体 } 注解参数的可支持数据类型： 所有基本数据类型（int,float,boolean,byte,double,char,long,short) String类型 Class类型 enum类型 Annotation类型 以上所有类型的数组 Annotation类型里面的参数该怎么设定: 只能用public或默认(default)这两个访问权修饰.例如,String value();这里把方法设为defaul默认类型；　 　 参数成员只能用基本类型byte,short,char,int,long,float,double,boolean八种基本数据类型和 String,Enum,Class,annotations等数据类型,以及这一些类型的数组.例如,String value();这里的参数成员就为String;　　 如果只有一个参数成员,最好把参数名称设为\"value\",后加小括号.例:下面的例子FruitName注解就只有一个参数成员。 简单的自定义注解和使用注解实例： package annotation; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * 水果名称注解 * @author peida * */ @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface FruitName { String value() default \"\"; } package annotation; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * 水果颜色注解 * @author peida * */ @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface FruitColor { /** * 颜色枚举 * @author peida * */ public enum Color{ BULE,RED,GREEN}; /** * 颜色属性 * @return */ Color fruitColor() default Color.GREEN; } package annotation; import annotation.FruitColor.Color; public class Apple { @FruitName(\"Apple\") private String appleName; @FruitColor(fruitColor=Color.RED) private String appleColor; public void setAppleColor(String appleColor) { this.appleColor = appleColor; } public String getAppleColor() { return appleColor; } public void setAppleName(String appleName) { this.appleName = appleName; } public String getAppleName() { return appleName; } public void displayName(){ System.out.println(\"水果的名字是：苹果\"); } } 注解元素的默认值： 注解元素必须有确定的值， 要么在定义注解的默认值中指定，要么在使用注解时指定，非基本类型的注解元素的值不可为null。 因此, 使用空字符串或0作为默认值是一种常用的做法。 这个约束使得处理器很难表现一个元素的存在或缺失的状态，因为每个注解的声明中，所有元素都存在，并且都具有相应的值，为了绕开这个约束，我们只能定义一些特殊的值，例如空字符串或者负数，表示某个元素不存在，在定义注解时，这已经成为一个习惯用法。例如： package annotation; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * 水果供应者注解 * @author peida * */ @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface FruitProvider { /** * 供应商编号 * @return */ public int id() default -1; /** * 供应商名称 * @return */ public String name() default \"\"; /** * 供应商地址 * @return */ public String address() default \"\"; } 定义了注解，并在需要的时候给相关类，类属性加上注解信息，如果没有响应的注解信息处理流程，注解可以说是没有实用价值。如何让注解真真的发挥作用，主要就在于注解处理方法，下一步我们将学习注解信息的获取和处理！ 深入理解Java：注解（Annotation）--注解处理器 如果没有用来读取注解的方法和工作，那么注解也就不会比注释更有用处了。使用注解的过程中，很重要的一部分就是创建于使用注解处理器。Java SE5扩展了反射机制的API，以帮助程序员快速的构造自定义注解处理器。 注解处理器类库(java.lang.reflect.AnnotatedElement)： Java使用Annotation接口来代表程序元素前面的注解，该接口是所有Annotation类型的父接口。 除此之外，Java在java.lang.reflect 包下新增了AnnotatedElement接口，该接口代表程序中可以接受注解的程序元素，该接口主要有如下几个实现类： Class：类定义 Constructor：构造器定义 Field：累的成员变量定义 Method：类的方法定义 Package：类的包定义 java.lang.reflect 包下主要包含一些实现反射功能的工具类，实际上，java.lang.reflect 包所有提供的反射API扩充了读取运行时Annotation信息的能力。 当一个Annotation类型被定义为运行时的Annotation后，该注解才能是运行时可见，当class文件被装载时被保存在class文件中的Annotation才会被虚拟机读取。 AnnotatedElement 接口是所有程序元素（Class、Method和Constructor）的父接口，所以程序通过反射获取了某个类的AnnotatedElement对象之后，程序就可以调用该对象的如下4个方法来访问Annotation信息： T getAnnotation(Class annotationClass): 返回改程序元素上存在的、指定类型的注解，如果该类型注解不存在，则返回null。 Annotation[] getAnnotations():返回该程序元素上存在的所有注解。 boolean is AnnotationPresent(Class annotationClass):判断该程序元素上是否包含指定类型的注解，存在则返回true，否则返回false. Annotation[] getDeclaredAnnotations()：返回直接存在于此元素上的所有注释。与此接口中的其他方法不同，该方法将忽略继承的注释。（如果没有注释直接存在于此元素上，则返回长度为零的一个数组。）该方法的调用者可以随意修改返回的数组；这不会对其他调用者返回的数组产生任何影响。 一个简单的注解处理器：　　 /***********注解声明***************/ /** * 水果名称注解 * @author peida * */ @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface FruitName { String value() default \"\"; } /** * 水果颜色注解 * @author peida * */ @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface FruitColor { /** * 颜色枚举 * @author peida * */ public enum Color{ BULE,RED,GREEN}; /** * 颜色属性 * @return */ Color fruitColor() default Color.GREEN; } /** * 水果供应者注解 * @author peida * */ @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface FruitProvider { /** * 供应商编号 * @return */ public int id() default -1; /** * 供应商名称 * @return */ public String name() default \"\"; /** * 供应商地址 * @return */ public String address() default \"\"; } /***********注解使用***************/ public class Apple { @FruitName(\"Apple\") private String appleName; @FruitColor(fruitColor=Color.RED) private String appleColor; @FruitProvider(id=1,name=\"陕西红富士集团\",address=\"陕西省西安市延安路89号红富士大厦\") private String appleProvider; public void setAppleColor(String appleColor) { this.appleColor = appleColor; } public String getAppleColor() { return appleColor; } public void setAppleName(String appleName) { this.appleName = appleName; } public String getAppleName() { return appleName; } public void setAppleProvider(String appleProvider) { this.appleProvider = appleProvider; } public String getAppleProvider() { return appleProvider; } public void displayName(){ System.out.println(\"水果的名字是：苹果\"); } } /***********注解处理器***************/ public class FruitInfoUtil { public static void getFruitInfo(Class clazz){ String strFruitName=\" 水果名称：\"; String strFruitColor=\" 水果颜色：\"; String strFruitProvicer=\"供应商信息：\"; Field[] fields = clazz.getDeclaredFields(); for(Field field :fields){ if(field.isAnnotationPresent(FruitName.class)){ FruitName fruitName = (FruitName) field.getAnnotation(FruitName.class); strFruitName=strFruitName+fruitName.value(); System.out.println(strFruitName); } else if(field.isAnnotationPresent(FruitColor.class)){ FruitColor fruitColor= (FruitColor) field.getAnnotation(FruitColor.class); strFruitColor=strFruitColor+fruitColor.fruitColor().toString(); System.out.println(strFruitColor); } else if(field.isAnnotationPresent(FruitProvider.class)){ FruitProvider fruitProvider= (FruitProvider) field.getAnnotation(FruitProvider.class); strFruitProvicer=\" 供应商编号：\"+fruitProvider.id()+\" 供应商名称：\"+fruitProvider.name()+\" 供应商地址：\"+fruitProvider.address(); System.out.println(strFruitProvicer); } } } } 输出结果: public class FruitRun { /** * @param args */ public static void main(String[] args) { FruitInfoUtil.getFruitInfo(Apple.class); } } ==================================== 水果名称：Apple 水果颜色：RED 供应商编号：1 供应商名称：陕西红富士集团 供应商地址：陕西省西安市延安路89号红富士大厦 总结 Java注解的基础知识点（见下面导图）基本都过了一遍，下一篇我们通过设计一个基于注解的简单的ORM框架，来综合应用和进一步加深对注解的各个知识点的理解和运用。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section9/":{"url":"chapter1/section9/","title":"1.9 内省","keywords":"","body":"内省 核心概念 首先可以先了解下JavaBean的概念：一种特殊的类，主要用于传递数据信息。这种类中的方法主要用于访问私有的字段，且方法名符合某种命名规则。如果在两个模块之间传递信息，可以将信息封装进JavaBean中，这种对象称为“值对象”(Value Object)，或“VO”。 因此JavaBean都有如下几个特征： 属性都是私有的； 有无参的public构造方法； 对私有属性根据需要提供公有的getXxx方法以及setXxx方法； getters必须有返回值没有方法参数；setter值没有返回值，有方法参数； 符合这些特征的类，被称为JavaBean； JDK中提供了一套API用来访问某个属性的getter/setter方法，这些API存放在java.beans中，这就是内省(Introspector)。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section10/":{"url":"chapter1/section10/","title":"1.10 反射","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 编译时静态加载类，与运行时动态加载类 方法反射 反射绕过泛型限制 反射 泛型参数的安全检查发生在编译时, 在\"运行\"期间，所有的泛型信息都会被擦掉 反射之所以被称为框架的灵魂，主要是因为它赋予了我们在\"运行时\"分析类以及执行类中方法的能力。可以无视泛型参数的安全检查。 反射为各种框架提供开箱即用的功能提供了便利。 编译时静态加载类，与运行时动态加载类 package com.imooc.reflect; public class ClassDemo1 { public static void main(String[] args) { //Foo的实例对象如何表示 Foo foo1 = new Foo(); //foo1就表示出来了. //Foo这个类 也是一个实例对象，Class类的实例对象,如何表示呢 //任何一个类都是Class的实例对象，这个实例对象有三种表示方式 //第一种表示方式--->实际在告诉我们任何一个类都有一个隐含的静态成员变量class Class c1 = Foo.class; //第二中表达方式 已经知道该类的对象通过getClass方法 Class c2 = foo1.getClass(); /*官网 c1 ,c2 表示了Foo类的类类型(class type) * 万事万物皆对象， * 类也是对象，是Class类的实例对象 * 这个对象我们称为该类的类类型 * */ //不管c1 or c2都代表了Foo类的类类型，一个类只可能是Class类的一个实例对象 System.out.println(c1 == c2); //第三种表达方式 Class c3 = null; try { c3 = Class.forName(\"com.imooc.reflect.Foo\"); } catch (ClassNotFoundException e) { // TODO Auto-generated catch block e.printStackTrace(); } System.out.println(c2==c3); //我们完全可以通过类的类类型创建该类的对象实例---->通过c1 or c2 or c3创建Foo的实例对象 try { Foo foo = (Foo)c1.newInstance(); //需要有无参数的构造方法 foo.print(); } catch (InstantiationException e) { // TODO Auto-generated catch block e.printStackTrace(); } catch (IllegalAccessException e) { // TODO Auto-generated catch block e.printStackTrace(); } } } class Foo{ void print(){ System.out.println(\"foo\"); } } 方法反射 package com.imooc.reflect; import java.lang.reflect.Method; public class MethodDemo1 { public static void main(String[] args) { //要获取print(int ,int )方法 1.要获取一个方法就是获取类的信息，获取类的信息首先要获取类的类类型 A a1 = new A(); Class c = a1.getClass(); /* * 2.获取方法 名称和参数列表来决定 * getMethod获取的是public的方法 * getDelcaredMethod自己声明的方法 */ try { //Method m = c.getMethod(\"print\", new Class[]{int.class,int.class}); Method m = c.getMethod(\"print\", int.class,int.class); //方法的反射操作 //a1.print(10, 20);方法的反射操作是用m对象来进行方法调用 和a1.print调用的效果完全相同 //方法如果没有返回值返回null,有返回值返回具体的返回值 //Object o = m.invoke(a1,new Object[]{10,20}); Object o = m.invoke(a1, 10,20); System.out.println(\"==================\"); //获取方法print(String,String) Method m1 = c.getMethod(\"print\",String.class,String.class); //用方法进行反射操作 //a1.print(\"hello\", \"WORLD\"); o = m1.invoke(a1, \"hello\",\"WORLD\"); System.out.println(\"===================\"); // Method m2 = c.getMethod(\"print\", new Class[]{}); Method m2 = c.getMethod(\"print\"); // m2.invoke(a1, new Object[]{}); m2.invoke(a1); } catch (Exception e) { // TODO Auto-generated catch block e.printStackTrace(); } } } class A{ public void print(){ System.out.println(\"helloworld\"); } public void print(int a,int b){ System.out.println(a+b); } public void print(String a,String b){ System.out.println(a.toUpperCase()+\",\"+b.toLowerCase()); } } 反射绕过泛型限制 package com.imooc.reflect; import java.lang.reflect.Method; import java.util.ArrayList; public class MethodDemo4 { public static void main(String[] args) { ArrayList list = new ArrayList(); ArrayList list1 = new ArrayList(); list1.add(\"hello\"); //list1.add(20);错误的 Class c1 = list.getClass(); Class c2 = list1.getClass(); System.out.println(c1 == c2); //反射的操作都是编译之后的操作 /* * c1==c2结果返回true说明编译之后集合的泛型是去泛型化的 * Java中集合的泛型，是防止错误输入的，只在编译阶段有效， * 绕过编译就无效了 * 验证：我们可以通过方法的反射来操作，绕过编译 */ try { Method m = c2.getMethod(\"add\", Object.class); m.invoke(list1, 20); //绕过编译操作就绕过了泛型 System.out.println(list1.size()); System.out.println(list1); /*for (String string : list1) { System.out.println(string); }*/ //现在不能这样遍历 } catch (Exception e) { e.printStackTrace(); } } } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section11/":{"url":"chapter1/section11/","title":"1.11 内省和反射的区别","keywords":"","body":"内省和反射的区别 反射：Java反射机制是在运行中，对任意一个类，能够获取得到这个类的所有属性和方法；它针对的是任意类 内省（Introspector）：是Java语言对JavaBean类属性、事件的处理方法 反射可以操作各种类的属性，而内省只是通过反射来操作JavaBean的属性 内省设置属性值肯定会调用setter方法，反射可以不用（反射可直接操作属性Field） 反射就像照镜子，然后能看到.class的所有，是客观的事实。内省更像主观的判断：比如看到getName()，内省就会认为这个类中有name字段，但事实上并不一定会有name；通过内省可以获取bean的getter/setter 使用示例： class People{ String name; int age; public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } } public class Main { public static void main(String[] args) throws Exception{ BeanInfo beanInfo = Introspector.getBeanInfo(People.class); PropertyDescriptor[] propertyDescriptors = beanInfo.getPropertyDescriptors(); for (PropertyDescriptor propertyDescriptor : propertyDescriptors) { System.out.print(propertyDescriptor.getName()+\" \"); } } } 程序输出： age class name 为什么会输出class呢？前文中有提到，“看到getName()，内省就会认为这个类中有name字段，但事实上并不一定会有name”，我们知道每个对象都会有getClass方法，所以使用内省时，默认就认为它具有class这个字段 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section12/":{"url":"chapter1/section12/","title":"1.12 构造方法的访问级别","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 private修饰的构造方法的访问级别： 把构造方法声明为private的理由： 疑问 构造方法的访问级别 public、protected、private、默认访问级别都可以。在此重点记录由private修饰的构造方法。 private修饰的构造方法的访问级别： 当构造方法别声明为private时，就意味着只有当前类的方法可以调用它， 当前类的其它构造方法可以通过this关键字来调用。 当前类的成员方法可以通过new语句调用它。 把构造方法声明为private的理由： 这个类中仅仅包含供其它类调用的静态方法，没有实例方法。这意味着当某个类想要调用该类中的方法时，无需创建该类的实例，即不会触及到该类的构造方法。 禁止这个类被继承。 这个类需要把自身实现的细节封装起来，不允许其它程序通过new语句来创建这个类的实例。这个类向其他程序提供了获取自身实例的静态方法，这种方法称为静态工厂方法。 疑问 疑问1: 也许有人会有疑问：“用abstract修饰词修饰的类也不可以创建实例，在此和要使用private访问权限词限定构造访问的区别是什么？” 疑问2：final修饰词修饰的类也不能被继承，在此和要使用private访问权限词限定构造访问的区别是什么 原因：用private访问权限限定词限定类的构造方法，表示该类既不能被继承又不能创建该类的实例。 abstract，可以被继承，不能创建实例。 final，不可以被继承，可以创建实例。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section13/":{"url":"chapter1/section13/","title":"1.13 从磁盘获取资源","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 Class.getResource(String path) Class.getClassLoader().getResource(String path) 从磁盘获取资源 Java中取资源时，经常用到Class.getResource和ClassLoader.getResource，这里来看看他们在取资源文件时候的路径问题。 Class.getResource(String path) path不以’/'开头时，默认是从此类所在的包下取资源； path 以’/'开头时，则是从ClassPath根下获取； 什么意思呢？看下面这段代码的输出结果就明白了： package testpackage; public class TestMain { public static void main(String[] args) { System.out.println(TestMain.class.getResource(\"\")); System.out.println(TestMain.class.getResource(\"/\")); } } 输出结果： file:/E:/workspace/Test/bin/testpackage/ file:/E:/workspace/Test/bin/ 上面说到的【path以’/'开头时，则是从ClassPath根下获取；】在这里就是相当于bin目录(Eclipse环境下)。 再来一个实例，假设有如下Project结构： 如果我们想在TestMain.java中分别取到1~3.properties文件，该怎么写路径呢？代码如下： package testpackage; public class TestMain { public static void main(String[] args) { // 当前类(class)所在的包目录 System.out.println(TestMain.class.getResource(\"\")); // class path根目录 System.out.println(TestMain.class.getResource(\"/\")); // TestMain.class在/testpackage包中 // 2.properties 在/testpackage包中 System.out.println(TestMain.class.getResource(\"2.properties\")); // TestMain.class在/testpackage包中 // 3.properties 在/testpackage.subpackage包中 System.out.println(TestMain.class.getResource(\"subpackage/3.properties\")); // TestMain.class在/testpackage包中 // 1.properties 在bin目录（class根目录） System.out.println(TestMain.class.getResource(\"/1.properties\")); } } 注： Class.getResource和Class.getResourceAsStream在使用时，路径选择上是一样的。 Class.getClassLoader().getResource(String path) path不能以’/'开头； path是从ClassPath根下获取； 还是先看一下下面这段代码的输出： package testpackage; public class TestMain { public static void main(String[] args) { TestMain t = new TestMain(); System.out.println(t.getClass()); System.out.println(t.getClass().getClassLoader()); System.out.println(t.getClass().getClassLoader().getResource(\"\")); System.out.println(t.getClass().getClassLoader().getResource(\"/\"));//null } } 输出结果： class testpackage.TestMain sun.misc.Launcher$AppClassLoader@1fb8ee3 file:/E:/workspace/Test/bin/ null 从结果来看: TestMain.class.getResource(\"/\") == t.getClass().getClassLoader().getResource(\"\") 如果有同样的Project结构 使用Class.getClassLoader().getResource(String path)可以这么写： package testpackage; public class TestMain { public static void main(String[] args) { TestMain t = new TestMain(); System.out.println(t.getClass().getClassLoader().getResource(\"\")); System.out.println(t.getClass().getClassLoader().getResource(\"1.properties\")); System.out.println(t.getClass().getClassLoader().getResource(\"testpackage/2.properties\")); System.out.println(t.getClass().getClassLoader().getResource(\"testpackage/subpackage/3.properties\")); } } 注： Class.getClassLoader（）.getResource和Class.getClassLoader（）.getResourceAsStream在使用时，路径选择上也是一样的。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section14/":{"url":"chapter1/section14/","title":"1.14 hashcode()&equals()","keywords":"","body":"hashcode()&equals() 在插入桶中的判断时，会先比较旧值和新插入值的hashcode,碰到hashCode相同的值，才会去调用equals方法判断两个对象是否真的相等。 而本身默认的方法产生的hashCode一定不会相等，那么即使重写了equals方法，这个equals方法也不会被调用，那不白重写了。 因此重写equals必须重写自己的业务hashCode，让两个对象有可能生成相等的hashCode。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section15/":{"url":"chapter1/section15/","title":"1.15 包装类","keywords":"","body":"包装类 有-128到127的缓存常量（除了Float和Double） Byte,Short,Integer,Long 这 4 种包装类默认创建了数值 [-128，127] 的相应类型的缓存数据， Character 创建了数值在 [0,127] 范围的缓存数据， Boolean 直接返回 True Or False。 超过后就new对象。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter1/section16/":{"url":"chapter1/section16/","title":"1.16 try-catch中的return","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 执行顺序 2 return在不同的块中 2.1 return在try中 2.2 return在catch中 2.3 return在finally中 try catch finally 中的return try-catch-finally 中，如果 catch 中 return 了，finally 还会执行吗 1 执行顺序 try{ }catch(){ }finally{ } 无异常：try->finally 有异常：try->catch->finally 2 return在不同的块中 2.1 return在try中 无异常：保存try中return后的表达式计算结果(a=0)->finally随便怎么修改(a=1)->依然return之前保存的结果(a=0) int a = 0; try{ return a; }catch(){ }finally{ ++a; } 但如果a是引用类型的话，finally中修改了a里面的成员字段的值，这样在最后return后的值是起效的。 2.2 return在catch中 有异常：try抛异常->保存catch中return后的表达式结果(a=1)->finally随便怎么修改(a=2)->依然return之前保存的结果(a=1) int a = 0; try{ //抛异常 return a; }catch(){ return ++a; }finally{ ++a; } 如果a是引用类型的话，同上。 2.3 return在finally中 假设无异常：保存try中return后的表达式计算结果(a=0)->保存finally中return后的表达式计算结果(a=1),直接返回1。 int a = 0; try{ return a; }catch(){ }finally{ return ++a; } 有异常也同理，都会在finally中直接返回 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-17 16:44:38 "},"chapter1/section17/":{"url":"chapter1/section17/","title":"1.17 java命令行操作","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 javac 1.1 @ 1.2 -classpath 1.3 -sourcepath 1.4 -d 2 java java命令行操作 javac的相关的参数 java -c_JAVAC 命令使用方法 1 javac 笔记就主要记4个参数： -sourcepath: 指定源文件(.java)的位置 -classpath: 指定类文件(.class,通常源文件中依赖的其它类文件)的位置 -d: 指定在哪里放编译后生成的类文件(通常源文件不应该和类文件在同一个目录下) @: @后跟的文件名对应的文件中可以放很多个需要编译的java文件名 1.1 @ javac @sourcefiles sourcefiles这个文件名对应的文件中可以写任意多个.java的文件： MyClass1.java MyClass2.java MyClass3.java 1.2 -classpath 1 有类路径 设置用户类路径，它将覆盖环境变量 CLASSPATH 中的用户类路径。 示例，设置当前目录中的examples为类路径： javac -classpath \\examples \\examples\\greetings\\Hi.java 若classpath指定的包含jar包，需要加冒号进行连接： javac -sourcepath src -classpath classes:lib\\Banners.jar \\ 意思是类路径为classes\\lib下有个叫Banners.jar的jar包里的类，最后一个\\指的是将src下所有且不同层级的.java全部进行编译。 java命令碰到jar包也是用冒号连接 2 没有类路径 若: 没有环境变量 CLASSPATH 又未指定 -classpath， 则用户类路径由当前文件夹构成。有关具体信息，请參阅设置类路径。 示例： javac greetings\\Hi.java 1.3 -sourcepath 若未指定 -sourcepath 选项，则将在用户类路径中查找类文件和源文件。 示例见上面1 有类路径的情况。 1.4 -d 设置编译后生成的类文件的目标文件夹。 假设某个类是一个包的组成部分，则 javac 将把该类文件放入反映包名的子文件夹中，必要时创建文件夹。 比如，假设指定 -d c:\\myclasses 而且该类名叫 com.mypackage.MyClass，那么类文件就叫作 c:\\myclasses\\com\\mypackage\\MyClass.class。 若未指定 -d 选项，则 javac 将把类文件放到与源文件同样的文件夹中。 注意： -d 选项指定的文件夹不会被自己主动增加到用户类路径中。 2 java 见首部参考链接。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-07-08 12:53:43 "},"chapter2/section1/":{"url":"chapter2/section1/","title":"2.1 总览","keywords":"","body":"总览 HashSet(无序，唯一): 基于 HashMap 实现。其value为常量值new Object(); LinkedHashSet: 基于LinkedHashMap 实现。其value为常量值new Object(); LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。详细可以查看：《LinkedHashMap 源码详细分析（JDK1.8）》 TreeSet(有序，唯一): 红黑树(自平衡的排序二叉树) PriorityQueue: Object[] 数组来实现二叉堆 ArrayQueue: Object[] 数组 + 双指针 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter2/section2/":{"url":"chapter2/section2/","title":"2.2 Queue与Deque的区别","keywords":"","body":"﻿ Queue 与 Deque 的区别 Queue 扩展了 Collection 的接口，是单端队列，只能从一端插入元素，另一端删除元素， Deque 扩展了 Queue 的接口，是双端队列，增加了在队首和队尾进行插入和删除的方法，在队列的两端均可以插入或删除元素。 Queue 接口 抛出异常 返回特殊值 插入队尾 add(E e) offer(E e) 删除队首 remove() poll() 查询队首元素 element() peek() Deque 接口 抛出异常 返回特殊值 插入队首 addFirst(E e) offerFirst(E e) 插入队尾 addLast(E e) offerLast(E e) 删除队首 removeFirst() pollFirst() 删除队尾 removeLast() pollLast() 查询队首元素 getFirst() peekFirst() 查询队尾元素 getLast() peekLast() Deque 还提供有 push() 和 pop() 等其他方法，可用于模拟栈。实现类LinkedList既可以当栈使用也可以当队列。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter2/section3/":{"url":"chapter2/section3/","title":"2.3 Stack","keywords":"","body":"﻿ Stack boolean empty() synchronized E peek() synchronized E pop() E push(E object) synchronized int search(Object o) Stack实际上也是通过数组去实现的。 执行push时(即，将元素推入栈中)，是通过将元素追加的数组的末尾中。 执行peek时(即，取出栈顶元素，不执行删除)，是返回数组末尾的元素。 执行pop时(即，取出栈顶元素，并将该元素从栈中删除)，是取出数组末尾的元素，然后将该元素从数组中删除。 Stack继承于Vector，意味着Vector拥有的属性和功能，Stack都拥有。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter2/section4/":{"url":"chapter2/section4/","title":"2.4 PriorityQueue","keywords":"","body":"﻿ PriorityQueue PriorityQueue 在面试中可能更多的会出现在手撕算法的时候，典型例题包括堆排序、求第K大的数、带权图的遍历等，所以需要会熟练使用才行。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter2/section5/":{"url":"chapter2/section5/","title":"2.5 ArrayList","keywords":"","body":"﻿ ArrayList 1.5倍扩容。 List list = new ArrayList<>(Arrays.asList(\"a\", \"b\", \"c\")) Arrays.asList的参数不能是基本数据类型，必须是包装类。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter2/section6/":{"url":"chapter2/section6/","title":"2.6 数组/列表互换","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 数组/列表互换 将列表转为int数组（基本类型数组） ﻿ 数组/列表互换 数组转列表：new ArrayList<>(Arrays.asList(T[] t)); 列表转数组：List对象的toArray(new T[len]); //只能是对象数组，不能是基本类型数组 将多个数组转化成一个链表 list.add(new ArrayList<>(Arrays.asList(nums[i], nums[left], nums[right]))); 转成二维数组 List list = new ArrayList<>(); list.toArray(new int[list.size()][]); 将列表转为int数组（基本类型数组） 使用流。 ArrayList res = new ArrayList<>(); int[] a = res.stream().mapToInt(Integer::valueOf).toArray(); Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter2/section7/":{"url":"chapter2/section7/","title":"2.7 高并发下的集合替换","keywords":"","body":"﻿ 高并发下的集合替换 多线程 单线程 CopyOnWriteArrayList （内部支持读写锁思想） arraylist ConcurrentLinkedQueue（非阻塞队列，cas来控制多线程并发） linkedlist BlockingQueue （阻塞队列，用锁来控制多线程并发，多用于实现生产者-消费者模式） ConcurrentSkipListMap（有序） ConcurrentHashMap（无序） hashMap Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter2/section8/":{"url":"chapter2/section8/","title":"2.8 Collections&Arrays","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 collections 2 Arrays 2.1 System.arraycopy ﻿# Collections&Arrays 1 collections void reverse(List list)//反转 void shuffle(List list)//随机排序 void sort(List list)//按自然排序的升序排序 void sort(List list, Comparator c)//定制排序，由Comparator控制排序逻辑 void swap(List list, int i , int j)//交换两个索引位置的元素 void rotate(List list, int distance)//旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面 int binarySearch(List list, Object key)//对List进行二分查找，返回索引，注意List必须是有序的 int max(Collection coll)//根据元素的自然顺序，返回最大的元素。 类比int min(Collection coll) int max(Collection coll, Comparator c)//根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c) void fill(List list, Object obj)//用指定的元素代替指定list中的所有元素 int frequency(Collection c, Object o)//统计元素出现次数 int indexOfSubList(List list, List target)//统计target在list中第一次出现的索引，找不到则返回-1，类比int lastIndexOfSubList(List source, list target) boolean replaceAll(List list, Object oldVal, Object newVal)//用新元素替换旧元素 2 Arrays copyOfRange(int[] original, int from, int to)//返回某个范围的元素形成的数组 copyOf(int[] original, int newLength)//复制数组，内部实际调用System.arraycopy toString() sort binarySearch equals fill 2.1 System.arraycopy System.arraycopy(Object src, int srcPos, Object dest, int destPos, int length); 从src中索引srcPos开始的length个item复制到dest中索引为destPos的位置上。 浅拷贝：假设B复制了A，当修改A时，B也跟着变了 深拷贝：B没变 该方法针对不同类型复制的类型不同： 浅拷贝：二维数组 深拷贝：基本数据类型(int/long...)、Object类型(自定义的)、String类型 该方法线程不安全，参考System.arraycopy线程安全问题 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter2/section9/":{"url":"chapter2/section9/","title":"2.9 comparator","keywords":"","body":"﻿ comparator comparator的compare方法返回值反应方法入参的两个参数的权重。 参数的顺序严格区分。 返回值大于0是前者权重大，小于0是后者权重大。 最后按照权重由小到大排序（升序排列）。 假设令compare(o1,o2),其中o1=4, o2=6, 返回值大于0表示4权重大，权重默认升序,最后4排后面, 最后得到的排列结果为数值降序。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section1/":{"url":"chapter3/section1/","title":"3.1 总览","keywords":"","body":"总览 特性: 可维护； 可扩展； 可复用； 灵活性好。 原则: 单一职责原则； 开放-封闭原则； 依赖倒转原则：①高层和底层都依赖抽象②具体依赖抽象； 里氏代换原则：子类可以代替父类； 迪米特法则：如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果其中一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。强调类之间的松耦合； 合成/聚合复用原则，优先使用对象合成/聚合，而不是类继承，用继承时，一定要在是‘is-a’关系时再考虑使用（桥接模式）。【18_01_28补充】 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section2/":{"url":"chapter3/section2/","title":"3.2 单例模式","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 在懒汉情况下 在饿汉情况下 spring的单例 bean 存在线程案例 单例模式 多线程时， 在懒汉情况下 是在第一次被引用时，才会实例化。 如果运用单例模式那个类获得实例的方法被同时访问，可能会创建多个实例，这时需要做双重锁来确保线程安全（指的是获得时的线程安全） /** * 懒汉单例 */ public class LazySingleton { private static volatile LazySingleton instance; private LazySingleton(){ } public static LazySingleton getInstance() { if(instance == null){ synchronized (LazySingleton.class){ if(instance == null){ instance = new LazySingleton(); } } } return instance; } } 第1个check：如果去掉，那么所有线程都会串行执行 第2个check：如果同时有多个线程绕过了第1个check，那么只会有一个线程进入同步块，等第1个线程创建好再退出同步块后，后面堵塞的线程判断第2个check会发现已经创建好，直接退出同步块。 volatile修饰：instance = new LazySingleton();不是原子操作，步骤包括： 分配内存 初始化零值 设置对象头（该对象是某类的实例等） 调用构造方法 在第3步时，对象已不为null，若此时当前线程时间片到期，有另外的线程判断第1个check： 若没有volatile,会发现不为null，直接返回未初始完成的对象。 若有volatile,因为storeload屏障的存在，另外的线程会阻塞在当前对象的读取上，直到能够初始该对象的线程写入（即构造方法调用）完成。 在饿汉情况下 就是静态初始化的方式，是类一加载就实例化的对象，就不会出现多线程安全问题 /** * 饿汉单例 */ public class HungrySingleton { private static final HungrySingleton instance = new HungrySingleton(); private HungrySingleton(){ } public static HungrySingleton getInstance() { return instance; } } spring的单例 bean 存在线程案例 主要是因为当多个线程操作同一个对象的时候是存在资源竞争的。 常见的有两种解决办法： 在 bean 中尽量避免定义可变的成员变量。 在类中定义一个 ThreadLocal 成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。 不过，大部分 bean 实际都是无状态（没有实例变量）的（比如 Dao、Service），这种情况下， bean 是线程安全的。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section3/":{"url":"chapter3/section3/","title":"3.3 原型模式","keywords":"","body":"原型模式 浅复制与深复制 浅复制，被复制对象的所有变量都含有与原来的对象相同的值，而所有的对其他对象的引用都仍然指向原来的对象 深复制，把引用对象的变量指向复制过的新对象，而不是原有的被引用的对象 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section4/":{"url":"chapter3/section4/","title":"3.4 简单工厂模式","keywords":"","body":"简单工厂模式 简单工厂模式需要客户端认识两个及以上的类, 违背了开放封闭原则。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section5/":{"url":"chapter3/section5/","title":"3.5 策略模式","keywords":"","body":"策略模式 而策略模式只需要客户端认识一个类。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section6/":{"url":"chapter3/section6/","title":"3.6 模板方法模式","keywords":"","body":"模板方法模式 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section7/":{"url":"chapter3/section7/","title":"3.7 工厂方法模式","keywords":"","body":"工厂方法模式 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section8/":{"url":"chapter3/section8/","title":"3.8 抽象工厂模式","keywords":"","body":"抽象工厂模式 抽象工厂模式只是在工厂方法模式的基础上在factory接口中添加创建新对象的方法 在本例中就是添加新的表，再在factory接口中添加对应的表对象的方法 这里用简单工厂改造抽象工厂，再利用反射，使得程序由编译时转为运行时， 即具体的对象生成可以利用properties文件通过反射获得 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section9/":{"url":"chapter3/section9/","title":"3.9 代理模式","keywords":"","body":"代理模式 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section10/":{"url":"chapter3/section10/","title":"3.10 装饰器模式","keywords":"","body":"装饰器模式 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section11/":{"url":"chapter3/section11/","title":"3.11 观察者模式","keywords":"","body":"观察者模式 https://blog.csdn.net/u010644448/article/details/53764489 应用场景：监听器 通过观察者模式可以实现监听器， 我认为用户自定义的监听器类可以通过反射的方式获取，具体方法是通过获得监听器接口的类加载器，获得该类加载器所加载的所有类，遍历判断哪些类实现了该监听器接口。具体如下： @SuppressWarnings(\"unchecked\") private List> getAllSubclassOfTestInterface() { Field field = null; Vector v = null; List> allSubclass = new ArrayList>(); Class scmJobClass = ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); Class classOfClassLoader = classLoader.getClass(); try { testInterfaceClass = (Class) Class.forName(\"com.xxx.xxx.xxx.TestInterface\"); } catch (ClassNotFoundException e) { throw new RuntimeException( \"无法获取到TestInterface的Class对象!查看包名,路径是否正确\"); } while (classOfClassLoader != ClassLoader.class) { classOfClassLoader = classOfClassLoader.getSuperclass(); } try { field = classOfClassLoader.getDeclaredField(\"classes\"); } catch (NoSuchFieldException e) { throw new RuntimeException( \"无法获取到当前线程的类加载器的classes域!\"); } field.setAccessible(true); try { v = (Vector) field.get(classLoader); } catch (IllegalAccessException e) { throw new RuntimeException( \"无法从类加载器中获取到类属性!\"); } for (int i = 0; i c = (Class) v.get(i); if (scmJobClass.isAssignableFrom(c) && !scmJobClass.equals(c) && !abstractScmJobClass .equals(c)) { allSubclass.add((Class) c); } } return allSubclass; } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter3/section12/":{"url":"chapter3/section12/","title":"3.12 门面模式","keywords":"","body":"外观模式（门面模式） 门面模式，其核心为外部与一个子系统的通信必须通过一个统一的外观对象进行，使得子系统更易于使用。用一张图来表示门面模式的结构为： 门面模式的核心为Facade即门面对象，门面对象核心为几个点： 知道所有子角色的功能和责任 将客户端发来的请求委派到子系统中，没有实际业务逻辑 不参与子系统内业务逻辑的实现 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section1/":{"url":"chapter4/section1/","title":"4.1 使用多线程原因","keywords":"","body":"使用多线程原因 比起用多进程，线程切换的成本要低一些。 在单核cpu时代，如果只有一个线程，当它堵塞在io时，cpu就闲置了，因此多线程可以提升效率。 在多核cpu时代，在无竞争情况下，一核可以运行一个线程，如果只有一个线程运行，其它核岂不是浪费。 再说现在这个互联网时代，并发量更高才能承载更多的流量，钱不香吗。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section2/":{"url":"chapter4/section2/","title":"4.2 带来的问题","keywords":"","body":"带来的问题 像内存泄露啊，某些已经是无用的变量开辟的空间没得到清理，持续占用着内存，导致可用内存越来越小。 死锁，互相占着对方需要的资源（锁对象），然后请求获得对方拥有的锁对象，导致的死锁。 线程不安全，如果在使用共享变量的时候，不加锁，因为在改变变量的值的操作不是原子操作，引此会引起两个线程操作，值只变化了一次。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section3/":{"url":"chapter4/section3/","title":"4.3 生命周期（各个状态）","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 Object.wait|Object.notify实例 Thread.sleep|Thread.yield join interrupt 生命周期（各个状态） wait叫等待，抢不到锁才叫阻塞。 【操作系统中层面线程有 READY 和 RUNNING 状态，但jvm因为这两种状态切换时间太短，直接合二为一称之为RUNNABLE状态】 通过 sleep（long millis）方法或 wait（long millis）方法可以将 Java 线程置于 TIMED_WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE （其实是就绪）状态。 Object.wait|Object.notify实例 Object的实例方法(不过只调用锁对象中的该方法) public class Main { Object odd = new Object(); // 奇数条件锁 Object even = new Object(); // 偶数条件锁 private int max=200; private AtomicInteger status = new AtomicInteger(0); // AtomicInteger保证可见性，也可以用volatile public static void main(String[] args) { Main main = new Main(); Thread printer1 = new Thread(main.new MyPrinter(\"线程1\", 0)); Thread printer2 = new Thread(main.new MyPrinter(\"线程2\", 1)); printer1.start(); printer2.start(); } public class MyPrinter implements Runnable { private String name; private int type; // 打印的类型，0：代表打印奇数，1：代表打印偶数 public MyPrinter(String name, int type) { this.name = name; this.type = type; } @Override public void run() { if (type == 0){ while(status.get()Thread.sleep|Thread.yield 两者是Thread类的静态方法。 sleep交出的资源所有线程都可以去竞争， yield交出的时间片资源只有和当前线程同优先级的线程才可以获取到。 如果持有锁的话，两者都不释放锁。 Java中，通过一个整型变量Priority来控制线程的优先级，范围为1~10,通过调用setPriority（int Priority）可以设置，默认值为5。 join join是Thread类的实例方法。 A线程如果调用了B线程的join方法，那么A线程会一直阻塞直到B线程运行结束。 class AThread extends Thread { BThread bt; public AThread(BThread bt) { super(\"[AThread] Thread\"); this.bt = bt; } public void run() { String threadName = Thread.currentThread().getName(); System.out.println(threadName + \" start.\"); try { bt.join();//调用之后，A线程阻塞直到B线程运行结束 System.out.println(threadName + \" end.\"); } catch (Exception e) { System.out.println(\"Exception from \" + threadName + \".run\"); } } } interrupt interrupt是Thread类的实例方法。 interrupt基于一个线程不应该由其他线程来强制中断或停止，而是应该由线程内部来自行停止的思想来实现的，自己的事自己处理，是一种比较温柔和安全的做法，而且中断不活动的线程不会产生任何影响。 调用interrupt()会立即将线程的中断标记设为“true”，因此代码可以这样写： public class InterruptionInJava implements Runnable{ public static void main(String[] args) throws InterruptedException { Thread testThread = new Thread(new InterruptionInJava(),\"InterruptionInJava\"); //start thread testThread.start(); Thread.sleep(1000);//主线程sleep //interrupt thread testThread.interrupt(); System.out.println(\"main end\"); } @Override public void run() { while (!Thread.currentThread().isInterrupted()) { } } } 但是由于线程处于\"阻塞\"状态（包含了I/O阻塞或线程等待状态或抢不到锁进入的阻塞状态），所以该“中断标记”会立即被清除为“false”，同时，会产生一个InterruptedException的异常。此时应这样写： @Override public void run() { try { // 1. isInterrupted()保证，只要中断标记为true就终止线程。 while (!Thread.currentThread().isInterrupted()) { Thread.sleep(10000000); } } catch (InterruptedException ie) { // 2. InterruptedException异常保证，当InterruptedException异常产生时，线程被终止。 } } 中断时抛出的异常种类有： 除非当前线程正在中断自身（始终允许），否则将调用此线程的checkAccess方法，但这可能导致抛出SecurityException。 如果在调用Object类的wait（）、join（）、sleep（long）阻塞了这个线程，那么它的中断状态将被清除并收到InterruptedException。 如果在InterruptibleChannel上的I / O操作中阻塞了该线程，则该通道将被关闭，线程的中断状态将被设置，并且线程将收到ClosedByInterruptException。 获得中断标记的区别： interrupted()除了返回中断标记之外，它还会清除中断标记(即将中断标记设为false)； 而isInterrupted()仅仅返回中断标记。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section4/":{"url":"chapter4/section4/","title":"4.4 上下文切换","keywords":"","body":"上下文切换 多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。 概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。 从保存当前线程任务状态到再加载另一线程任务状态的过程就是一次上下文切换（jvm的程序计数器）。 上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。 Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section5/":{"url":"chapter4/section5/","title":"4.5 锁","keywords":"","body":"锁 每个对象中都内置了一个 ObjectMonitor对象。另外，wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。 synchronized 主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态。 synchronized或reentrantlock reentrantlock相比synchronized拥有一个tryLock的优势，它可以先尝试获得锁，或者设置在一定时间内尝试获得锁，如果能获得，再lock()，要不然就直接放弃，而synchronized会直接堵塞未获得锁的线程，没有商量的余地。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section6/":{"url":"chapter4/section6/","title":"4.6 死锁：4个条件同时成立","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 避免死锁 银行家算法 手里有100 手里有40 手里有20 死锁：4个条件同时成立 资源得： 互斥：资源被获得后必须得由共享变成非共享，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。 占有并等待：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。 不能被抢：已经获得的资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。 循环等待：有一组等待进程 {P0, P1,..., Pn}， P0 等待的资源被 P1 占有，P1 等待的资源被 P2 占有，......，Pn-1 等待的资源被 Pn 占有，Pn 等待的资源被 P0 占有。 注意，只有四个条件同时成立时，死锁才会出现。 避免死锁 静态策略，破坏上述2、3、4的条件就行。 破坏2，一口气将所有需要的资源全部获得。 破坏3，有线程来抢资源时，抢不到，就把它自己占有的资源放弃了。 破坏4，按某一顺序申请资源，释放资源则反序释放。 动态策略：在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。 银行家算法 核心思想：在资源分配之前，预先判断这次分配是否会导致系统进入不安全状态，如果会导致，就不答应资源分配请求，否则答应。 算法解释： 手里有100 如果你手里有100元，有3个人(B/A/T)来找你借钱。 如果手里的钱+已经借出去的钱不能满足任意一人的最大需求，人家就不还钱了（不安全序列，不答应资源分配）。 解释：手里的钱+已经借出去的钱能满足至少一人的最大需求，就安全，否则连一个人都满足不了了，就不安全。 首先B(70)来借20，判断如果借给它，自己手里还有80，如果A(40)或者T(50)来借钱，自己是能满足二人中任意一人的最大需求的，因此可以借。 A和T相继借钱。 手里有40 等三个人借完后，借钱的情况如下图所示，而自己手里还有40元， 判断一： 此时，如果B想借50，判断如果将手里的40全给他，加上已经借给他的20，就是60 判断二： 或者此时B只借30，判断如果借30给B，加上已经借给他的20，就是50 自己手里的10元钱+三人中任意一人已经借出去的钱都满足不了每个人的最大需求了，此时是不安全序列，因此给B借30也是不行的。 【如果给B借30，系统进入不安全状态，此时自己只有10元，而B、A、T三人只要还没有再借钱，虽然我现在一个人都满足不了，但我还没真正进入死锁状态，只是有可能而已】 判断三： 如果A借20，判断如果借20给A，加上之前借的就是30 手里有20 计算当BAT三人如果把还需要借的钱全部借完的话，此时的安全序列。 判断一： 此时A再借10，自己剩20-10=10，满足其最大需求后，A会将所有的钱还给自己，即自己又有了10+40=50，能满足B和T，安全，可以给A借10. 此时剩下B和T，先借给B或者T都无所谓了，因此所有的人都能满足，此为安全序列：A->B->T或A->T->B 判断二： 此时T再借20，自己分文不剩20-20=0，满足需求后，T还回来，自己又有了50，能满足B和A， 安全序列为：T->A->B或T->B->A Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section7/":{"url":"chapter4/section7/","title":"4.7 AQS","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 原理 AQS 定义两种资源共享方式 基于AQS自定义锁 基于AQS的jdk中的锁 独占锁 1. ReentrantLock 共享锁 1. Semaphore（信号量） 2. CountDownLatch （倒计时器） 3. CyclicBarrier(循环栅栏) AQS AbstractQueuedSynchronizer (AQS)：抽象队列同步器。 它是一个抽象类，主要用来构建锁，或者说同步器。 //java.util.concurrent.locks public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable {} AQS 提供了一些通用功能的实现，因此，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如: ReentrantLock， Semaphore， ReentrantReadWriteLock， SynchronousQueue， FutureTask(jdk1.7) 等等皆是基于 AQS 的。 原理 核心思想： 请求的共享资源空闲， 请求资源的线程设置为有效的工作线程， 将共享资源设置为锁定状态。 请求的共享资源被占用，需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁 实现的，即将暂时获取不到锁的线程加入到队列中。 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。 AQS实现 用一个volatile int 成员变量state来表示争抢的共享资源的同步状态，CAS修改， 通过内置的 FIFO(CLH) 队列来完成获取资源线程的排队工作。 AQS 定义两种资源共享方式 独占：只有一个线程能执行如 ReentrantLock 共享：多个线程可同时执行，如 Semaphore、 CountDownLatCh、 CyclicBarrier、 ReadWriteLock ReentrantReadWriteLock 可以看成是组合式，因为 ReentrantReadWriteLock 也就是读写锁允许多个线程同时对某一资源进行读，不过写时独占。 独占和共享都可分为： 公平锁 ：按照线程在队列中的排队顺序，先到者先拿到锁； 非公平锁 ：当线程要获取锁时，先通过两次 CAS 操作去抢锁，如果没抢到，当前线程再加入到队列中等待唤醒。 基于AQS自定义锁 AQS采用模板方法模式，自定义同步器时需要重写下面几个 AQS 提供的模板方法(对于共享资源 state 的获取和释放)： isHeldExclusively() //该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int) //独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int) //独占方式。尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int) //共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int) //共享方式。尝试释放资源，成功则返回true，失败则返回false。 一般来说，自定义同步器: 要么是独占方法，只需实现tryAcquire-tryRelease、 要么是共享方式，只需实现tryAcquireShared-tryReleaseShared. 但 AQS 也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 基于AQS的jdk中的锁 独占锁 1. ReentrantLock ReentrantLock中公平锁和非公平锁实现的区别， 在于公平锁只tryAquire一次，并且还要判断队列中是否有先于它的线程存在， 而非公平锁要tryAquire两次，并且不判断队列。 ReentrantLock 默认采用非公平锁（更好的性能），通过 boolean 来决定是否用公平锁（传入 true 用公平锁）。 共享锁 1. Semaphore（信号量） 默认非公平模式; 功能： 可以指定多个线程同时访问某个资源。 实现方式： 它默认构造 AQS 的 state 为 permits。当执行任务的线程数量超出 permits，那么多余的线程将会被放入阻塞队列 Park,并自旋判断 state 是否大于 0。只有当 state 大于 0 的时候，阻塞的线程才能继续执行,此时先前执行任务的线程继续执行 release() 方法，release() 方法使得 state 的变量会加 1，那么自旋的线程便会判断成功。 如此，每次只有最多不超过 permits 数量的线程能自旋成功，便限制了执行任务线程的数量。 Semaphore 对应的两个构造方法如下： public Semaphore(int permits) { sync = new NonfairSync(permits); } public Semaphore(int permits, boolean fair) { sync = fair ? new FairSync(permits) : new NonfairSync(permits); } 使用示例： public class SemaphoreExample1 { // 请求的数量 private static final int threadCount = 550; public static void main(String[] args) throws InterruptedException { // 创建一个具有固定线程数量的线程池对象（如果这里线程池的线程数量给太少的话你会发现执行的很慢） ExecutorService threadPool = Executors.newFixedThreadPool(300); // 一次只能允许执行的线程数量。 final Semaphore semaphore = new Semaphore(20); for (int i = 0; i {// Lambda 表达式的运用 try { semaphore.acquire();// 获取一个许可，所以可运行线程数量为20/1=20 test(threadnum); semaphore.release();// 释放一个许可 } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } }); } threadPool.shutdown(); System.out.println(\"finish\"); } public static void test(int threadnum) throws InterruptedException { Thread.sleep(1000);// 模拟请求的耗时操作 System.out.println(\"threadnum:\" + threadnum); Thread.sleep(1000);// 模拟请求的耗时操作 } } 2. CountDownLatch （倒计时器） 功能 允许 count 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。 实现方式 它默认构造 AQS 的 state 值为 count。当线程使用 countDown() 方法时,其实使用了tryReleaseShared方法以 CAS 的操作来减少 state,直至 state 为 0 。当调用 await() 方法的时候，如果 state 不为 0，那就证明任务还没有执行完毕，await() 方法就会一直阻塞，也就是说 await() 方法之后的语句不会被执行。然后，CountDownLatch 会自旋 CAS 判断 state == 0，如果 state == 0 的话，就会释放所有等待的线程，await() 方法之后的语句得到执行。 使用示例 public class CountDownLatchExample1 { // 请求的数量 private static final int threadCount = 550; public static void main(String[] args) throws InterruptedException { // 创建一个具有固定线程数量的线程池对象（如果这里线程池的线程数量给太少的话你会发现执行的很慢） ExecutorService threadPool = Executors.newFixedThreadPool(300); final CountDownLatch countDownLatch = new CountDownLatch(threadCount); for (int i = 0; i {// Lambda 表达式的运用 try { test(threadnum); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } finally { countDownLatch.countDown();// 表示一个请求已经被完成 } }); } countDownLatch.await(); threadPool.shutdown(); System.out.println(\"finish\"); } public static void test(int threadnum) throws InterruptedException { Thread.sleep(1000);// 模拟请求的耗时操作 System.out.println(\"threadnum:\" + threadnum); Thread.sleep(1000);// 模拟请求的耗时操作 } } 两种典型用法 1、某一线程在开始运行前等待 n 个线程执行完毕。 将 CountDownLatch 的计数器初始化为 n （new CountDownLatch(n)），每当一个任务线程执行完毕，就将计数器减 1 （countdownlatch.countDown()），当计数器的值变为 0 时，在 CountDownLatch 上 await() 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。 2、实现多个线程开始执行任务的最大并行性。 注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 CountDownLatch 对象，将其计数器初始化为 1 （new CountDownLatch(1)），多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为 0，多个线程同时被唤醒。 3. CyclicBarrier(循环栅栏) 功能 CyclicBarrier 和 CountDownLatch 类似，它也可以实现线程间的技术等待，但是功能更加复杂和强大。 实现方法 CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是：让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。 CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用 await() 方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。 public CyclicBarrier(int parties) { this(parties, null); } public CyclicBarrier(int parties, Runnable barrierAction) { if (parties parties 就代表了有拦截的线程的数量，当拦截的线程数量达到这个值的时候就打开栅栏，让所有线程通过。 CountDownLatch 的实现是基于 AQS 的，而 CycliBarrier 是基于 ReentrantLock 和 Condition 的。 应用场景 可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个 Excel 保存了用户所有银行流水，每个 Sheet 保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个 sheet 里的银行流水，都执行完之后，得到每个 sheet 的日均银行流水，最后，再用 barrierAction 用这些线程的计算结果，计算出整个 Excel 的日均银行流水。 使用示例 public class CyclicBarrierExample2 { // 请求的数量 private static final int threadCount = 550; // 需要同步的线程数量 private static final CyclicBarrier cyclicBarrier = new CyclicBarrier(5); public static void main(String[] args) throws InterruptedException { // 创建线程池 ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i { try { test(threadNum); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } catch (BrokenBarrierException e) { // TODO Auto-generated catch block e.printStackTrace(); } }); } threadPool.shutdown(); } public static void test(int threadnum) throws InterruptedException, BrokenBarrierException { System.out.println(\"threadnum:\" + threadnum + \"is ready\"); try { /**等待60秒，保证子线程完全执行结束*/ cyclicBarrier.await(60, TimeUnit.SECONDS); } catch (Exception e) { System.out.println(\"-----CyclicBarrierException------\"); } System.out.println(\"threadnum:\" + threadnum + \"is finish\"); } } CountDownLatch 可以让某一个线程等待直到倒计时结束，再开始执行；也可以一个子线程执行结束后，然后countdown(),主线程调用await阻塞等待所有子线程执行完毕，再往下执行。 CyclicBarrier 让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活 上面两个共享锁使用场景一样。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section8/":{"url":"chapter4/section8/","title":"4.8 线程池","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 线程池大小确定 2 常见线程池 2.1 FixedThreadPool 2.1.1 不推荐使用FixedThreadPool 2.2 SingleThreadExecutor 2.2.1 不推荐使用SingleThreadExecutor 2.3 CachedThreadPool 2.3.1 不推荐使用CachedThreadPool 2.4 ScheduledThreadPoolExecutor 2.4.1 运行机制 2.4.2 执行周期任务的步骤 2.4.3 ScheduledThreadPoolExecutor 和 Timer 的比较 3 Excutor使用 线程池 线程池参数解析： 最小线程数量 最大线程数量 任务队列（包括长度） 空闲线程可存活时间（大于最小线程数量的其它线程） 饱和策略（线程数量和任务队列都满了该怎么做） submit()，线程池会返回一个 Future 类型的对象，Future 的get()方法会阻塞当前调用线程直到任务完成。 1 线程池大小确定 有一个简单并且适用面比较广的公式，N（CPU 核心数）： CPU 密集型任务(N+1)： 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N+1，比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。 I/O 密集型任务(2N)： 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。 如何判断是 CPU 密集任务还是 IO 密集任务？ CPU 密集型：简单理解就是利用 CPU 计算能力的任务比如你在内存中对大量数据进行排序。 IO 密集型：但凡涉及到网络读取，文件读取这类都是，这类任务的特点是 CPU 计算耗费时间相比于等待 IO 操作完成的时间来说很少，大部分时间都花在了等待 IO 操作完成上。 2 常见线程池 https://snailclimb.gitee.io/javaguide/#/./docs/java/concurrent/java-thread-pool-summary?id=_52-singlethreadexecutor-%e8%af%a6%e8%a7%a3 2.1 FixedThreadPool FixedThreadPool 被称为可重用固定线程数的线程池。 /** * 创建一个可重用固定数量线程的线程池 */ public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue(), threadFactory); } public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()); } FixedThreadPool 的 corePoolSize 和 maximumPoolSize 都被设置为 nThreads，这个 nThreads 参数是我们使用的时候自己传递的。 运行过程： 如果当前运行的线程数小于 corePoolSize， 如果再来新任务的话，就创建新的线程来执行任务； 当前运行的线程数等于 corePoolSize 后， 如果再来新任务的话，会将任务加入 LinkedBlockingQueue； 线程池中的线程执行完 手头的任务后，会在循环中反复从 LinkedBlockingQueue 中获取任务来执行； 2.1.1 不推荐使用FixedThreadPool FixedThreadPool 使用无界队列 LinkedBlockingQueue（队列的容量为 Integer.MAX_VALUE）作为线程池的工作队列会对线程池带来如下影响 ： 当线程池中的线程数达到 corePoolSize 后，新任务将在无界队列中等待，因此线程池中的线程数不会超过 corePoolSize； 由于使用无界队列时 maximumPoolSize 将是一个无效参数，因为不可能存在任务队列满的情况。所以，通过创建 FixedThreadPool的源码可以看出创建的 FixedThreadPool 的 corePoolSize 和 maximumPoolSize 被设置为同一个值。 由于 1 和 2，使用无界队列时 keepAliveTime 将是一个无效参数； 运行中的 FixedThreadPool（未执行 shutdown()或 shutdownNow()）不会拒绝任务，在任务比较多的时候会导致 OOM（内存溢出）。 2.2 SingleThreadExecutor SingleThreadExecutor 是只有一个线程的线程池。 /** *返回只有一个线程的线程池 */ public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue(), threadFactory)); } public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue())); } 新创建的 SingleThreadExecutor 的 corePoolSize 和 maximumPoolSize 都被设置为 1.其他参数和 FixedThreadPool 相同。 运行过程： 如果当前运行的线程数少于 corePoolSize，则创建一个新的线程执行任务； 当前线程池中有一个运行的线程后，将任务加入 LinkedBlockingQueue; 线程执行完当前的任务后，会在循环中反复从LinkedBlockingQueue 中获取任务来执行； 2.2.1 不推荐使用SingleThreadExecutor SingleThreadExecutor 使用无界队列 LinkedBlockingQueue 作为线程池的工作队列（队列的容量为 Intger.MAX_VALUE）。 SingleThreadExecutor 使用无界队列作为线程池的工作队列会对线程池带来的影响与 FixedThreadPool 相同。说简单点就是可能会导致 OOM， 2.3 CachedThreadPool CachedThreadPool 是一个会根据需要创建新线程的线程池。 /** * 创建一个线程池，根据需要创建新线程，但会在先前构建的线程可用时重用它。 */ public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue(), threadFactory); } public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue()); } CachedThreadPool 的corePoolSize 被设置为空（0），maximumPoolSize被设置为 Integer.MAX.VALUE，即它是无界的，这也就意味着如果主线程提交任务的速度高于 maximumPool 中线程处理任务的速度时，CachedThreadPool 会不断创建新的线程。极端情况下，这样会导致耗尽 cpu 和内存资源。 运行过程： 首先执行 SynchronousQueue.offer(Runnable task) 提交任务到任务队列。如果当前 maximumPool 中有闲线程正在执行 SynchronousQueue.poll(keepAliveTime,TimeUnit.NANOSECONDS)，那么主线程执行 offer 操作与空闲线程执行的 poll 操作配对成功，主线程把任务交给空闲线程执行，execute()方法执行完成，否则执行下面的步骤 2； 当初始 maximumPool 为空，或者 maximumPool 中没有空闲线程时，将没有线程执行 SynchronousQueue.poll(keepAliveTime,TimeUnit.NANOSECONDS)。这种情况下，步骤 1 将失败，此时 CachedThreadPool 会创建新线程执行任务，execute 方法执行完成； 2.3.1 不推荐使用CachedThreadPool CachedThreadPool允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。 2.4 ScheduledThreadPoolExecutor ScheduledThreadPoolExecutor 主要用来在给定的延迟后运行任务，或者定期执行任务。 这个在实际项目中基本不会被用到，也不推荐使用，简单了解一下思想即可。 2.4.1 运行机制 ScheduledThreadPoolExecutor 使用的任务队列 DelayQueue 封装了一个 PriorityQueue，PriorityQueue 会对队列中的任务进行排序： 执行所需时间短的放在前面先被执行(ScheduledFutureTask 的 time 变量小的先执行)， 如果执行所需时间相同则先提交的任务将被先执行(ScheduledFutureTask 的 squenceNumber 变量小的先执行)。 ScheduledThreadPoolExecutor 的执行主要分为2大部分： 当调用 ScheduledThreadPoolExecutor 的 scheduleAtFixedRate() 方法或者 scheduleWithFixedDelay() 方法时，会向 ScheduledThreadPoolExecutor 的 DelayQueue 添加一个实现了 RunnableScheduledFuture 接口的 ScheduledFutureTask 。 线程池中的线程从 DelayQueue 中获取 ScheduledFutureTask，然后执行任务。 2.4.2 执行周期任务的步骤 ScheduledThreadPoolExecutor 为了实现周期性的执行任务，对 ThreadPoolExecutor做了如下修改： 使用 DelayQueue 作为任务队列； 获取任务的方不同； 执行周期任务后，增加了额外的处理。 线程 1 从 DelayQueue 中获取已到期的 ScheduledFutureTask(DelayQueue.take())。到期任务是指 ScheduledFutureTask的 time 大于等于当前系统的时间； 线程 1 执行这个 ScheduledFutureTask； 线程 1 修改 ScheduledFutureTask 的 time 变量为下次将要被执行的时间； 线程 1 把这个修改 time 之后的 ScheduledFutureTask 放回 DelayQueue 中（DelayQueue.add()）。 2.4.3 ScheduledThreadPoolExecutor 和 Timer 的比较 - Timer ScheduledThreadPoolExecutor 对系统时钟的变化 敏感 不敏感 线程数量 只有一个执行线程，因此长时间运行的任务可以延迟其他任务 可以配置任意数量的线程。 此外，如果你想（通过提供 ThreadFactory），你可以完全控制创建的线程; 运行时异常 在TimerTask 中抛出的运行时异常会杀死一个线程，从而导致 Timer 死机:-( ...即计划任务将不再运行。 不仅捕获运行时异常，还允许您在需要时处理它们（通过重写 afterExecute 方法ThreadPoolExecutor）。抛出异常的任务将被取消，但其他任务将继续运行。 综上，在 JDK1.5 之后，你没有理由再使用 Timer 进行任务调度了。 3 Excutor使用 主线程首先要创建实现 Runnable 或者 Callable 接口的任务对象。 把创建完成的实现 Runnable/Callable接口的 对象直接交给 ExecutorService 执行: ExecutorService.execute(Runnable command)或者也可以把 Runnable 对象或Callable 对象提交给 ExecutorService 执行（ExecutorService.submit(Runnable task)或 ExecutorService.submit(Callable task)）。 如果执行 ExecutorService.submit(…)，ExecutorService 将返回一个实现Future接口的对象（我们刚刚也提到过了执行 execute()方法和 submit()方法的区别，submit()会返回一个 FutureTask 对象）。由于 FutureTask 实现了 Runnable，我们也可以创建 FutureTask，然后直接交给 ExecutorService 执行。 3.1 最后，主线程可以执行 FutureTask.get()方法来等待任务执行完成。主线程也可以执行 FutureTask.cancel(boolean mayInterruptIfRunning)来取消此任务的执行。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section9/":{"url":"chapter4/section9/","title":"4.9 threadLocal","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 原理： 使用 threadLocal 可以看成存放变量副本的一个容器，各线程之间放在threadLocal中的变量互不依赖。 使用完 ThreadLocal后 最好手动调用remove()方法，清理掉 key 为 null 的记录，否则在垃圾回收的时候，key (弱引用)会被清理掉，而 value 不会被清理掉，造成内存泄露。 原理： 每个线程实例都有一个ThreadLocalMap类型的成员threadLocals，这个成员存放着键值对，key为ThreadLocal，value为存放的值，若想让一个线程保存多个变量，就需要定义多个Threadlocal类的对象。 //Thread类 public class Thread implements Runnable { //...... //与此线程有关的ThreadLocal值。由ThreadLocal类维护 ThreadLocal.ThreadLocalMap threadLocals = null; //与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护 ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; //...... } //ThreadLocal类 public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } ThreadLocalMap getMap(Thread t) { return t.threadLocals; } 使用 public class ThreadLocalExample implements Runnable{ // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本 private static final ThreadLocal formatter = ThreadLocal.withInitial(() -> new SimpleDateFormat(\"yyyyMMdd HHmm\")); public static void main(String[] args) throws InterruptedException { ThreadLocalExample obj = new ThreadLocalExample(); for(int i=0 ; iThreadLocalMap的hash采用开放地址法: Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section10/":{"url":"chapter4/section10/","title":"4.10 volatile","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 java内存模型（JMM） lock指令 volatile 建议先看：cpu缓存模型 java内存模型（JMM） 在 JDK1.2 之前，Java 的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。 而在当前的 Java 内存模型下，线程可以把变量保存本地内存（native memory,比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。 为了解决这个问题，就需要把变量声明为 volatile，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。 总结 多线程下， 普通变量的读取若是寄存器已有副本（之前已经从主存中读取到寄存器过），则其它线程则直接读取寄存器里的值。 但如果是volatile修饰过的，该变量会强制从主存进行读取。 lock指令 https://www.cnblogs.com/yaowen/p/11240540.html volatile关键字使用的是Lock指令，volatile的作用取决于Lock指令。 工作内存：指代寄存器之类的存储器。 在写(use)之前会锁住主内存中的缓存行，让其它volatile的变量无法use。 可见性： 起到内存屏障的作用，保证了有序性(防止指令重排)。 java内存屏障可以被分为以下几种类型： LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。 在大多数处理器的实现中，StoreLoad屏障是个万能屏障，兼具其它三种内存屏障的功能。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section11/":{"url":"chapter4/section11/","title":"4.11 CAS","keywords":"","body":"CAS CAS不是保证原子的更新，而是使用死循环保证更新成功时候只有一个线程更新，不包括主工作内存的同步。 CAS配合volatile既保证了只有一个线程更新又保证了多个线程更新获得的是最新的值互不影响。 aba问题 考虑如下操作： 并发1（上）：获取出数据的初始值是A，后续计划实施CAS乐观锁，期望数据仍是A的时候，修改才能成功 并发2：将数据修改成B 并发3：将数据修改回A 并发1（下）：CAS乐观锁，检测发现初始值还是A，进行数据修改 上述并发环境下，并发1在修改数据时，虽然还是A，但已经不是初始条件的A了，中间发生了A变B，B又变A的变化，此A已经非彼A，数据却成功修改，可能导致错误，这就是CAS引发的所谓的ABA问题。 解决办法 ABA问题导致的原因，是CAS过程中只简单进行了“值”的校验，再有些情况下，“值”相同不会引入错误的业务逻辑（例如库存），有些情况下，“值”虽然相同，却已经不是原来的数据了。 优化方向：CAS不能只比对“值”，还必须确保的是原来的数据，才能修改成功。 常见实践：“版本号”的比对，一个数据一个版本，版本变化，即使值相同，也不应该修改成功。 /* 如果当前引用为{@code ==}到预期引用且当前戳记等于预期戳记，则以原子方式将引用和戳记的值设置为给定的更新值。 */ public class AtomicStampedReference { public boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) { Pair current = pair; return expectedReference == current.reference && expectedStamp == current.stamp && ((newReference == current.reference && newStamp == current.stamp) || casPair(current, Pair.of(newReference, newStamp))); } private boolean casPair(Pair cmp, Pair val) { return UNSAFE.compareAndSwapObject(this, pairOffset, cmp, val); } } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section12/":{"url":"chapter4/section12/","title":"4.12 哲学家吃饭","keywords":"","body":"哲学家吃饭 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter4/section13/":{"url":"chapter4/section13/","title":"4.13 原子类","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1. CAS 2. Unsafe类 2.1 提供的功能： 3. 原子包装类 3.1 AtomicLong 3.2 LongAdder 问题 选择 4. 原子引用 4.1 原子引用类 4.2 原子时间戳引用类 原子类 https://www.cnblogs.com/9dragon/archive/2019/12/11/12023971.html 1. CAS 约定： compareAndSet: java代码，内部获得旧值和实参传入的期待值进行比较，相同调用本地方法compareAndSwap; compareAndSwap: native代码，操作系统已经实现了cas指令（引用,期待值,新值），底层进行比较和赋值的二合一的原子性操作。 众所周知，cpu为分时复用的，而一个指令只能在一个时间片里执行完成，因此指令是原子性的。 2. Unsafe类 https://www.cnblogs.com/pkufork/p/java_unsafe.html 所有的Atomic**中的compareAndSet内部最终都要调用Unsafe的compareAndSwap，去底层真正地调用cas指令，从而实现了业务层的“免锁”操作。 它里面封装了一些对底层资源的访问，包括直接访问内存、使用cas指令等，但是这个类只允许jdk访问，其他地方使用Unsafe会报错。 要想使用Unsafe类需要用一些比较tricky的办法。Unsafe类使用了单例模式，需要通过一个静态方法getUnsafe()来获取。但Unsafe类做了限制，如果是普通的调用的话，它会抛出一个SecurityException异常；只有由主类加载器加载的类才能调用这个方法。 有一些办法来用主类加载器加载用户代码，比如设置bootclasspath参数。 但更简单方法是利用Java反射，方法如下： Field f = Unsafe.class.getDeclaredField(\"theUnsafe\"); f.setAccessible(true); Unsafe unsafe = (Unsafe) f.get(null); 如果使用unsafe开辟的内存，是不被JVM垃圾回收管理，需要自己管理，容易造成内存泄漏等。 2.1 提供的功能： 内存管理：包括分配内存、释放内存等。 非常规的对象实例化。 操作类、对象、变量。 数组操作。 多线程同步。包括锁机制、CAS操作等。 挂起与恢复。这部分包括了park、unpark等方法。 内存屏障。包括了loadFence、storeFence、fullFence。 3. 原子包装类 以AtomicLong为例，其它Atomic的包装类实现一样。 3.1 AtomicLong 存在ABA问题 AtomicLong的几个重要成员变量： private static final Unsafe unsafe = Unsafe.getUnsafe(); private volatile long value; private static final long valueOffset; AtomicLong是如何利用CAS实现免锁线程安全的： //AtomicLong类 // AtomicLong一个利用CAS更新值的方法：将Atomic的值更新成newValue，返回老的值 public final long getAndSet(long newValue) { // 这里调用的是Unsafe的CAS方法 return unsafe.getAndSetLong(this, valueOffset, newValue); } //Unsafe类 public final long getAndSetLong(Object obj, long valueOffset, long newValue) { long oldValue; do { //通过对象及偏移量获得属性的值。getLongVolatile()是个native防范 oldValue = this.getLongVolatile(obj, valueOffset); // cas来更新值。compareAndSwapLong()方法是个native方法，封装的就是cAS指令 } while(!this.compareAndSwapLong(obj, valueOffset, oldValue, newValue));// cas不成功就在无限重试 return oldValue; } 可以看见如果Unsafe.getAndSetLong中的CAS失败，会无限重试，直到成功为止。极端一点并发特别高，每次CAS失败，那么一个线程就会一致再这疯狂的重试，然后更多的线程进来重试，那么cpu会被瞬间打爆的。 所以说，AtomicLong这种类型，只是适合并发冲突不高的场景。 如果我们要原子更新多个值，可以使用AtomicReference。 3.2 LongAdder https://blog.csdn.net/sinat_14913533/article/details/115588023 https://blog.csdn.net/weixin_43314519/article/details/110195621 存在ABA问题 在AtomicLong的实现中，如果CAS失败，就无限的重试，直到成功为止，但是在LongAdder是想办法尽量减少冲突。 产生冲突的本质原因是多个线程共享一个变量的场景，为了保证对这个变量操作的线程安全，那就必须采取措施，不让多个线程同时操作这个共享变量。一种方式是加锁，这里不多说了。另一种方式就如AtomicLong(cas): AtomicLong的思路: 如果一个线程尝试去操作的时候发现有其他线程正在操作，那我就放弃本次操作，过会再来； LongAdder的思路: 将这个共享变量打散，变成很多碎片，当遇到多个线程同时更改这个变量的时候，给每个线程分配一个碎片，各自更改一个碎片，然后在读取这个变量的时候，将所有的碎片整合到一起，对外部看来，这就是一个变量。 将一个变量分成了n多部分：一个base和m个cell(m+1=n)，其中base和cell背后其实都是一个long型的变量。 当更新LongAdder数据的时候，首先尝试用CAS去更新base，如果没有冲突就会更新成功，就结束了；如果有冲突，就随机选择一个cell，然后用CAS将数据更新到这个cell上；如果也冲突，那就重新换个cell重试；如果还冲突就将cell的个数扩充2倍，然后再重新选一个cell来cas将数据更新到这个cell上。 读取真正的值时，全部累加起来: public long sum() { Cell[] as = cells; Cell a; long sum = base; if (as != null) { for (int i = 0; i 问题 结果累加造成一定延迟； 冲突存在扩容或重试造成一定延迟。 选择 性能 提供的方法 LongAdder 只提供了 add、increment 等简单的方法，适合的是统计求和计数的场景，场景比较单一， AtomicLong 还具有 compareAndSet 等高级方法，可以应对除了加减之外的更复杂的需要 CAS 的场景。 4. 原子引用 4.1 原子引用类 存在ABA问题 java.util.concurrent.atomic.AtomicReference 原子引用其实和原子包装类(AtomicInteger/AtomicLong)是差不多的概念，就是将一个java类，用原子引用类进行包装起来，那么这个类就具备了原子性。 public class ABADemo { /** * 普通的原子引用包装类 */ static AtomicReference atomicReference = new AtomicReference<>(100); public static void main(String[] args) { new Thread(() -> { // 把100 改成 101 然后在改成100，也就是ABA atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); }, \"t1\").start(); new Thread(() -> { try { // 睡眠一秒，保证t1线程，完成了ABA操作 TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } // 把100 改成 101 然后在改成100，也就是ABA System.out.println(atomicReference.compareAndSet(100, 2019) + \"\\t\" + atomicReference.get()); }, \"t2\").start(); } } 例子中，原子引用的泛型可以使用任意java类，如自定义一个User类，可以通过原子引用保证对User更改的原子性（不是内部的setter方法，就只是User，就比如说原来原子引用中存的是User类的a实例，可以原子操作替换成User类的b实例）。 4.2 原子时间戳引用类 https://blog.csdn.net/weixin_42073629/article/details/104872490 java.util.concurrent.atomic.AtomicStampedReference 利用每次更改后添加的时间戳解决了ABA问题。 public class ABADemo { // 传递两个值，一个是初始值，一个是初始版本号 static AtomicStampedReference atomicStampedReference = new AtomicStampedReference<>(100, 1); public static void main(String[] args) { new Thread(() -> { // 获取版本号 int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + \"\\t 第一次版本号\" + stamp); // 暂停t3一秒钟 try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } // 传入4个值，期望值，更新值，期望版本号，更新版本号 atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp()+1); System.out.println(Thread.currentThread().getName() + \"\\t 第二次版本号\" + atomicStampedReference.getStamp()); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp()+1); System.out.println(Thread.currentThread().getName() + \"\\t 第三次版本号\" + atomicStampedReference.getStamp()); }, \"t3\").start(); new Thread(() -> { // 获取版本号 int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + \"\\t 第一次版本号\" + stamp); // 暂停t4 3秒钟，保证t3线程也进行一次ABA问题 try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); } boolean result = atomicStampedReference.compareAndSet(100, 2019, stamp, stamp+1); System.out.println(Thread.currentThread().getName() + \"\\t 修改成功否：\" + result + \"\\t 当前最新实际版本号：\" + atomicStampedReference.getStamp()); System.out.println(Thread.currentThread().getName() + \"\\t 当前实际最新值\" + atomicStampedReference.getReference()); }, \"t4\").start(); } } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter5/section1/":{"url":"chapter5/section1/","title":"5.1 java内存区域（运行时数据区域）","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 程序计数器 Java 虚拟机栈 堆 方法区 常量池 直接内存 java内存区域（运行时数据区域） 程序计数器 （唯一一个不会出现 OutOfMemoryError 的内存区域）： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 Java 虚拟机栈 由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。 会出现两种错误： StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： Java 虚拟机栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 Java 方法有两种返回方式：return 语句和抛出异常。不管哪种返回方式都会导致栈帧被弹出。 堆 并不是所有对象都在堆上进行分配，从 JDK 1.7 开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。 对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入逻辑上的 from区（to区一直保持为空），并且对象的年龄还会加 1(Eden 区->Survivor 区后对象的初始年龄变为 1)， 当它的年龄增加到一定程度（默认为 15 岁，但默认晋升年龄并不都是 15，这个是要区分垃圾收集器的，CMS 就是 6），就会被晋升到老年代中。 对象晋升到老年代的年龄阈值， 可以通过参数 -XX:MaxTenuringThreshold 来设置。 或者Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的一半时，取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值。 容易出现OutOfMemoryError 错误，表现形式： java.lang.OutOfMemoryError: GC Overhead Limit Exceeded ： 当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。 java.lang.OutOfMemoryError: Java heap space :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象（full gc后）, 就会引发此错误。(和配置的最大堆内存有关，且受制于物理内存大小。最大堆内存可通过-Xmx参数配置，若没有特别配置，将会使用默认值，详见：https://stackoverflow.com/questions/28272923/default-xmxsize-in-java-8-max-heap-size) 等 方法区 方法区是 Java 虚拟机规范中的定义，是一种规范。 hotspot永久代是对该标准的实现，1.8后改为在直接内存里划分出一片空间称为元空间进行实现。 存储已被虚拟机加载的： 类信息、 常量、 静态变量、 即时编译器编译后的代码等数据。 设置元空间大小： -XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小） -XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小 与永久代很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。 注意：【字符串常量池被从永久代拿到了堆中，而不是移到了元空间】 常量池 运行时常量池逻辑包含字符串常量池。 字符串常量池在堆，存的是 实际的在编译期间就确定的字符串常量， 或在运行期间创建的字符串常量， 编译期可以确定值的字符串，也就是常量字符串(实际的字符串)，jvm 会将其存入字符串常量池。 运行时常量池在方法区（永久代/元空间） 在类加载到内存后，将class常量池（即.class文件的内容）转移到元空间，原先存储在硬盘上的各种字面量和符号引用都会去找字符串常量池，查看其是否存在相关字符串，有则返回常量池中该字符串的引用，没有则： JDK1.7 之前（不包含 1.7）的处理方式是在字符串常量池中创建与此 String 内容相同的字符串（不是对象），并返回该字符串的引用， JDK1.7 以及之后的处理方式是jvm 不会在常量池中创建该字符串，而是将方法区（String.intern这里是堆）中这个字符串的引用（地址）直接放到常量池中，并返回该引用。 直接内存 直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。 JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 12:10:11 "},"chapter5/section2/":{"url":"chapter5/section2/","title":"5.2 类文件结构","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 魔数 Class 文件版本号 常量池 访问标志 当前类（This Class）、父类（Super Class）、接口（Interfaces）索引集合 字段表集合 方法表集合 属性表集合 类文件结构 .class 文件可以通过 javap -v class类名 指令来看一下其常量池中的信息(javap -v class类名-> temp.txt ：将结果输出到 temp.txt 文件)。 记录了类的版本、字段、方法、接口等描述信息外，还有常量池表（用于存放编译期生成的各种字面量和符号引用）】 class文件中有关修饰符的access_flag：各个修饰符都是布尔值，要么有某个修饰符，要么没有，很适合使用标志位来表示。即用16位二进制（2个字节）可以表述出不同的修饰符的意思。 总结：修饰符用二进制位表示，不能用二进制表示的需要描述的信息被记录在常量池中的“符号引用”中，因此其它地方通过指针一样的引用指向常量池中的“符号引用”，常量池除符号引用之外就是常量（字符串和被final修饰的）。 实质上，常量池的字面量和符号引用的内容都是广义上的“字面量”，就是记录在纸上的东西，数字啊，文字啥的 \\============================================= 根据 Java 虚拟机规范，Class 文件通过 ClassFile 定义，有点类似 C 语言的结构体。 ClassFile { u4 magic; //Class 文件的标志 值是0xCAFEBABE u2 minor_version; //Class 的小版本号 u2 major_version; //Class 的大版本号 u2 constant_pool_count; //常量池的数量 cp_info constant_pool[constant_pool_count-1];//常量池 u2 access_flags; //Class 的访问标记 u2 this_class; //当前类 u2 super_class; //父类 u2 interfaces_count; //接口 u2 interfaces[interfaces_count]; //一个类可以实现多个接口 u2 fields_count; //Class 文件的字段属性 field_info fields[fields_count]; //一个类会可以有多个字段 u2 methods_count; //Class 文件的方法数量 method_info methods[methods_count]; //一个类可以有个多个方法 u2 attributes_count; //此类的属性表中的属性数 attribute_info attributes[attributes_count]; //属性表集合 } 可通过 IDEA 插件 jclasslib 查看。 魔数 u4 magic; //Class 文件的标志 每个 Class 文件的头 4 个字节称为魔数（Magic Number）,它的唯一作用是确定这个文件是否为一个能被虚拟机接收的 Class 文件。 程序设计者很多时候都喜欢用一些特殊的数字表示固定的文件类型或者其它特殊的含义。 Class 文件版本号 可以使用 javap -v 命令来快速查看 Class 文件的版本号信息。 u2 minor_version;//Class 的小版本号 u2 major_version;//Class 的大版本号 第 5 和第 6 位是次版本号，第 7 和第 8 位是主版本号。 每当 Java 发布大版本（比如 Java 8，Java9）的时候，主版本号都会加 1。 高版本的 Java 虚拟机可以执行低版本编译器生成的 Class 文件，反之不行。 常量池 u2 constant_pool_count;//常量池的数量 cp\\_info constant_pool[constant_pool_count-1];//常量池 常量池计数器并不是从0，而是从 1 开始计数的，将第 0 项常量空出来是有特殊考虑的，索引值为 0 代表“不引用任何一个常量池项”。 常量池主要存放两大常量： 字面量：字面量比较接近于 Java 语言层面的的常量概念，如文本字符串、声明为 final 的常量值等。 符号引用：属于编译原理方面的概念。包括下面三类常量： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 常量池中每一项常量都是一个表，这 14 种表有一个共同的特点：开始的第一位是一个 u1 类型的标志位 -tag 来标识常量的类型，代表当前这个常量属于哪种常量类型． 类型 标志（tag） 描述 CONSTANT_utf8_info 1 UTF-8 编码的字符串 CONSTANT_Integer_info 3 整形字面量 CONSTANT_Float_info 4 浮点型字面量 CONSTANT_Long_info 5 长整型字面量 CONSTANT_Double_info 6 双精度浮点型字面量 CONSTANT_Class_info 7 类或接口的符号引用 CONSTANT_String_info 8 字符串类型字面量 CONSTANT_Fieldref_info 9 字段的符号引用 CONSTANT_Methodref_info 10 类中方法的符号引用 CONSTANT_InterfaceMethodref_info 11 接口中方法的符号引用 CONSTANT_NameAndType_info 12 字段或方法的符号引用 CONSTANT_MothodType_info 16 标志方法类型 CONSTANT_MethodHandle_info 15 表示方法句柄 CONSTANT_InvokeDynamic_info 18 表示一个动态方法调用点 访问标志 u2 access_flags;//Class 的访问标记 用于识别一些类或者接口层次的访问信息，包括： 这个 Class 是类还是接口， 是否为 public 或者 abstract 类型， 如果是类的话是否声明为 final 等等。 类访问和属性修饰符: 当前类（This Class）、父类（Super Class）、接口（Interfaces）索引集合 u2 this_class;//当前类 u2 super_class;//父类 u2 interfaces_count;//接口 u2 interfaces[interfaces_count];//一个类可以实现多个接口 类索引，用于确定这个类的全限定名， 父类索引，用于确定这个类的父类的全限定名， 由于 Java 语言的单继承，所以父类索引只有一个，除了 java.lang.Object 之外，所有的 java 类都有父类，因此除了 java.lang.Object 外，所有 Java 类的父类索引都不为 0。 接口索引集合用来描述这个类实现了那些接口，这些被实现的接口将按 implements (如果这个类本身是接口的话则是extends) 后的接口顺序从左到右排列在接口索引集合中。 字段表集合 u2 fields_count;//Class 文件的字段的个数 field_info fields[fields_count];//一个类会可以有个字段 字段表（field info）用于描述接口或类中声明的变量。字段包括类级变量以及实例变量，但不包括在方法内部声明的局部变量。 field_info { u2 access_flags; u2 name_index; //对常量池的引用，表示的字段的名称； u2 descriptor_index; //对常量池的引用，表示字段和方法的描述符； u2 attributes_count; //一个字段还会拥有一些额外的属性，attributes_count 存放属性的个数； attribute_info attributes[attributes_count]; //存放具体属性、具体内容。 } access_flags: 字段的作用域（public ,private,protected修饰符），是实例变量还是类变量（static修饰符）,可否被序列化（transient 修饰符）,可变性（final）,可见性（volatile 修饰符，是否强制从主内存读写）。 上述这些信息中，各个修饰符都是布尔值，要么有某个修饰符，要么没有，很适合使用标志位来表示。即用16位二进制（2个字节）可以表述出不同的修饰符的意思。 而字段叫什么名字、字段被定义成什么数据类型这些都是无法固定的，只能引用常量池中常量来描述。 方法表集合 u2 methods_count;//Class 文件的方法的数量 method_info methods[methods_count];//一个类可以有个多个方法（方法表） 方法表： method_info { u2 access_flags; u2 name_index; //对常量池的引用，表示的字段的名称； u2 descriptor_index; //对常量池的引用，表示字段和方法的描述符； u2 attributes_count; //一个字段还会拥有一些额外的属性，attributes_count 存放属性的个数； attribute_info attributes[attributes_count]; //存放具体属性、具体内容。 } access_flag： 属性表集合 u2 attributes_count;//此类的属性表中的属性数 attribute_info attributes[attributes_count];//属性表集合 Class 文件、字段表、方法表都可以携带自己的属性表集合，以用于描述某些场景专有的信息。 与 Class 文件中其它的数据项目要求的顺序、长度和内容不同，属性表集合的限制稍微宽松一些，不再要求各个属性表具有严格的顺序，并且只要不与已有的属性名重复，任何人实现的编译器都可以向属性表中写 入自己定义的属性信息，Java 虚拟机运行时会忽略掉它不认识的属性。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter5/section3/":{"url":"chapter5/section3/","title":"5.3 类加载过程","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 加载 验证（连接） 准备（连接） 解析（连接） 初始化 卸载（无用的类） 类加载过程 虚拟机加载 Class 类型的文件主要三步：加载->连接->初始化。 连接过程又可分为三步：验证->准备->解析。 加载 将 .class文件加载到内存。 加载阶段和连接阶段的部分内容是交叉进行的，加载阶段尚未结束，连接阶段可能就已经开始了。 类加载过程的第一步，主要完成下面 3 件事情： 通过全类名获取定义此类的二进制字节流; 将字节流所代表的静态存储结构转换为方法区的运行时数据结构; 在内存中生成一个代表该类的 Class 对象（类对象），作为方法区这些数据的访问入口。 虚拟机规范上面这 3 点并不具体，因此是非常灵活的。比如：\"通过全类名获取定义此类的二进制字节流\" 并没有指明具体从哪里获取、怎样获取。比如： 比较常见的就是从 ZIP 包中读取（日后出现的 JAR、EAR、WAR 格式的基础）、 其他文件生成（典型应用就是 JSP）等等。 注： 一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。 数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。 验证（连接） 准备（连接） 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。 需要注意： 内存分配的仅包括类变量，实例变量会在对象实例化时随着对象一块分配在 Java 堆中。 从概念上讲，类变量所使用的内存都应当在 方法区 中进行分配。不过有一点需要注意的是： JDK 7 之前，HotSpot 使用永久代来实现方法区的时候，实现是完全符合这种逻辑概念的。 JDK 7 及之后，HotSpot 已经把原本放在永久代的字符串常量池、静态变量等移动到堆中，这个时候类变量则会随着 Class 对象一起存放在 Java 堆中。 这里所设置的初始值\"通常情况\"下是数据类型默认的零值（如 0、0L、null、false 等），比如:我们定义了public static int value=111 ， 那么 value 变量在准备阶段的初始值就是 0 而不是 111（初始化阶段才会赋值）。 特殊情况：比如给 value 变量加上了 final 关键字public static final int value=111 ，那么准备阶段 value 的值就被赋值为 111。 基本数据类型的零值 ： (图片来自《深入理解 Java 虚拟机》第 3 版 7.33 ) 解析（连接） 将常量池内的符号引用替换为直接引用的过程。 符号引用就是一组符号来描述目标，可以是任何广义上的字面量。 直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 主要针对7 类符号引用进行： 类或接口、 字段、 类方法、 接口方法、 方法类型、 方法句柄 调用限定符 在程序实际运行时，只有符号引用是不够的，举个例子：在程序执行方法时，系统需要明确知道这个方法所在的位置。Java 虚拟机为每个类都准备了一张方法表来存放类中所有的方法。当需要调用一个类的方法的时候，只要知道这个方法在方法表中的偏移量就可以直接调用该方法了。通过解析操作符号引用就可以直接转变为目标方法在类中方法表的位置，从而使得方法可以被调用。 综上，解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。 初始化 类加载的最后一步：执行初始化方法 ()方法（编译之后自动生成的）的过程。 JVM 开始真正执行类中定义的 Java 程序代码(字节码)。 对于()方法的调用，虚拟机会自己确保其在多线程环境中的安全性。因为()方法是带锁线程安全，所以在多线程环境下进行类初始化的话可能会引起多个进程阻塞，并且这种阻塞很难被发现。 虚拟机严格规范了有且只有 6种情况下，必须对类进行初始化(只有主动去使用类才会初始化类)： 当遇到 new 、 getstatic、putstatic 或 invokestatic 这 4 条直接码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。 当 jvm 执行 new 指令时会初始化类。即当程序创建一个类的实例对象。 当 jvm 执行 getstatic 指令时会初始化类。即程序访问类的静态变量(不是静态常量，常量会被加载到运行时常量池)。 当 jvm 执行 putstatic 指令时会初始化类。即程序给类的静态变量赋值。 当 jvm 执行 invokestatic 指令时会初始化类。即程序调用类的静态方法。 使用 java.lang.reflect 包的方法对类进行反射调用时如 Class.forname(\"...\"), newInstance() 等等。如果类没初始化，需要触发其初始化。 初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。 当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的那个类)，虚拟机会先初始化这个类。 MethodHandle 和 VarHandle 可以看作是轻量级的反射调用机制，而要想使用这 2 个调用，就必须先使用 findStaticVarHandle 来初始化要调用的类。 当一个接口中定义了 JDK8 新加入的默认方法（被 default 关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。 卸载（无用的类） 卸载类：即该类的 Class 对象（类对象）被 GC。 卸载类需要满足 3 个要求: 该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。 该类没有在其他任何地方被引用 该类的类加载器的实例已被 GC 所以，在 JVM 生命周期内，由 jvm 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。 只要想通一点就好了，jdk 自带的 BootstrapClassLoader, ExtClassLoader, AppClassLoader 负责加载 jdk 提供的类，所以它们(类加载器的实例)肯定不会被回收。而我们自定义的类加载器的实例是可以被回收的，所以使用我们自定义加载器加载的类是可以被卸载掉的。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 12:15:14 "},"chapter5/section4/":{"url":"chapter5/section4/","title":"5.4 类加载器","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 双亲委派模型 双亲委派模型实现源码 双亲委派模型的好处 避免双亲委托机制 类加载器 JVM 中内置了三个重要的 ClassLoader，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader（自定义类加载器也是继承这个）： BootstrapClassLoader(启动类加载器) ：最顶层的加载类，由 C++实现，负责加载 %JAVA_HOME%/lib目录下的 jar 包和类或者被 -Xbootclasspath参数指定的路径中的所有类。 ExtensionClassLoader(扩展类加载器) ：主要负责加载 %JRE_HOME%/lib/ext 目录下的 jar 包和类，或被 java.ext.dirs 系统变量所指定的路径下的 jar 包。 AppClassLoader(应用程序类加载器)：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。 双亲委派模型 每一个类都有一个对应它的类加载器。系统中的 ClassLoader 在协同工作的时候会默认使用 双亲委派模型 。即在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，首先会把该请求委派给父类加载器的 loadClass() 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 BootstrapClassLoader 中。当父类加载器无法处理时，才由自己来处理。当父类加载器为 null 时，会使用启动类加载器 BootstrapClassLoader 作为父类加载器。 类加载器之间的“父子”关系也不是通过继承来体现的，是由“优先级”来决定。 public class ClassLoaderDemo { public static void main(String[] args) { System.out.println(\"ClassLodarDemo's ClassLoader is \" + ClassLoaderDemo.class.getClassLoader()); System.out.println(\"The Parent of ClassLodarDemo's ClassLoader is \" + ClassLoaderDemo.class.getClassLoader().getParent()); System.out.println(\"The GrandParent of ClassLodarDemo's ClassLoader is \" + ClassLoaderDemo.class.getClassLoader().getParent().getParent()); } } output: ClassLodarDemo's ClassLoader is sun.misc.Launcher$AppClassLoader@18b4aac2 The Parent of ClassLodarDemo's ClassLoader is sun.misc.Launcher$ExtClassLoader@1b6d3586 The GrandParent of ClassLodarDemo's ClassLoader is null AppClassLoader的父类加载器为ExtClassLoader， ExtClassLoader的父类加载器为 null，null 并不代表ExtClassLoader没有父类加载器，而是 BootstrapClassLoader。 双亲委派模型实现源码 双亲委派模型的实现代码非常简单，逻辑非常清晰，都集中在 java.lang.ClassLoader 的 loadClass() 中，相关代码如下所示： private final ClassLoader parent; protected Class loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // 首先，检查请求的类是否已经被加载过 Class c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) {//父加载器不为空，调用父加载器loadClass()方法处理 c = parent.loadClass(name, false); } else {//父加载器为空，使用启动类加载器 BootstrapClassLoader 加载 c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { //抛出异常说明父类加载器无法完成加载请求 } if (c == null) { long t1 = System.nanoTime(); //自己尝试加载 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } 双亲委派模型的好处 双亲委派模型保证了 Java 程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了 Java 的核心 API 不被篡改。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 java.lang.Object 类的话，那么程序运行的时候，系统就会出现多个不同的 Object 类。 避免双亲委托机制 自定义加载器的话，需要继承 ClassLoader 。 如果不想打破双亲委派模型，就重写 ClassLoader 类中的 findClass() 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。 如果想打破双亲委派模型则需要重写 loadClass() 方法（重写方法内部不调用父亲的loadClass即可） Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter5/section5/":{"url":"chapter5/section5/","title":"5.5 创建对象","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 创建过程 类加载检查： 分配内存： 初始化零值: 设置对象头 执行 init 方法 对象内存分布 对象头 指针压缩 锁升级过程 锁优化总结 定位对象的方式 创建对象 创建过程 类加载检查： 虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 分配内存： 在堆中为对象分配内存，类加载完成后可以确定对象大小， 分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 标记整理、标记复制： 标记清除： 分配内存并发问题： CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配。 初始化零值: 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 设置对象头 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如 这个对象是哪个类的实例、 如何才能找到类的元数据信息、 对象的哈希码、 对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 执行 init 方法 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始， 方法(构造方法)还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 对象内存分布 在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：对象头、对象体(实例数据)和对齐填充。 对象头包括两部分信息， 用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志等等）， 类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。 实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容, 保存对象属性和值的主体部分，占用内存空间取决于对象的属性数量和类型； 起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 为了减少堆内存的碎片空间（不一定准确） 对象头 对象头中的Mark Word（标记字）主要用来表示对象的线程锁状态，另外还可以用来配合GC、存放该对象的hashCode； Klass Word（类指针）是一个指向方法区中Class信息的指针，意味着该对象可随时知道自己是哪个Class的实例，该指针的位长度为JVM的一个字大小，即32位的JVM为32位，64位的JVM为64位； 记录数组长度也为JVM的一个字大小，即32位的JVM为32位，64位的JVM为64位，这是可选的，只有当本对象是一个数组对象时才会有这个部分；该区域长度也可由64位压缩至32位。 指针压缩 为了节约内存可以使用选项+UseCompressedOops开启指针压缩，其中，oop即ordinary object pointer普通对象指针。 开启该选项后，下列指针将压缩至32位： 每个Class的属性指针（即静态变量） 每个对象的属性指针（即对象变量） 普通对象数组的每个元素指针 当然，也不是所有的指针都会压缩，一些特殊类型的指针JVM不会优化，比如指向PermGen的Class对象指针(JDK8中指向元空间的Class对象指针)、本地变量、堆栈元素、入参、返回值和NULL指针等。 锁升级过程 epoch[ˈepək]：纪元 存储内容 biased_lock lock位 mark word含义 对象的hashcode，gc分代年龄 0 01 无锁 偏向线程ID，偏向线程时间戳(epoch)，gc分代年龄 1 01 偏向锁 指向栈中锁记录的指针 00 轻量级锁 指向对象监视器Monitor的指针 10 重量级锁 无 11 gc标记 hashcode采用延迟加载技术。调用方法System.identityHashCode()计算，并会将结果写到该对象头中。当对象加锁后（偏向、轻量级、重量级），MarkWord的字节没有足够的空间保存hashCode，因此该值会移动到管程Monitor中。 jvm使用synchronized为了提高效率，不会一开始就使用重量级锁，JVM在内部会根据需要，按如下步骤进行锁的升级： 优化synchronized的目的是为了提高获得锁和释放锁的效率。 初期锁对象刚创建时，还没有任何线程来竞争，该对象处于无锁状态。 当有一个线程来竞争锁时(54位线程id全是0，表明此前无线程来获得该锁)，先用偏向锁，表示锁对象偏爱这个线程，这个线程要执行这个锁关联的任何代码，不需要再做任何检查和切换，这种竞争不激烈的情况下，效率非常高。 当有两个线程开始竞争这个锁对象，情况发生变化了（54位线程ID已经不为0了说明已有线程正持有锁，此时再来线程，产生竞争关系），不再是偏向（独占）锁了，锁会升级为轻量级锁，两个线程公平竞争，哪个线程先占有锁对象并执行代码，锁对象的Mark Word就指向哪个线程的栈帧中的锁记录。 如果竞争的这个锁对象的线程更多，导致了更多的切换和等待，JVM会把该锁对象的锁升级为重量级锁，这个就叫做同步锁，这个锁对象Mark Word再次发生变化，会指向一个监视器对象，这个监视器对象用集合的形式，来登记和管理排队的线程。 锁优化总结 https://www.jianshu.com/p/36eedeb3f912 自旋锁 使用-XX:-UseSpinning参数关闭自旋锁优化； -XX:PreBlockSpin参数修改默认的自旋次数。 前提：锁的持有时间比较短，对于线程而言，因为锁阻塞造成线程切换的时间与锁持有的时间相当，减少线程阻塞造成的线程切换，能得到较大的性能提升，因此出现了自旋锁。 当前线程竞争锁失败时，不直接阻塞自己，而是自旋一会（空等待，比如一个空的有限次数for循环） 在自旋的同时重新竞争锁，如果自旋结束前获得了锁，那么锁获取成功； 否则，自旋结束后阻塞自己 自旋锁的目标是降低线程切换的成本。 锁持有时间长，且竞争激烈的场景中，此时应主动禁用自旋锁。【因为自旋通常不能获得锁，白白浪费了自旋占用的CPU时间】 自适应自旋锁 自适应意味着自旋的时间不再固定了，它假定不同线程持有同一个锁对象的时间基本相当，竞争程度趋于稳定，因此，可以根据上一次自旋的时间与结果调整下一次自旋的时间。 偏向锁 无竞争 “偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），因此，只需要在Mark Word中CAS记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁。 偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定。（因为自旋锁的前提就是有竞争，偏向锁假定就是没有竞争） 轻量级锁 无实际竞争 使用轻量级锁时，不需要申请互斥量（即不需要竞争锁对象），仅仅将Mark Word中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁； 此时本应有两个线程在竞争，只是刚好另外一个线程的指针指向cas重置了，当前线程cas更新成功 否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。 由于轻量级锁天然瞄准不存在锁竞争的场景，如果存在锁竞争但不激烈，仍然可以用自旋锁优化，自旋失败后再膨胀为重量级锁。 定位对象的方式 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有① 使用句柄和② 直接指针两种： 这两种对象访问方式各有优势。 使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。 使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 12:30:35 "},"chapter5/section6/":{"url":"chapter5/section6/","title":"5.6 jvm垃圾回收","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 分配对象时触发gc minor gc和major gc 总结 gc时判断哪些对象需要清理 引用计数法 可达性分析法 强、软、弱、虚引用 真正gc对象的时机 清理常量和类 gc算法 标记清除 标记复制 标记整理 分代收集（young复制old清除或整理） gc收集器 jvm垃圾回收 从垃圾回收的角度，由于现在收集器基本都采用分代收集算法，因此堆被分为：新生代和老年代。 分配对象时触发gc 一般对象在eden区分配 而大对象直接进入老年代（为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率） 大对象就是需要大量连续内存空间的对象（比如：字符串、数组） minor gc和major gc minor gc： 发生在新生代的GC。 发生时机： 如果新生的对象无法在 Eden 区创建（Eden 区无法容纳) 就会触发一次Young GC（minor gc别名）。 将 from 区与Eden 区的对象一起进行可达性分析，找出活跃的对象，将它复制到 to 区并且将eden区域和 from 区的对象给清空，这样那些不可达的对象进行清除，并且将from 区 和 to区交换(保证逻辑的to区为空)。 major gc： 发生在老年代的GC。 发生时机： 对于一个对象，我们会首先在Eden 尝试创建，如果创建不了，就会触发Minor GC 随后继续尝试在Eden区存放，发现仍然放不下 尝试直接进入老年代，老年代也放不下 触发 Major GC 清理老年代的空间 放的下 成功 放不下 OOM 通过上面的步骤，发现如果发生了major gc，那么之前必然也发生了minor gc。 而full gc指的是清理包括新生代、老年代、永久代（如果存在）的空间。 如果major gc发生了的话，表示清理了老年代，再加上之前发生的minor gc清理的新生代，而java8之后堆不再存在永久代，因此可以说，major gc通常和full gc等价。 总结 针对 HotSpot VM 的实现，它里面的 GC 其实准确分类只有两大种： 部分收集 (Partial GC)： 新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集； 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集； 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。 整堆收集 (Full GC)：收集整个 Java 堆和方法区。 gc时判断哪些对象需要清理 死亡的对象需要清理，有两种方法判断对象是否死亡。 引用计数法 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。（无法解决相互循环引用） 可达性分析法 通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。 可作为 GC Roots 的对象包括下面几种: 虚拟机栈(栈帧中的本地变量表)中引用的对象(局部变量) 本地方法栈(Native 方法)中引用的对象 方法区中类静态属性引用的对象(static) 方法区中常量引用的对象(final) 所有被同步锁持有的对象（锁对象） 强、软、弱、虚引用 强引用：日常使用的普通引用，不会被回收，如果gc后仍空间不够，宁愿抛出oom. 软引用：空间够，不回收；空间不够，回收。 弱引用：只要gc就回收。 虚引用：随时都有可能被回收，主要用来跟踪对象被垃圾回收的活动。 软、弱、虚引用都可以配合一个引用队列一起使用，如果引用的对象被垃圾回收，Java 虚拟机就会把这个引用加入到与之关联的引用队列中。 软引用的作用： 可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 虚引用的作用： 当垃圾回收器准备回收一个对象时(无Gcroots引用链)，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 真正gc对象的时机 对象不可达后，第1次标记； finalize还没有执行过，需要执行（对象覆盖了finalize方法或者没被虚拟机执行过默认的finalize方法，后者有可能无法被执行，直接将对象进行回收【finalize最多被虚拟机执行一次】），第2次标记， 两次标记后gc。GC在回收对象之前调用finalize，执行finalize方法完毕后，GC会再次判断该对象是否可达，若不可达，则进行回收，否则，对象“复活”。 如上面虚引用说过的，如果发现了某个对象即将被回收（无论是第1次标记还是第2次），反正虚引加入了相关联的引用队列，那么可以通过找到这个虚引用指向的对象的类，重写其finalize，让这个对象与引用链上的任何一个对象建立关联，那么当虚拟机执行finalize的时候，该对象复活了。 清理常量和类 废弃常量 假如在字符串常量池中存在字符串 \"abc\"，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 \"abc\" 就是废弃常量，如果这时发生内存回收的话而且有必要的话，\"abc\" 就会被系统清理出常量池了。 无用的类 同时满足以下3个条件，就可以被回收了，但不一定。 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 gc算法 标记清除 标记复制 标记整理 先标记清除，然后让所有存活的对象向一端移动（如下图左上方向），然后直接清理掉端边界以外的内存。 分代收集（young复制old清除或整理） 新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。 老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 gc收集器 gc算法的具体实现。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter5/section7/":{"url":"chapter5/section7/","title":"5.7 JIT编译器","keywords":"","body":"JIT编译器 简述 即时编译器（JIT） Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 12:08:32 "},"chapter6/section1/":{"url":"chapter6/section1/","title":"6.1 IOC","keywords":"","body":"IOC 依赖注入（setter注入）和构造注入（构造方法注入，赋值顺序有要求） 如果要求Bean B必须要在Bean A之前初始化，而B又不是A的属性，因此无法向A中注入B来保证在加载配置文件时首先完成对B的创建，这时spring为元素提供了depends-on属性来指定前置依赖的bean。 还有作用域之类的， Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 12:39:49 "},"chapter6/section2/":{"url":"chapter6/section2/","title":"6.2 AOP","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 使用实例 增强执行顺序 AOP实现原理 注册 获得代理类 AOP使用 多个切面类切同一个方法，哪个切面类中的增强器先执行？ AOP使用场景 AOP AOP功能可以通过JavaSE动态代理和字节码生成实现 spring的AOP功能是通过JavaSE动态代理和cglib实现的 JavaSE动态代理：一个类需要实现了某个接口，才能在运行期间动态的构造这个接口的实现对象，通过反射实现。 cglib：本身是动态字节码生成工具，可以对没有实现业务接口的对象进行增强。 是Spring AOP配置的根元素，其中有个属性为proxy-target-class 如果为true,则使用cglib生成代理对象，相反为false， 默认如果目标类实现了接口，选择用jdk动态代理，没有实现接口就采用cglib生成一个被代理对象的子类来作为代理。 可以用注解配置Spring AOP 使用实例 导入aop模块：Spring AOP：（spring-aspects） 定义一个业务逻辑类（MathCalculator）；在业务逻辑运行的时候将日志进行打印（方法之前、方法运行结束、方法出现异常等) 定义一个日志切面类（LOgAspects）；切面类里面的方法需要动态感知MathCalculator.div运行到哪里然后执行对应的切面方法； 通知方法： 前置通知(@Before)：logStart:在目标方法div()运行之前运行 后置通知(@After)：logEnd：在目标方法div()运行结束之后运行 返回通知(@AfterReturning)：logReturn：在目标方法div()正常返回之后运行 异常通知(@AfterThrowing)：logException：在目标方法div()出现异常之后运行 环绕通知：动态代理，手动推进目标方法运行（joinPoint.procced()） 给切面类的目标方法标注何时何地运行（通知注解） 将切面类和业务逻辑类（目标方法所在类）都加入到容器中； 必须告诉Spring哪个类是切面类（给切面类上加一个注解：@Aspect） ※给配置类中加@EnableAspectJAutoProxy 开启基于注解的AOP模式 在Spring中很多的@EnableXXX都是表示要开启XXX功能 主要三步： 将业务逻辑组件和切面类都加入到容器中；告诉Spring哪个类是切面类（@Aspect） 在切面类上的每一个通知方法上标注通知注解，告诉Spring何时何地运行（切入点表达式） 开启基于注解的AOP模式；@EnableAspectJAutoProxy @EnableAspectJAutoProxy @Configuration public class MainConfigOfAop { //业务逻辑类加入到容器中 @Bean public MathCalculator mathCalculator() { System.out.println(\"mathCalculator bean\"); return new MathCalculator(); } //切面类加入到容器中 @Bean public LogAspects logAspects() { return new LogAspects(); } } public class MathCalculator { public int div(int i, int j) { System.out.println(\"MathCalculator >> div\"); return i / j; } } @Aspect public class LogAspects { //抽取公共的切入点表达式 //1、本类引用 //2、其他的切面引用 @Pointcut(\"execution(public int com.spring.aop.MathCalculator.*(..))\") private void pointCut(){}; //@Before在目标方法之前切入；切入点表达式（指定在哪个方法切入） //JoinPoint一定要出现在参数列表的第一位 @Before(value = \"pointCut()\") public void logStart(JoinPoint joinpoint) { System.out.println(\"logStart>>>>\"+joinpoint.getSignature().getName()+\">>>>\"+Arrays.toString(joinpoint.getArgs())); } @After(value =\"com.spring.aop.LogAspects.pointCut()\") public void logEnd(JoinPoint joinpoint) { System.out.println(\"logEnd>>>>>\"+joinpoint.getSignature().getName()+\">>>>\"+Arrays.toString(joinpoint.getArgs())); } @AfterReturning(value =\"execution(public int com.spring.aop.MathCalculator.*(..))\",returning=\"object\") public void logReturn(Object object) { System.out.println(\"logReturn>>>>\"+object); } @AfterThrowing(value = \"execution(public int com.spring.aop.MathCalculator.*(..))\",throwing = \"object\") public void logException(Exception object) { System.out.println(\"logException>>>>\"+object); } } public class IOCTestAOP { @Test public void test01() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAop.class); MathCalculator mathCalculator = applicationContext.getBean(MathCalculator.class); mathCalculator.div(10, 0); applicationContext.close(); } } 增强执行顺序 对于一个切面中多个不同Advice的执行顺序，是由对应增强器的invoke方法本身实现的，具体顺序如下所示： 目标方法正常执行： @Around前 ->@Before ->执行方法 -> @Around后 -> @After -> @AfterReturning 目标方法抛异常： @Around前 ->@Before ->方法报错 -> @After -> @AfterThrowing AOP实现原理 注册 Spring容器启动时，全局搜索启动AOP的自定义标签， 自定义标签包括所有已存在的标签都有个解析parse方法，aop也不例外， 定位到注册该自定义标签的解析类AopNamespaceHandler中的parse方法。 其中注册了类为AnnotationAwareAspectJAutoProxyCreator的BeanDefinition BeanDefinition为类，起标识作用。 处理proxy-target-class跟expose-proxy（以key-value的形式放入BeanDefinition的propertyValues属性中） 若有多个切面类，Spring容器启动时会按照你配置的方式（在XML中以Bean标签的形式配置或者在切面类上加注解的方式）将这多个切面类一齐作为一个BeanDefinition加载注册到容器中， 获得代理类 其中AnnotationAwareAspectJAutoProxyCreator类“继承”了BeanPostProcessor接口，其中有个postProcessorAfterInitialization方法。 此方法的执行时机是spring容器启动，初始化所有bean后， 即IOC的实现，getBean时，初始化完Bean对象之后。 该方法会判断该类中是否有被代理（AOP就是代理实现的），如果有代理，则会生成该类的对象的代理对象并返回。 postProcessorAfterInitialization方法，关键点有两处： getAdvicesAndAdvisorsForBean方法获取到所有增强，以Object[]的形式存放； 遍历所有的bean(),校验每一个beanName对应的type，如果有AspectJ的注解，则通过advisorFactory.getAdvisor(factory)方法获取此切面类下的所有增强方法（先找到有Advice类注解(如@Before、@Around等)的方法，然后给每一个切点生成对应PointCut对象，用InstantiationModelAwarePointcutAdvisorImpl统一封装，并对不同的PoinCut使用对应的增强器初始化（如@Before对应AspectJMethodBeforeAdvice）增强器），以List形式存放。其中，切面中每个增强+对应的PointCut对应一个Advisor。 然后筛选获取到的所有增强器，只取到与当前bean相关的Advisor。 注：由此可知，若有多个切面类增加同一个方法，其以类为单位的增强的调用顺序由bean注册进spring容器的顺序决定。 createProxy方法针对增强创建代理，最终postProcessorAfterInitialization方法返回的对象就是这个创建的代理对象，而此代理对象最后就成了getBean方法获取到的对象。 先创建了AopProxyFactory，再创建AopProxy（创建AopProxy时，会根据配置项或者代理类的特性选择是Jdk还是Cglib），最后通过getProxy方法获得代理对象。 如果该类在上一步扫描时被多个Advisor增强了，则将其封装进此代理对象的属性AdvisedSupport advised中。 AOP使用 假设该AOP选择jdk动态代理，那么所有的增强都会在invoke方法进行处理，其中夹杂着真正的对象的方法的调用（反射的method.invoke）。 代理的invoke方法中两个重要的点： 处理exposeProxy：如果之前解析到的exposeProxy为true，则通过AopContext.setCurrentProxy(proxy)，在代码中使用AopContext.getCurrentProxy才能获取到当前的代理对象。 拦截器链（即增强）的调用：在invoke方法中，将当前方法的所有拦截器都封装进ReflectiveMethodInvocation中，调用其proceed()方法，使所有拦截器生效。不同的增强器，如@Before、@After，他们的执行顺序由他们自身功能来控制。 多个切面类切同一个方法，哪个切面类中的增强器先执行？ AOP实现原理中可知AOP中没有规定不同切面的执行顺序，都是把切面打乱放进了List中，但从放入List中的顺序追溯， 可知对应的是Spring加载类后注册BeanDefinition的顺序，即Spring注册BeanDefinition的顺序。而此顺序有两个方法控制， 一个是在切面类上加@Order(123)注解，后面的数字越小越早加载； 另一个是切面类实现Ordered接口，重写getOrder方法，返回的值越小越早加载。 AOP使用场景 事务管理：https://www.cnblogs.com/xss512/p/10944697.html 日志管理：上面已经演示过了 权限控制：https://www.cnblogs.com/sxkgeek/p/9985929.html 不过我用的shiro来权限控制 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 12:42:09 "},"chapter6/section3/":{"url":"chapter6/section3/","title":"6.3 事务","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 隔离级别 传播行为 事务 Spring支持： 编程式事务管理 声明式事务管理 两种方式。 声明式事务管理也有两种常用的方式： 一种是基于tx和aop名字空间的xml配置文件， 另一种就是基于@Transactional注解。 无论采用XML文件还是注解来配置事务，都需要完成下列步骤： 配置数据源； 配置事务管理器； 配置事务增强； 配置事务增强的切面。 xml文件： 注解式： 在要进行事务管理的方法前加上如@Transactional(propagation= Propagation.REQUIRED) 在配置文件中指定驱动： 隔离级别 注： 脏读：事务B修改了某条数据行，还未提交，说不定之后还要修改，但在再次修改之前，事务A访问了这条数据行。 不可重复读：事务A第一次读取了某条数据行并未提交，然后事务B修改了该数据行并进行提交，事务A再次进行读取该数据行，发现数据发生了变化。 幻读：事务A第一次读取了5条数据，之后再执行同样的sql语句第二次读取，数据量少了或者多了。 TransactionDefinition.ISOLATION_DEFAULT :使用后端数据库默认的隔离级别， MySQL 默认采用的 REPEATABLE_READ 隔离级别 Oracle 默认采用的 READ_COMMITTED 隔离级别 TransactionDefinition.ISOLATION_READ_UNCOMMITTED :最低的隔离级别，使用这个隔离级别很少，因为它允许读取尚未提交的数据变更， 读未提交可能会导致脏读、不可重复读、幻读。 TransactionDefinition.ISOLATION_READ_COMMITTED : 允许读取并发事务已经提交的数据， 读提交可以阻止脏读， 可能会导致不可重复读、幻读。 TransactionDefinition.ISOLATION_REPEATABLE_READ : 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改， 重复读可以阻止脏读、不可重复读， 可能会导致幻读。 TransactionDefinition.ISOLATION_SERIALIZABLE : 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说， 串行可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 mysql的innodb实现重复读级别时，解决了幻读【查看】。 传播行为 为了解决业务层方法之间互相调用的事务问题。 当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行。 正确的事务传播行为可能的值如下: TransactionDefinition.PROPAGATION_REQUIRED 使用的最多的一个事务传播行为，我们平时经常使用的@Transactional注解默认使用就是这个事务传播行为。如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。 TransactionDefinition.PROPAGATION_REQUIRES_NEW 创建一个新的事务，如果当前存在事务，则把当前事务挂起。也就是说不管外部方法是否开启事务，Propagation.REQUIRES_NEW修饰的内部方法会新开启自己的事务，且开启的事务相互独立，互不干扰。 TransactionDefinition.PROPAGATION_NESTED 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。 TransactionDefinition.PROPAGATION_MANDATORY（很少使用） 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性） 若是错误的配置以下 3 种事务传播行为，事务将不会发生回滚： TransactionDefinition.PROPAGATION_SUPPORTS: 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED: 以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER: 以非事务方式运行，如果当前存在事务，则抛出异常。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter6/section4/":{"url":"chapter6/section4/","title":"6.4 maven打包","keywords":"","body":"maven打包 因为是用的springboot的maven插件打的jar包，所以它会默认去找启动类，如果要打的包不需要启动类，那首先最好是把当前模块中的所有main方法注释，再 org.springframework.boot spring-boot-maven-plugin NONE exec layout标签是指明不需要main方法，然后如果只有这一个标签还是不行，如果你试着打包的话，会发现打的jar包，当前项目的类都在一个BOOT-INF的目录下，如果有要依赖当前模块的模块要打jar包的话，会报compile错误，也就是报找不到依赖的类，所以在当前模块还要加上classifier这个标签并配置exec，把当前模块依赖的和本身的类的jar包分开，这样就行了，classifier具体作用不清楚，找个时间仔细看一下maven的各种插件， Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter6/section5/":{"url":"chapter6/section5/","title":"6.5 springMVC参数绑定","keywords":"","body":"springMVC参数绑定 springMVC参数绑定 简单类型绑定，方法形参名和前台参数名一样 不一样，使用@RequestParam 对象类，其属性是基本类型，前台参数名需和对象属性名一样，方法形参为对象 如果有转换错误的，需自定义转换器，并配置，如Date类 对象类，其属性有是对象类的，和③一样，比如A类里有属性B类对象b，B类里有属性是基本类型c，前台参数写b.c，方法形参为A类对象a，可以将b封装到a中 数组，前台有多个相同name参数，方法形参可直接采用数组接收，名字同① List，方法形参为List alist，前台参数为alist[index].b(c,d)，其中b，c，d为alist的泛形对象的属性名 Map，再百度 注意: 第7和8有点错误，list和map，如果方法形参直接采用list或map来接收，这样的方式是不行的，会报异常: Could not instantiate bean class [java.util.List]: Specifiedclass is an interface 必须得新建一个包装类专门来包装类似的需要接收的list参数 前台参数名：user.contactList[0].phone，方法形参名：User user,这里User为“包装类” 为什么直接不行？ 因为spring mvc 中获取参数的方式不管有多少种，他的本质依然是 request.getParameter(\"name\") 那把这个参数封装到一个对象中，也只能是同setter方法，那问题的关键是如何找到这个setter方法？肯定是setName中的name和request中的name对应。这才能找到。你想，如果你单纯接收一个list参数，list虽然有get和set方法，但是没有名字呀，只能根据数组下标来判断参数位置。所以只能通过第二种方法进行参数传递. 当然方法形参也可以直接用list，只要前台是用ajax的json类型传来，那么方法形参的list可以用@RequestBody来解释json，具体百度 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter6/section6/":{"url":"chapter6/section6/","title":"6.6 springCache","keywords":"","body":"springCache @Cacheable({\"gao\"})，保存在gao的缓存位置，key为方法参数，value为返回值 @CacheEvict(value=\"andCache\",allEntries=true),清除保存在andCache缓存位置的所有缓存 @CachePut也可以声明一个方法支持缓存功能。与@Cacheable不同的是使用@CachePut标注的方法在执行前不会去检查缓存中是否存在之前执行过的结果，而是每次都会执行该方法，并将执行结果以键值对的形式存入指定的缓存中。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter6/section7/":{"url":"chapter6/section7/","title":"6.7 springMVC","keywords":"","body":"springMVC http://www.51gjie.com/javaweb/909.html Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter6/section8/":{"url":"chapter6/section8/","title":"6.8 web.xml内的标签加载顺序","keywords":"","body":"web.xml内的标签加载顺序 https://blog.csdn.net/qq_22075041/article/details/78692780 当启动一个WEB项目容器时，容器包括(JBoss,Tomcat等)。首先会去读取web.xml配置文件里的配置。 顺序为： -> -> -> 流程 启动WEB项目的时候，容器首先会去读取web.xml配置文件中的两个节点： 和 。 容器创建中的类实例，根据配置的class类路径来创建监听，在监听中会有初始化方法，启动Web应用时，系统调用Listener的该方法 contextInitialized(ServletContextEvent args)，在这个方法中获得： //容器创建一个ServletContext(application),这个web项目的所有部分都将共享这个上下文。 ServletContext application =ServletContextEvent.getServletContext(); //容器以的name作为键，value作为值，将其转化为键值对，存入ServletContext context-param的值 = application.getInitParameter(\"context-param的键\"); 注：ServletConfig获取配置参数的方法和ServletContext获取配置参数的方法完全一样，只是ServletConfig是取得当前Servlet的配置参数，而ServletContext是获取整个web应用的配置参数。 得到这个context-param的值之后，你就可以做一些操作了。 　　举例： 你可能想在项目启动之前就打开数据库，那么这里就可以在中设置数据库的连接方式（驱动、url、user、password），在监听类中初始化数据库的连接。这个监听是自己写的一个类，除了初始化方法，它还有销毁方法，用于关闭应用前释放资源。比如:说数据库连接的关闭，此时，调用contextDestroyed(ServletContextEvent args)，关闭Web应用时，系统调用Listener的该方法。 　　接着，容器会读取，根据指定的类路径来实例化过滤器。 以上都是在WEB项目还没有完全启动起来的时候就已经完成了的工作。 如果系统中有，则Servlet是在第一次发起请求的时候被实例化的，而且一般不会被容器销毁，它可以服务于多个用户的请求。所以，Servlet的初始化都要比上面提到的那几个要迟。 不过如果需要在web容器启动时就加载某servlet的话，可以在某servlet标签内部加上让该servlet紧接着filter加载完后进行加载，如： springmvc org.springframework.web.servlet.DispatcherServlet contextConfigLocation classpath:/config/spring-servlet.xml 1 springmvc /rest/* Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 12:59:31 "},"chapter6/section9/":{"url":"chapter6/section9/","title":"6.9 事件驱动模型: 加载ContextLoaderListener","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 继承ContextLoader有什么作用？ 实现ServletContextListener又有什么作用？ 那么ContextLoaderListener的作用是什么？ 那又是怎么为我们的项目提供spring支持的呢？ 事件驱动模型: 加载ContextLoaderListener 观察者模式: ContextLoaderListener 每一个整合spring框架的项目中，总是不可避免地要在web.xml中加入这样一段配置: org.springframework.web.context.ContextLoaderListener contextConfigLocation /WEB-INF/applicationContext*.xml 类定义： public class ContextLoaderListener extends ContextLoader implements ServletContextListener 可以看到ContextLoaderListener继承自ContextLoader，实现的是ServletContextListener接口。 继承ContextLoader有什么作用？ ContextLoaderListener可以指定在Web应用程序启动时载入Ioc容器，正是通过ContextLoader来实现的，可以说是Ioc容器的初始化工作。 实现ServletContextListener又有什么作用？ ServletContextListener接口里的函数会结合Web容器的生命周期被调用。因为ServletContextListener是ServletContext的监听者，如果ServletContext发生变化，会触发相应的事件，而监听器一直对事件监听，如果接收到了变化，就会做出预先设计好的相应动作。由于ServletContext变化而触发的监听器的响应具体包括：在服务器启动时，ServletContext被创建的时候，服务器关闭时，ServletContext将被销毁的时候等，相当于web的生命周期创建与效果的过程。 那么ContextLoaderListener的作用是什么？ ContextLoaderListener的作用就是启动Web容器时，读取在contextConfigLocation中定义的xml文件，自动装配ApplicationContext的配置信息，并产生WebApplicationContext对象，然后将这个对象放置在ServletContext的属性里，这样我们只要得到Servlet就可以得到WebApplicationContext对象，并利用这个对象访问spring容器管理的bean。 简单来说，就是上面这段配置为项目提供了spring支持，初始化了Ioc容器。 那又是怎么为我们的项目提供spring支持的呢？ 上面说到“监听器一直对事件监听，如果接收到了变化，就会做出预先设计好的相应动作”。而监听器的响应动作就是在服务器启动时contextInitialized会被调用，关闭的时候contextDestroyed被调用。这里我们关注的是WebApplicationContext如何完成创建。因此销毁方法就暂不讨论。 //重写ServletContextListener接口里的方法 @Override public void contextInitialized(ServletContextEvent event) { //初始化webApplicationCotext,调用的是父类ContextLoader的方法 initWebApplicationContext(event.getServletContext()); } WebApplicationContext根据在context-params中配置的contextClass和contextConfigLocation完成初始化。 public WebApplicationContext initWebApplicationContext( ServletContext servletContext) { // application对象中存放了spring context，则抛出异常 // 其中ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE = WebApplicationContext.class.getName() + \".ROOT\"; if (servletContext .getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) { throw new IllegalStateException( \"Cannot initialize context because there is already a root application context present - \" + \"check whether you have multiple ContextLoader* definitions in your web.xml!\"); } // 创建得到WebApplicationContext // createWebApplicationContext最后返回值被强制转换为ConfigurableWebApplicationContext类型 if (this.context == null) { this.context = createWebApplicationContext(servletContext); } // 只要上一步强转成功，进入此方法（事实上走的就是这条路） if (this.context instanceof ConfigurableWebApplicationContext) { // 强制转换为ConfigurableWebApplicationContext类型 ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; // cwac尚未被激活，目前还没有进行配置文件加载 if (!cwac.isActive()) { // 加载配置文件 configureAndRefreshWebApplicationContext(cwac, servletContext); 【点击进入该方法发现这样一段： //为wac绑定servletContext wac.setServletContext(sc); //CONFIG_LOCATION_PARAM=contextConfigLocation //getInitParameter(CONFIG_LOCATION_PARAM)解释了为什么配置文件中需要有contextConfigLocation项 //需要注意还有sevletConfig.getInitParameter和servletContext.getInitParameter作用范围是不一样的 String initParameter = sc.getInitParameter(CONFIG_LOCATION_PARAM); if (initParameter != null) { //装配ApplicationContext的配置信息 wac.setConfigLocation(initParameter); } 】 } } // 把创建好的spring context，交给application内置对象，提供给监听器/过滤器/拦截器使用 servletContext.setAttribute( WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); // 返回webApplicationContext return this.context; } initWebApplicationContext中加载了contextConfigLocation的配置信息，初始化Ioc容器，说明了上述配置的必要性。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter6/section10/":{"url":"chapter6/section10/","title":"6.10 加载DispatcherServlet初始化顺序详解","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1. Web容器启动时将调用HttpServletBean的init方法 2. FrameworkServlet通过initServletBean()进行Web上下文初始化 3. DispatcherServlet实现了onRefresh()方法: 提供一些前端控制器相关的配置 加载DispatcherServlet初始化顺序详解 简单说就是： DispatcherServlet的init方法里面load了springmvc的配置信息， 然后初始化了spring容器（调用了onRefresh方法），把controller的信息缓存了，比如映射信息； 然后DispatcherServlet会拦截所有的请求，根据用户的请求信息通过缓存的映射信息找到对应的controller中对应的方法，继而反射调用（其实底层的源码就是反射调用controller的方法）， 然后视图裁决、解析等等工作。 1. Web容器启动时将调用HttpServletBean的init方法 public abstract class HttpServletBean extends HttpServlet implements EnvironmentAware{ @Override public final void init() throws ServletException { //省略部分代码 //1、如下代码的作用是将Servlet初始化参数()设置到该servlet对象上 //初始化参数如contextAttribute、contextClass、namespace、contextConfigLocation； try { PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, this.environment)); initBeanWrapper(bw); bw.setPropertyValues(pvs, true); } catch (BeansException ex) { //…………省略其他代码 } //2、提供给子类初始化的扩展点，该方法由FrameworkServlet覆盖 initServletBean(); if (logger.isDebugEnabled()) { logger.debug(\"Servlet '\" + getServletName() + \"' configured successfully\"); } } //…………省略其他代码 } 将Servlet初始化参数（init-param）设置到该servlet对象上（如contextAttribute、contextClass、namespace、contextConfigLocation这些参数），通过BeanWrapper（装饰模式） 简化设值过程，方便后续使用； 注：ServletConfig获取配置参数的方法和ServletContext获取配置参数的方法完全一样，只是ServletConfig是取得当前Servlet的配置参数，而ServletContext是获取整个web应用的配置参数。 提供给子类初始化扩展点: initServletBean()，该方法由FrameworkServlet覆盖。 2. FrameworkServlet通过initServletBean()进行Web上下文初始化 该方法主要作用如下： 初始化web上下文； 提供给子类初始化扩展点；public abstract class FrameworkServlet extends HttpServletBean { @Override protected final void initServletBean() throws ServletException { //省略部分代码 try { //1、初始化Web上下文 this.webApplicationContext = initWebApplicationContext(); //2、提供给子类初始化的扩展点 initFrameworkServlet(); } //省略部分代码 } } initWebApplicationContext():protected WebApplicationContext initWebApplicationContext() { //ROOT上下文（ContextLoaderListener加载的） WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) { // 1、在创建该Servlet注入的上下文 wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) { ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) { if (cwac.getParent() == null) { cwac.setParent(rootContext); } configureAndRefreshWebApplicationContext(cwac); } } } if (wac == null) { //2、查找已经绑定的上下文 wac = findWebApplicationContext(); } if (wac == null) { //3、如果没有找到相应的上下文，并指定父亲为ContextLoaderListener wac = createWebApplicationContext(rootContext); } if (!this.refreshEventReceived) { //4、刷新上下文（执行一些初始化） onRefresh(wac); } if (this.publishContext) { // Publish the context as a servlet context attribute. String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); //省略部分代码 } return wac; } 从initWebApplicationContext()方法可以看出， ContextLoaderListener（观察者模式） 加载了上下文将作为根上下文（DispatcherServlet的父容器）。 最后调用了onRefresh()方法执行容器的一些初始化，这个方法由子类实现，来进行扩展。 3. DispatcherServlet实现了onRefresh()方法: 提供一些前端控制器相关的配置 九大组件 public class DispatcherServlet extends FrameworkServlet { //实现子类的onRefresh()方法，该方法委托为initStrategies()方法。 @Override protected void onRefresh(ApplicationContext context) { initStrategies(context); } //初始化默认的Spring Web MVC框架使用的策略（如HandlerMapping） protected viod initStrategies(ApplicationContext context){ initMultipartResolver(context);//初始化上传文件解析器 initLocaleResolver(context);//初始化本地解析器 initThemeResolver(context);//初始化主题解析器 initHandlerMapping(context);//初始化处理器映射器,将请求映射到处理器 initHandlerAdapters(context);//初始化处理器适配器 initHandlerExceptionResolver(context);//初始化处理器异常解析器,如果执行过程中遇到异常将交给HandlerExceptionResolver来解析 initRequestToViewNameTranslator(context);//初始化请求到具体视图名称解析器 initViewResolvers(context);//初始化视图解析器,通过ViewResolver解析逻辑视图名到具体视图实现 initFlshMapManager(context);//初始化flash映射管理 } } initStrategies方法将在WebApplicationContext初始化后自动执行,自动扫描上下文的Bean,根据名称或者类型匹配的机制查找自定义组件,如果没有找到则会装配一套Spring的默认组件.在org.springframework.web.servlet路径下有一个DispatcherServlet.properties配置文件,该文件指定了DispatcherServlet所使用的默认组件. 在DispatcherServlet同一个目录下的DispatchServlet.properties文件中默认的九大组件： 1.org.springframework.web.servlet.LocaleResolver=org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolver 2.org.springframework.web.servlet.ThemeResolver=org.springframework.web.servlet.theme.FixedThemeResolver // 带\"\\\"的是多个默认配置Handler类 3.org.springframework.web.servlet.HandlerMapping=org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping,\\ org.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMapping 4.org.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\\ org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\\ org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter 5.org.springframework.web.servlet.HandlerExceptionResolver=org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerExceptionResolver,\\ org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver,\\ org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolver 6.org.springframework.web.servlet.RequestToViewNameTranslator=org.springframework.web.servlet.view.DefaultRequestToViewNameTranslator //这个也可以有多个，这里默认只配置了一个而已 7.org.springframework.web.servlet.ViewResolver=org.springframework.web.servlet.view.InternalResourceViewResolver 8.org.springframework.web.servlet.FlashMapManager=org.springframework.web.servlet.support.SessionFlashMapManager DispatcherServlet启动时会进行我们需要的Web层Bean的配置，如HandlerMapping、HandlerAdapter等，而且如果我们没有配置，还会给我们提供默认的配置。 整个DispatcherServlet初始化的过程具体主要做了如下两件事情： 初始化Spring Web MVC使用的Web上下文，并且可能指定父容器为（ContextLoaderListener加载了根上下文）； 初始化DispatcherServlet使用的策略，如HandlerMapping、HandlerAdapter等。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter6/section11/":{"url":"chapter6/section11/","title":"6.11 BeanWrapper","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 BeanWrapper整体UML图： 右边部分 PropertyEditorRegistry（属性编辑器注册器） PropertyAccessor（属性访问器） TypeConverter（类型转换器） ConfigurablePropertyAccessor BeanWrapper 接口功能总结 左边部分 PropertyEditorRegistrySupport TypeConverterSupport AbstractPropertyAccessor AbstractNestablePropertyAccessor BeanWrapperImpl BeanWrapper使用 BeanWrapper https://blog.csdn.net/qq_41907991/article/details/105214244 BeanWrapper整体UML图： 右边部分 先看BeanWrapper能做啥，有什么功能，即看实现了什么接口（右边部分）： PropertyEditorRegistry（属性编辑器注册器）：注入属性编辑器（PropertyEditor） PropertyAccessor（属性访问器） TypeConverter（类型转换器） ConfigurablePropertyAccessor BeanWrapper：BeanWrapper是Spring中一个很重要的接口，Spring在通过配置信息创建对象时，第一步首先就是创建一个BeanWrapper。PropertyEditorRegistry（属性编辑器注册器） // 这个接口的功能很简单，就是用来注入属性编辑器（PropertyEditor），那么什么是PropertyEditor呢？ public interface PropertyEditorRegistry { void registerCustomEditor(Class requiredType, PropertyEditor propertyEditor); void registerCustomEditor(@Nullable Class requiredType, @Nullable String propertyPath, PropertyEditor propertyEditor); @Nullable PropertyEditor findCustomEditor(@Nullable Class requiredType, @Nullable String propertyPath); } PropertyEditor是JavaBean规范定义的接口，这是java.beans中一个接口，其设计的意图是图形化编程上，方便对象与String之间的转换工作， 而Spring将其扩展，方便各种对象Object与String之间的转换工作。 Spring中对PropertyEditor使用的实例: 我们在通过XML的方式对Spring中的Bean进行配置时，不管Bean中的属性是何种类型，都是直接通过字面值来设置Bean中的属性。那么是什么在这其中做转换呢？这里用到的就是PropertyEditor SpringMVC在解析请求参数时，也是使用的PropertyEditor Spring内置的PropertyEditor (将String转换成各种Object): PropertyAccessor（属性访问器） public interface PropertyAccessor { // 嵌套属性的分隔符,比如\"foo.bar\"将会调用getFoo().getBar()两个方法 String NESTED_PROPERTY_SEPARATOR = \".\"; char NESTED_PROPERTY_SEPARATOR_CHAR = '.'; // 代表角标index的符号 如person.addresses[0] 这样就可以把值放进集合/数组/Map里了 String PROPERTY_KEY_PREFIX = \"[\"; char PROPERTY_KEY_PREFIX_CHAR = '['; String PROPERTY_KEY_SUFFIX = \"]\"; char PROPERTY_KEY_SUFFIX_CHAR = ']'; // 该属性是否可读/可写，不存在则返回false boolean isReadableProperty(String propertyName); boolean isWritableProperty(String propertyName); // 获取/设置属性的方法，基本见名知意 @Nullable Class getPropertyType(String propertyName) throws BeansException; @Nullable TypeDescriptor getPropertyTypeDescriptor(String propertyName) throws BeansException; @Nullable Object getPropertyValue(String propertyName) throws BeansException; void setPropertyValue(String propertyName, @Nullable Object value) throws BeansException; void setPropertyValue(PropertyValue pv) throws BeansException; void setPropertyValues(Map map) throws BeansException; void setPropertyValues(PropertyValues pvs) throws BeansException; void setPropertyValues(PropertyValues pvs, boolean ignoreUnknown) throws BeansException; void setPropertyValues(PropertyValues pvs, boolean ignoreUnknown, boolean ignoreInvalid) throws BeansException; } 什么是PropertyValue？ 当设置属性值时，少不了两样东西： 属性访问表达式：如listMap[0][0] 属性值：ProperyValue对象就是用来封装这些信息的。如果某个值要给赋值给bean属性，Spring都会把这个值包装成ProperyValue对象。 TypeConverter（类型转换器） // 定义了进行类型转换时的一些规范，就像名字定义的那样，主要用来做类型转换 public interface TypeConverter { // 将指定的值转换成指定的类型 @Nullable T convertIfNecessary(@Nullable Object value, @Nullable Class requiredType) throws TypeMismatchException; // 相对于上面这个方法下面这个三种方法能处理转换过程中的泛型 @Nullable T convertIfNecessary(@Nullable Object value, @Nullable Class requiredType, @Nullable MethodParameter methodParam) throws TypeMismatchException; @Nullable T convertIfNecessary(@Nullable Object value, @Nullable Class requiredType, @Nullable Field field) throws TypeMismatchException; default T convertIfNecessary(@Nullable Object value, @Nullable Class requiredType, @Nullable TypeDescriptor typeDescriptor) throws TypeMismatchException { throw new UnsupportedOperationException(\"TypeDescriptor resolution not supported\"); } } ConfigurablePropertyAccessor public interface ConfigurablePropertyAccessor extends PropertyAccessor, PropertyEditorRegistry, TypeConverter { // ConversionService：进行转换的业务类，转换系统的入口 void setConversionService(@Nullable ConversionService conversionService); @Nullable ConversionService getConversionService(); // 进行属性编辑是是否返回旧的值 void setExtractOldValueForEditor(boolean extractOldValueForEditor); boolean isExtractOldValueForEditor(); // 当设置（dog.name）这种嵌套属性的情况下，如果dog属性为null是否会报错 // 为true的话不会，为false会抛出NullValueInNestedPathException void setAutoGrowNestedPaths(boolean autoGrowNestedPaths); boolean isAutoGrowNestedPaths(); } BeanWrapper // Spring低级JavaBeans基础设施的中央接口。通常来说并不直接使用BeanWrapper，而是借助BeanFactory或者DataBinder来一起使用,BeanWrapper对Spring中的Bean做了包装，为的是更加方便的操作Bean中的属性 public interface BeanWrapper extends ConfigurablePropertyAccessor { void setAutoGrowCollectionLimit(int autoGrowCollectionLimit); int getAutoGrowCollectionLimit(); // 获取包装的Bean Object getWrappedInstance(); // 获取包装的Bean的class Class getWrappedClass(); // 获取所有属性的属性描述符 PropertyDescriptor[] getPropertyDescriptors(); // 获取指定属性的属性描述符 PropertyDescriptor getPropertyDescriptor(String propertyName) throws InvalidPropertyException; } PropertyDescriptor：属性描述符，能够描述javaBean中的属性，通过属性描述符我们能知道这个属性的类型，获取到操纵属性的方法（getter/setter） 接口功能总结 BeanWrapper接口自身对Bean进行了一层包装。 另外它的几个通过间接继承了几个接口，所以它还能对Bean中的属性进行操作。PropertyAccessor赋予了BeanWrapper对属性进行访问及设置的能力， 在对Bean中属性进行设置时，不可避免的需要对类型进行转换，而恰好PropertyEditorRegistry，TypeConverter就提供了类型转换的统一约束。 左边部分 唯一实现类BeanWrapperImpl到底是个啥，看继承关系（左边部分） PropertyEditorRegistrySupport 这个类最大的作用在于管理PropertyEditor,添加了很多的默认的PropertyEditor。在PropertyEditorRegistry的基础上做了进一步的扩展，提供的还是PropertyEditor注册的功能。 TypeConverterSupport public abstract class TypeConverterSupport extends PropertyEditorRegistrySupport implements TypeConverter { @Nullable TypeConverterDelegate typeConverterDelegate; ...... } 这个接口实现了TypeConverter，所以它具有类型转换的能力，而它这种能力的实现，依赖于它所持有的一个TypeConverterDelegate。 class TypeConverterDelegate { private final PropertyEditorRegistrySupport propertyEditorRegistry; @Nullable private final Object targetObject; public T convertIfNecessary(@Nullable String propertyName, @Nullable Object oldValue, @Nullable Object newValue, @Nullable Class requiredType, @Nullable TypeDescriptor typeDescriptor) throws IllegalArgumentException { // 查看是否为当前这个类型配置了定制的PropertyEditor PropertyEditor editor = this.propertyEditorRegistry.findCustomEditor(requiredType, propertyName); ConversionFailedException conversionAttemptEx = null; // 获取当前容器中的类型转换业务类 ConversionService conversionService = this.propertyEditorRegistry.getConversionService(); // 在这里可以看出，Spring底层在进行类型转换时有两套机制 // 1.首选的是采用PropertyEditor // 2.在没有配置PropertyEditor的情况下，会采用conversionService if (editor == null && conversionService != null && newValue != null && typeDescriptor != null) { TypeDescriptor sourceTypeDesc = TypeDescriptor.forObject(newValue); if (conversionService.canConvert(sourceTypeDesc, typeDescriptor)) { try { // 通过conversionService进行类型转换 return (T) conversionService.convert(newValue, sourceTypeDesc, typeDescriptor); } catch (ConversionFailedException ex) { // fallback to default conversion logic below conversionAttemptEx = ex; } } } Object convertedValue = newValue; // 配置了定制的属性编辑器，采用PropertyEditor进行属性转换 if (editor != null || (requiredType != null && !ClassUtils.isAssignableValue(requiredType, convertedValue))) { if (typeDescriptor != null && requiredType != null && Collection.class.isAssignableFrom(requiredType) && convertedValue instanceof String) { TypeDescriptor elementTypeDesc = typeDescriptor.getElementTypeDescriptor(); if (elementTypeDesc != null) { Class elementType = elementTypeDesc.getType(); if (Class.class == elementType || Enum.class.isAssignableFrom(elementType)) { convertedValue = StringUtils.commaDelimitedListToStringArray((String) convertedValue); } } } if (editor == null) { // 没有配置定制的属性编辑器，采用默认的属性编辑器 editor = findDefaultEditor(requiredType); } // 采用属性编辑器进行转换，需要注意的是，默认情况下PropertyEditor只会对String类型的值进行类型转换 convertedValue = doConvertValue(oldValue, convertedValue, requiredType, editor); } // ..... return (T) convertedValue; } } PropertyEditor主要进行的是String到Object的转换，正因为如此，属性编辑器进行类型转换有很大的局限性，所以Spring又推出了一套ConversionService的体系 AbstractPropertyAccessor public abstract class AbstractPropertyAccessor extends TypeConverterSupport implements ConfigurablePropertyAccessor { // 省略部分代码...... // 批量设置属性 @Override public void setPropertyValues(PropertyValues pvs, boolean ignoreUnknown, boolean ignoreInvalid) throws BeansException { List propertyAccessExceptions = null; List propertyValues = (pvs instanceof MutablePropertyValues ? ((MutablePropertyValues) pvs).getPropertyValueList() : Arrays.asList(pvs.getPropertyValues())); for (PropertyValue pv : propertyValues) { try { setPropertyValue(pv); } // .... } } @Override @Nullable public abstract Object getPropertyValue(String propertyName) throws BeansException; @Override public abstract void setPropertyValue(String propertyName, @Nullable Object value) throws BeansException; } 这个类继承了TypeConverterSupport,所以它具备了类型转换的能力。同时它也是一个属性访问器，但是它只是实现了批量设置属性的方法，真正的setPropertyValue还是留待子类实现。 可以看到，到这个类为止，还没有将属性的设置跟类型转换的能力结合起来。 AbstractNestablePropertyAccessor 这个类开始真正的将属性访问跟类型转换结合到一起，它真正的实现了setPropertyValue（访问属性->设置属性->类型转换），具体代码就不看了，非常繁杂，但是整体不难。 BeanWrapperImpl // 这个类我只保留一些关键的代码，其余的琐碎代码都不看了 public class BeanWrapperImpl extends AbstractNestablePropertyAccessor implements BeanWrapper { // 缓存内省的结果，BeanWrapperImpl就是通过这个对象来完成对包装的Bean的属性的控制 @Nullable private CachedIntrospectionResults cachedIntrospectionResults; ...... public void setBeanInstance(Object object) { this.wrappedObject = object; this.rootObject = object; // 实际进行类型转换的对象：typeConverterDelegate this.typeConverterDelegate = new TypeConverterDelegate(this, this.wrappedObject); setIntrospectionClass(object.getClass()); } ...... // 最终调用的就是CachedIntrospectionResults的forClass方法进行内省并缓存，底层调用的就是java的内省机制 private CachedIntrospectionResults getCachedIntrospectionResults() { if (this.cachedIntrospectionResults == null) { this.cachedIntrospectionResults = CachedIntrospectionResults.forClass(getWrappedClass()); } return this.cachedIntrospectionResults; } ....... // 最终进行类型转换的方法 private Object convertIfNecessary(@Nullable String propertyName, @Nullable Object oldValue, @Nullable Object newValue, @Nullable Class requiredType, @Nullable TypeDescriptor td) throws TypeMismatchException { Assert.state(this.typeConverterDelegate != null, \"No TypeConverterDelegate\"); try { // 可以看到，最后就是调用typeConverterDelegate来进行类型转换 return this.typeConverterDelegate.convertIfNecessary(propertyName, oldValue, newValue, requiredType, td); } ...... } } BeanWrapper使用 BeanWrapper的功能很简单，提供一个设置JavaBean属性的通用方法: Object obj = Class.forName(\"packageAname.subPackage.ClassName\").newInstance(); BeanWrapper bw = new BeanWrapperImpl(obj); bw.setPropertyValue(\"propertyName\", \"updateValue\");//propertyName属性名称，updateValue属性值 System.out.println(bw.getPropertyValue(\"propertyName\")); Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter6/section12/":{"url":"chapter6/section12/","title":"6.12 DispatcherServlet解析请求过程","keywords":"","body":"DispatcherServlet解析请求过程 在doDispatcher的第二步是通过handlerMapping找到handler进而获取handlerAdapter: HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter6/section13/":{"url":"chapter6/section13/","title":"6.13 HandlerAdapter","keywords":"","body":"HandlerAdapter protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException { if (this.handlerAdapters != null) { for (HandlerAdapter ha : this.handlerAdapters) { if (logger.isTraceEnabled()) { logger.trace(\"Testing handler adapter [\" + ha + \"]\"); } if (ha.supports(handler)) { return ha; } } } throw new ServletException(\"No adapter for handler [\" + handler + \"]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler\"); } 遍历自身的handlerAdapter链表如果支持该handler则返回该adpter。 这里的逻辑就需要想两个问题: 该adpter链表什么时候填充进来的 答：这个应该是在9大组件初始化的时候完成：initHandlerAdapters(context); handlerAdapter的support是如何实现？ 答：这里就要分析HandlerAdapter组件 通过 HandlerAdapter 执行这个 Handler 得到 ModelAndView 对象。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter6/section14/":{"url":"chapter6/section14/","title":"6.14 ContextLoaderListener和DispatcherServlet初始化上下文关系和区别","keywords":"","body":"ContextLoaderListener和DispatcherServlet初始化上下文关系和区别 从上图可以看出， ContextLoaderListener初始化的上下文加载的Bean是对于整个应用程序共享的，一般如：DAO层、Service层Bean； DispatcherServlet初始化的上下文加载的Bean是只对Spring MVC有效的Bean，如：Controller、HandlerMapping、HandlerAdapter等，该初始化上下文只加载Web相关组件。 注意：用户可以配置多个DispatcherServlet来分别处理不同的url请求，每个DispatcherServlet上下文都对应一个自己的子Spring容器，他们都拥有相同的父Spring容器（业务层，持久（dao）bean所在的容器）。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 13:08:26 "},"chapter6/section15/":{"url":"chapter6/section15/","title":"6.15 spring使用的设计模式","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1. Spring 中常见的设计模式 2. Spring 的四大模块及典型的设计模式 3. Spring 中常见设计模式分类 spring使用的设计模式 1. Spring 中常见的设计模式 工厂模式 ： BeanFactory 装饰器模式： BeanWrapper 代理模式： AopProxy 单例模式： ApplicationContext 委派模式： DispatcherServlet 策略模式: HandlerMapping 适配器模式： HandlerApdapter 模板方法模式： JdbcTemplate 观察者模式： ContextLoaderListener 2. Spring 的四大模块及典型的设计模式 Spring IOC 工厂模式、单例模式、装饰器模式 Spring AOP 代理模式、观察者模式 Spring MVC 委派模式、适配器模式 Spring JDBC 模板方法模式 3. Spring 中常见设计模式分类 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter7/section1/":{"url":"chapter7/section1/","title":"7.1 resultyType","keywords":"","body":"resultyType 基本类型：resultType=基本类型 List类型：resultType=List中元素的类型 Map类型：单条记录：resultType =map;多条记录：resultType =Map中value的类型 https://www.cnblogs.com/pjfmeng/p/7688172.html 可以用别名让数据库的字段和resultType里的对象属性一一相对 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter7/section2/":{"url":"chapter7/section2/","title":"7.2 关联查询","keywords":"","body":"关联查询 实现方式、区别 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section1/":{"url":"chapter8/section1/","title":"8.1 范式","keywords":"","body":"范式 函数依赖：若在一张表中，在属性（或属性组）X 的值确定的情况下，必定能确定属性 Y 的值，那么就可以说 Y 函数依赖于 X，写作 X → Y。 部分函数依赖：比如学生基本信息表 R 中（学号，身份证号，姓名）当然学号属性取值是唯一的，在 R 关系中， （学号，身份证号）->（姓名）， （学号）->（姓名），（身份证号）->（姓名）； 所以（姓名）部分函数依赖于（学号，身份证号）； 完全函数依赖：比如学生基本信息表 R（学号，班级，姓名）假设不同的班级学号有相同的，班级内学号不能相同，在 R 关系中， （学号，班级）->（姓名）， 但是（学号）->(姓名)不成立，（班级）->(姓名)不成立， 所以（姓名）完全函数依赖于（学号，班级）； 传递函数依赖：比如在关系 R(学号 ,姓名, 系名，系主任)中， 学号 → 系名，系名 → 系主任， 所以存在非主属性（系主任）对于（学号）的传递函数依赖。 1NF：属性不可再分。 2NF：1NF 的基础之上，消除了非主属性对于码的部分函数依赖。 3NF：3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 13:28:23 "},"chapter8/section2/":{"url":"chapter8/section2/","title":"8.2 int与varchar","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 int(5) varchar(20) int与varchar int(5) int可以存储4个字节大小的数据，但是它的宽度是5，即如果存储的数据的宽度小于5，会自动在前面补0，凑齐“个十百千万”的5位数字。 tinyint 1 smallint 2 mediumint 3 int 4 bigint 8 varchar(20) 5.0版本以上，varchar(20)，指的是20字符，无论存放的是数字、字母还是UTF8汉字（每个汉字3字节），都可以存放20个。 其最大可存储字符为21845个字符（0-21844），即最大大小是65535字节 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 13:30:50 "},"chapter8/section3/":{"url":"chapter8/section3/","title":"8.3 in&exists","keywords":"","body":"in&exists 小表驱动大表， 用in：说明in中的查询数据小 用exists：说明exists中的查询数据大 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 13:34:10 "},"chapter8/section4/":{"url":"chapter8/section4/","title":"8.4 删表不删库","keywords":"","body":"删表不删库 SELECT concat('DROP TABLE IF EXISTS ', table_name, ';') FROM information_schema.tables WHERE table_schema = 'mydb'; mydb换成你想删除的数据库的名字,这样可以生成一个批量处理的sql语句，你需要再运行一次这个结果集就可以删除所有的表而不删除数据库了 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section5/":{"url":"chapter8/section5/","title":"8.5 mysql主键断号解决","keywords":"","body":"mysql主键断号解决 mysql删除记录，对自增主键ID进行重新排序 Mysql数据库表的自增主键ID号经过一段时间的添加与删除之后乱了，需要重新排列。 原理：删除原有的自增ID，重新建立新的自增ID。 1，删除原有主键： ALTER TABLE `table_name` DROP `id`; 2，添加新主键字段： ALTER TABLE `table_name` ADD `id` MEDIUMINT( 8 ) NOT NULL FIRST; 3，设置新主键： ALTER TABLE `table_name` MODIFY COLUMN `id` MEDIUMINT( 8 ) NOT NULL AUTO_INCREMENT,ADD PRIMARY KEY(id); Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section6/":{"url":"chapter8/section6/","title":"8.6 7种join详解","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 Join算法原理 最后两个图的mysql实现 7种join详解 Join算法原理 MySQL的join算法原理基于嵌套循环查询。但是由于简单的嵌套循环查询存在效率低下，频繁与磁盘进行I/O的问题，故MySQL会分别从减少内层循环次数，以及减少I/O次数两个层面对join的简单嵌套循环查询进行优化。 从本质上来说，MySQL的join算法基于简单嵌套循环查询，即外层表的记录作为条件，循环遍历内层表进行查询，返回内层循环中满足条件的记录。对于SQL语句: select * from a left join b on a.id=b.id。 for(a from 外层表){ for(b from 内层表){ if(a.id == b.id){ return; } } } 但是简单的嵌套循环查询效率比较低，本质上是: 因为每次查询时都是从外层表取出一次记录，即进行一个I/O， 并且对内层表的查询是全表扫描， 故可以从这两个角度对简单嵌套循环查询进行优化。 优化1: 从优化I/O的角度，每次I/O取外层表的多条记录进行缓存，多条记录同时在内层循环中进行查找。 优化2: 内层循环的查询可以通过建立索引进行优化，通过索引进行查找的次数只为索引B树的高度。这就是索引嵌套循环连接。对于上述的SQL语句:select * from a left join b on a.id=b.id，如果在b表对id字段建立了索引，则外层的循环查询在内层循环中会使用到索引，从而减少了查询的次数。 最后两个图的mysql实现 select * from a left join b on a.id=b.id union select * from a right join b on a.id=b.id; select * from a left join b on a.id=b.id where b.id is null union select * from a right join b on a.id=b.id where a.id is null; Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 13:38:57 "},"chapter8/section7/":{"url":"chapter8/section7/","title":"8.7 索引","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 联合索引图 1.1 索引最左前缀原则 2 聚簇索引和非聚簇索引 2.1 聚簇索引 2.2 非聚簇索引 索引 https://www.bilibili.com/video/BV1KW411u7vy https://blog.csdn.net/feichitianxia/article/details/107997795 结合视频和博客，对mysql的索引和锁有了具体的了解。 总的来说，对sql性能的优化，就是要建立正确的索引， 无论是查询涉及到的where, 排序用的order by，或者是先排序后分组的group by，对高并发支持的innodb引擎的行锁，都要依赖于索引。 行锁锁的对象就是索引，所以如果更新条件where没用到索引，那么行锁就会升级成表锁，降低并发性能。 1 联合索引图 1.1 索引最左前缀原则 常见联合索引 索引index1:(a,b,c)，只会走a、a,b、a,b,c 三种类型的查询，其实这里说的有一点问题，a,c也走，但是只走a字段索引，不会走c字段。 另外还有一个特殊情况说明下，select * from table where a = '1' and b > ‘2’ and c='3' 这种类型的也只会有a与b走索引，c不会走。 原因如下： 索引是有序的，index1索引在索引文件中的排列是有序的，首先根据a来排序，然后才是根据b来排序，最后是根据c来排序， 像select * from table where a = '1' and b > ‘2’ and c='3' 这种类型的sql语句，在a、b走完索引后，c肯定是无序了，所以c就没法走索引，数据库会觉得还不如全表扫描c字段来的快。（感觉这一块说的始终有点牵强，无序又怎样，从剩下的里面挨着挨着找不就好了吗？） 2 聚簇索引和非聚簇索引 聚簇索引是什么 2.1 聚簇索引 就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据， 也将聚集索引的叶子节点称为数据页。 这个特性决定了索引组织表中数据也是索引的一部分，每张表只能拥有一个聚簇索引。 怎样选择聚簇索引 Innodb通过主键聚集数据，如果没有定义主键，innodb会选择非空的唯一索引代替。如果没有这样的索引，innodb会隐式的定义一个主键来作为聚簇索引。 聚簇索引的优缺点 优点： 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快 聚簇索引对于主键的排序查找和范围查找速度非常快 缺点： 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键 更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。 2.2 非聚簇索引 又叫辅助索引或二级索引。 在聚簇索引之上创建的索引称之为辅助索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值。 Innodb辅助索引的叶子节点并不包含行记录的全部数据，叶子节点除了包含键值外，还包含了相应行数据的聚簇索引键。 因此辅助索引访问数据总是需要二次查找。 查找数据方式 通过辅助索引首先找到的是主键值，再通过主键值找到数据行的数据页，再通过数据页中的Page Directory找到数据行。 总结 辅助索引的存在不影响数据在聚簇索引中的组织，所以一张表可以有多个辅助索引。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-22 18:24:24 "},"chapter8/section8/":{"url":"chapter8/section8/","title":"8.8 explain","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 id select_type table partitions type possible_keys、key、key_len ref rows filtered Extra 总结 explain explain（执行计划）: 使用explain关键字可以模拟优化器执行sql查询语句，从而知道MySQL是如何处理sql语句。explain主要用于分析查询语句或表结构的性能瓶颈。 id select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序，该字段通常与table字段搭配来分析。 id相同，执行顺序从上到下。 id相同，执行顺序从上到下，搭配table列进行观察可知，执行顺序为t1->t3->t2。 id不同，如果是子查询，id的序号会递增，id值越大执行优先级越高。 如果是子查询id的序号会递增，id值越大执行优先级越高，搭配table列可知，执行顺序为t3->t1->t2。 select_type 查询的类型，主要用于区别普通查询、联合查询、子查询等复杂的查询。其值主要有六个： SIMPLE: 简单的select查询，查询中不包含子查询或union查询。 PRIMARY: 查询中若包含任何复杂的子部分，最外层查询为PRIMARY，也就是最后加载的就是PRIMARY。 SUBQUERY: 在select或where列表中包含了子查询，就为被标记为SUBQUERY。 DERIVED: 在from列表中包含的子查询会被标记为DERIVED(衍生)，MySQL会递归执行这些子查询，将结果放在临时表中。 UNION: 若第二个select出现在union后，则被标记为UNION，若union包含在from子句的子查询中，外层select将被标记为DERIVED。 UNION RESULT: 从union表获取结果的select。 table 显示sql操作属于哪张表的。 partitions 官方定义为The matching partitions（匹配的分区），该字段应该是看table所在的分区吧（不晓得理解错误没）。值为NULL表示表未被分区。 type 表示查询所使用的访问类型，type的值主要有7种，该值表示查询的sql语句好坏，从最好到最差依次为：system>const>eq_ref>ref>range>index>ALL。 注：一般来说，需保证查询至少达到range级别，最好能达到ref。 system 表只有一行记录（等于系统表），是const的特例类型（mysql大于5.7版本后，system由const代替） const 表示通过一次索引就找到了结果，常出现于primary key或unique索引。因为只匹配一行数据，所以查询非常快。如将主键置于where条件中，MySQL就能将查询转换为一个常量。 3.eq_ref 唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见主键或唯一索引扫描。 ref 非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，返回匹配某值（某条件）的多行值，属于查找和扫描的混合体。 range 只检索给定范围的行，使用一个索引来检索行，可以在key列中查看使用的索引，一般出现在where语句的条件中，如使用between、>、 这种索引的范围扫描比全表扫描要好，因为索引的开始点和结束点都固定，不用扫描全索引。 特殊例子：deptid为非唯一性索引，id为主键索引（唯一索引） 对比两图，可以看到使用deptid和id进行操作，其type的值一个是ALL也就是进行了全表扫描，一个是range进行了指定索引范围值检索。可能原因deptid并不是唯一索引。 index 全索引扫描。 ALL 全表扫描。 注：index和ALL的区别：index只遍历索引树，通常比ALL快，因为索引文件通常比数据文件小。虽说index和ALL都是全表扫描，但是index是从索引中读取，ALL是从磁盘中读取。 possible_keys、key、key_len possible_keys：显示可能应用在表中的索引，可能一个或多个。查询涉及到的字段若存在索引，则该索引将被列出，但不一定被查询实际使用。 key：实际中使用的索引，如为NULL，则表示未使用索引。若查询中使用了覆盖索引，则该索引和查询的select字段重叠。 key_len：表示索引中所使用的字节数，可通过该列计算查询中使用的索引长度。在不损失精确性的情况下，长度越短越好。key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，并不是通过表内检索出的。 简单理解：possible_keys表示理论上可能用到的索引，key表示实际中使用的索引。 例： possible_keys为NULL表示可能未用到索引，但key=idx_deptid表示在实际查询的过程中进行了索引的全扫描。 ref 显示查询条件等号后面的东西： 如果是常量等值（字符串也是常量，或者数字之类的），则显示const； 如果是连接查询，则会显示关联的字段。 注：由于id相同，因此从上到下执行： tb_emp表为非唯一性索引扫描，实际使用的索引列为idx_name，由于tb_emp.name='rose'为一个常量，所以ref=const。 tb_dept.id为唯一索引扫描，从sql语句可以看出，实际使用了PRIMARY主键索引，ref=db01.tb_emp.deptid表示关联了db01数据库中tb_emp表的deptid字段。 rows 根据表统计信息及索引选用情况大致估算出找到所需记录所要读取的行数。当然该值越小越好。 filtered 百分比值，表示存储引擎返回的数据经过滤后，剩下多少满足查询条件记录数量的比例。 Extra 显示十分重要的额外信息。其取值有以下几个： 使用优先级Using index>Using filesort（九死一生）>Using temporary（十死无生）。也就说出现后面两项表明sql语句是非常烂的，急需优化！！！ 1. Using filesort Using filesort表明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。 mysql中无法利用索引完成的排序操作称为“文件排序”。 出现Using filesort就非常危险了，在数据量非常大的时候几乎“九死一生”。出现Using filesort尽快优化sql语句。 例：deptname字段未建索引的情况。 2. Using temporary 使用了临时表保存中间结果，常见于排序order by和分组查询group by。非常危险，“十死无生”，急需优化。 例：将tb_emp中name的索引先删除，出现如下图结果，非常烂，Using filesort和Using temporary，“十死无生”。 例：为name字段创建索引后。 3. Using index 表明相应的select操作中使用了覆盖索引，避免访问表的额外数据行，效率不错。 例：为deptname字段创建索引后。 如果同时出现了Using where，表明索引被用来执行索引键值的查找。（where deptid=1） 例：删除tb_emp表中name和deptid字段的单独索引，创建复合索引。 通过上面的例子理解：创建了（name，deptid）的复合索引，查询的时候也使用复合索引或部分，这就形成了覆盖索引。 如果没有同时出现Using where，表明索引用来读取数据而非执行查找动作。 总结 explain（执行计划）包含的信息十分的丰富，着重关注以下几个字段信息。 id，select子句或表执行顺序，id相同，从上到下执行，id不同，id值越大，执行优先级越高。 type，type主要取值及其表示sql的好坏程度（由好到差排序）：system>const>eq_ref>ref>range>index>ALL。保证range，最好到ref。 key，实际被使用的索引列。 ref，关联的字段，常量等值查询，显示为const，如果为连接查询，显示关联的字段。 Extra，额外信息，使用优先级Using index>Using filesort（九死一生）>Using temporary（十死无生）。 着重关注上述5个字段信息，对日常生产过程中调优十分有用。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section9/":{"url":"chapter8/section9/","title":"8.9 日志","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 redo log 刷盘策略 存储机制 redo log存在的必要性 bin log 存储机制 刷盘策略 两阶段提交 undo log 日志 MySQL 日志 主要包括5大类： 错误日志、 查询日志、 慢查询日志、 事务日志 redo log（重做日志）和 undo log（回滚日志） 二进制日志 binlog（归档日志） MySQL InnoDB 引擎使用 redo log(重做日志) 保证事务的持久性，使用 undo log(回滚日志) 来保证事务的原子性。 MySQL数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性。 redo log redo log 是物理日志，记录内容是“在某个数据页上做了什么修改”，是InnoDB存储引擎独有的，它让MySQL拥有了崩溃恢复能力。 MySQL实例挂了或宕机了，重启时，InnoDB存储引擎会使用redo log恢复数据，保证数据的持久性与完整性。 mysql实例：是应用程序,是位于用户与操作系统之间的一层数据管理软件，用户对数据库进行操作，包括定义表结构，数据查询，数据维护等控制，都是在数据库实例下进行的，可以这样理解，应用程序通过数据库实例才能和数据库打交道。 mysql中用户创建与数据库的连接，是与实例之间搭上了桥梁，然后建立会话，是在这条桥梁上进行沟涌。 MySQL中建立一个会话session，不是和具体的数据库相连接，而是跟某个instance建立好的连接里创建会话（每个会话可以使用不同的用户身份）。 例：如果以打电话来比喻：connect就好比你接通对方，这时，connect就建立了，有没有通话，不管。双方进行通话，则session建立了，如果换人，则新的session建立，原session结束，类似的，可以在同一个connect上进行多个会话。最后，挂机，connect结束。 MySQL 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool 中。 后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能。 更新表数据的时候，也是如此，发现 Buffer Pool 里存在要更新的数据，就直接在 Buffer Pool 里更新。 然后会把“在某个数据页上做了什么修改” 记录到重做日志缓存（redo log buffer）里【必做】， 接着刷盘（写到磁盘）到 redo log 文件里【刷盘策略】。 注：每条 redo 记录由“表空间号+数据页号+偏移量+修改数据长度+具体修改的数据”组成 刷盘策略 innodb_flush_log_at_trx_commit 参数 0 ：每次事务提交时不刷盘 1 ：每次事务提交时都将会调用 fsync把 redo log buffer 内容刷盘（默认值） 2 ：每次事务提交时都只把 redo log buffer 内容写入 page cache（文件系统缓存） 注：InnoDB 存储引擎有一个后台线程，每隔1 秒，会先进行2,然后再将page cache内容刷盘的操作。 也就是说，一个没有提交事务的数据页修改记录，也可能会刷盘到redo log。 当 redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动刷盘。 分析： 为0时，若后台线程刚刷盘了redo log，有1秒的真空期，此时某个事务在这1秒内提交了，并且在提交前，所有的修改记录都已经记录在了redo log buffer里，但是刚提交完，mysql实例就宕了，那么redo log buffer和buffer pool里的数据自然就没了，因此会丢失最多1秒内的数据修改。 为1时， 只要事务提交成功，redo log记录就一定在硬盘里，不会有任何数据丢失。如果事务执行期间MySQL挂了或宕机，这部分日志丢了，但是事务并没有提交，所以日志丢了也不会有损失。 为2时， 只要事务提交成功，redo log buffer中的内容只写入文件系统缓存（page cache）。 如果仅仅只是MySQL挂了不会有任何数据丢失，mysql重启后，可以对page cache的内容进行刷盘，但是计算机系统宕机可能会有1秒数据的丢失。 存储机制 https://snailclimb.gitee.io/javaguide/#/docs/database/mysql/MySQL%E4%B8%89%E5%A4%A7%E6%97%A5%E5%BF%97?id=redo-log redo log存在的必要性 实际上，数据页大小是16KB，刷盘比较耗时，可能就修改了数据页里的几 Byte 数据，有必要把完整的数据页刷盘吗？ 而且数据页刷盘是随机写，因为一个数据页对应的位置可能在硬盘文件的随机位置，所以性能是很差。 如果是写 redo log，一行记录可能就占几十 Byte，只包含表空间号、数据页号、磁盘文件偏移 量、更新值，再加上是顺序写，所以刷盘速度很快。 所以用 redo log 形式记录修改内容，性能会远远超过刷数据页的方式，这也让数据库的并发能力更强。 注：通过redo log的存储数据结构，可以知道，每次修改了数据库中的内容，并不是真正的将“修改”记录到磁盘中，而是将“修改”刷盘到redo log；每次 MySQL 加载redo log,恢复数据时（这时才真正地将之前修改过的数据写进了磁盘），会清空之前加载过的 redo log 记录，并把 checkpoint 后移更新。 注：其实内存中buffer poll的数据页在一定时机也会刷盘，我们把这称为页合并， bin log binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于MySQL Server 层。 不管用什么存储引擎，只要发生了表数据更新，都会产生 binlog 日志。 binlog会记录所有涉及更新数据的逻辑操作，并且是顺序写。 主要作用保证数据一致性: 数据备份、 主备同步、 主主同步、 主从同步. 存储机制 https://snailclimb.gitee.io/javaguide/#/docs/database/mysql/MySQL%E4%B8%89%E5%A4%A7%E6%97%A5%E5%BF%97?id=binlog 刷盘策略 事务执行过程中，先把日志写到binlog cache， 事务提交的时候，再把binlog cache写到binlog文件中。 因为一个事务的binlog不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为binlog cache。 我们可以通过binlog_cache_size参数控制单个线程 binlog cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘（Swap）。 binlog日志刷盘流程如下: 上图的 write，是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快; 上图的 fsync，才是将数据持久化到磁盘的操作; write和fsync的时机，可以由参数sync_binlog控制， 0，(默认)表示每次提交事务都只write，由系统自行判断什么时候执行fsync【虽然性能得到提升，但是机器宕机，page cache里面的 binglog 会丢失。】。 1，表示每次提交事务都会执行fsync，就如同binlog 日志刷盘流程一样。 N(N>1)，表示每次提交事务都write，但累积N个事务后才fsync。 在出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。 两阶段提交 redo log（重做日志）让InnoDB存储引擎拥有了崩溃恢复能力。 binlog（归档日志）保证了MySQL集群架构的数据一致性。 二者的区别： 在执行更新语句过程，以基本的事务为单位， redo log在事务执行过程中可以不断写入（后台线程）， 而binlog只有在提交事务时才写入， 所以redo log与binlog的写入时机不一样，但有可能导致redo log与binlog两份日志之间的逻辑不一致（即记录的内容不一样），这会出现问题！ 例：以update语句为例，假设id=2的记录，字段c值是0，把字段c值更新成1，SQL语句为 update T set c=1 where id=2 问：假设执行过程中写完redo log日志后，binlog日志写期间发生了异常，会出现什么情况呢？ 答：由于binlog没写完就异常，这时候binlog里面没有对应的修改记录。因此，之后集群用binlog日志恢复数据时，就会少这一次更新，恢复出来的这一行c值是0，而原库因为redo log日志恢复，这一行c值是1，最终数据不一致，如图： 为了解决两份日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案。 原理很简单，将redo log的写入拆成了两个状态prepare和commit进行标记，这就是两阶段提交。 也就是说以前怎么做的就怎么做，有后台线程刷盘就刷盘，只是说多了两个标记，在事务提交前，redo log存进磁盘里的记录标记为prepare，而只有当提交事务后，并且bin log正常刷盘后才能将redo log中之前写入磁盘里的记录标记为commit，如图： 使用两阶段提交后，写入binlog时发生异常也不会有影响，因为MySQL根据redo log日志恢复数据时， 发现redo log还处于prepare阶段，并且没有对应binlog日志，就会回滚该事务。 问：redo log设置commit阶段发生异常，会不会回滚事务？ 答：不会回滚事务，虽然redo log是处于prepare阶段，但是能通过事务id找到对应的binlog日志，所以MySQL认为是完整的，就会提交事务恢复数据。 undo log undo: 撤销，即回滚。 想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，在 MySQL 中，恢复机制是通过 回滚日志（undo log） 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 回滚日志 中的信息将数据回滚到修改之前的样子即可！并且， 回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section10/":{"url":"chapter8/section10/","title":"8.10 mvcc","keywords":"","body":"mvcc 多版本并发控制： 每行记录隐藏的3个字段； 其中一个字段类似指针，指向可以回退的该记录的不同版本，形成的链表称为update undo-log readview中的不同字段记录了不同的事务id集合 在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。 每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改。 事务开始后，根据隔离级别的不同，如分别在RC和RR下，前一个是在每次select前生成readview，而后一个是只有第一次select前生成快照readview，这也就是RC导致了不可重复读的问题，而RR解决了这个问题。 InnoDB 在实现Repeatable Read 时， MVCC实现了一致性非锁定读，解决了幻读（只能读取到第一次查询之前所插入的数据）； 如果执行的是锁定读（又叫当前读，每次都读取最新的记录，如更新操作），则会对读取的记录使用 Next-key Lock（行锁+间隙锁），来防止其它事务在间隙间插入数据（解决幻读）。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section11/":{"url":"chapter8/section11/","title":"8.11 mysql常用操作","keywords":"","body":"mysql常用操作 https://snailclimb.gitee.io/javaguide/#/docs/database/mysql/%E4%B8%80%E5%8D%83%E8%A1%8CMySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section12/":{"url":"chapter8/section12/","title":"8.12 设计规范","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 Mysql性能优化max_allowed_packet 一、max_allowed_packet是什么？ 二、什么情况下遇到？ 三、解决办法？ 设计规范 https://snailclimb.gitee.io/javaguide/#/docs/database/mysql/MySQL%E9%AB%98%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E8%A7%84%E8%8C%83%E5%BB%BA%E8%AE%AE Mysql性能优化max_allowed_packet 一、max_allowed_packet是什么？ 指mysql服务器端和客户端在一次传送数据包的过程当中最大允许的数据包大小。 二、什么情况下遇到？ 有时候大的插入和更新会被max_allowed_packet 参数限制掉，导致失败。 场景一：将本地数据库迁移到远程数据库时运行sql错误。错误信息是max_allowed_packet 场景二：插入数据时某个字段数据过于庞大(使用Elmentui编辑器自带的图片加密，图片过多，地址超级长，最好用的时候改成自定义的)，会报 Packet for query is too large (20682943>1048576). You can change this value on the server by setting the max_allowed_packet’ variable. 三、解决办法？ 调整mysql的配置文件 mysql 56中该参数修改好像无效，所以需要升级数据库到mysql57 window下修改配置文件my.ini 在mysqld段下添加 max_allowed_packet = 64M 后面的数字根据实际情况调优 linux下修改etc/my.cnf ,同样在mysqld段下添加 max_allowed_packet = 64M 注意改完参数后需要重启mysql服务 查看目前配置 show VARIABLES like '%max_allowed_packet%'; 临时修改set global max_allowed_packet = 10 * 1024 * 1024; 注意： 命令行修改时，不能用M、G，只能这算成字节数设置。配置文件修改才允许设置M、G单位。 命令行修改之后，需要退出当前回话(关闭当前mysql server链接)，然后重新登录才能查看修改后的值。通过命令行修改只能临时生效，下次数据库重启后又复原了。 max_allowed_packet 最大值是1G(1073741824)，如果设置超过1G，查看最终生效结果也只有1G。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section13/":{"url":"chapter8/section13/","title":"8.13 分布式锁","keywords":"","body":"分布式锁 DB分布式锁的实现：通过主键id的唯一性进行加锁，说白了就是加锁的形式是向一张表中插入一条数据，该条数据的id就是一把分布式锁，例如当一次请求插入了一条id为1的数据，其他想要进行插入数据的并发请求必须等第一次请求执行完成后删除这条id为1的数据才能继续插入，实现了分布式锁的功能。 def lock ： exec sql: insert into locked-table (xxx) values (xxx) if result == true : return true else : return false def unlock ： exec sql: delete from locked-table where order_id='order_id' 使用流水号+时间戳做幂等操作，可以看作是一个不会释放的锁。即每一个线程的操作都记录下来，根据记录的个数来决定如商品减少的个数之类的原子操作。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section14/":{"url":"chapter8/section14/","title":"8.14 sql练习","keywords":"","body":"sql练习 -- 学生表 create table Student(SId varchar(10),Sname varchar(10),Sage datetime,Ssex varchar(10)); insert into Student values('01' , '赵雷' , '1990-01-01' , '男'); insert into Student values('02' , '钱电' , '1990-12-21' , '男'); insert into Student values('03' , '孙风' , '1990-12-20' , '男'); insert into Student values('04' , '李云' , '1990-12-06' , '男'); insert into Student values('05' , '周梅' , '1991-12-01' , '女'); insert into Student values('06' , '吴兰' , '1992-01-01' , '女'); insert into Student values('07' , '郑竹' , '1989-01-01' , '女'); insert into Student values('09' , '张三' , '2017-12-20' , '女'); insert into Student values('10' , '李四' , '2017-12-25' , '女'); insert into Student values('11' , '李四' , '2012-06-06' , '女'); insert into Student values('12' , '赵六' , '2013-06-13' , '女'); insert into Student values('13' , '孙七' , '2014-06-01' , '女'); -- 科目表 create table Course(CId varchar(10),Cname nvarchar(10),TId varchar(10)); insert into Course values('01' , '语文' , '02'); insert into Course values('02' , '数学' , '01'); insert into Course values('03' , '英语' , '03'); -- 教师表 create table Teacher(TId varchar(10),Tname varchar(10)); insert into Teacher values('01' , '张三'); insert into Teacher values('02' , '李四'); insert into Teacher values('03' , '王五'); -- 成绩表 create table SC(SId varchar(10),CId varchar(10),score decimal(18,1)); insert into SC values('01' , '01' , 80); insert into SC values('01' , '02' , 90); insert into SC values('01' , '03' , 99); insert into SC values('02' , '01' , 70); insert into SC values('02' , '02' , 60); insert into SC values('02' , '03' , 80); insert into SC values('03' , '01' , 80); insert into SC values('03' , '02' , 80); insert into SC values('03' , '03' , 80); insert into SC values('04' , '01' , 50); insert into SC values('04' , '02' , 30); insert into SC values('04' , '03' , 20); insert into SC values('05' , '01' , 76); insert into SC values('05' , '02' , 87); insert into SC values('06' , '01' , 31); insert into SC values('06' , '03' , 34); insert into SC values('07' , '02' , 89); insert into SC values('07' , '03' , 98); -- 1. 查询\" 01 \"课程比\" 02 \"课程成绩高的学生的信息及课程分数 /* select * from student s right JOIN (select t1.SId, class1, class2 from (select SId, score as class1 from sc where CId = '01') as t1, (select SId, score as class2 from sc where CId = '02') as t2 where t1.SId = t2.SId and t1.class1>t2.class2) t on s.SId=t.SId */ -- 1.1 查询同时存在\" 01 \"课程和\" 02 \"课程的情况 /* select t1.SId, class1, class2 from (select SId, score as class1 from sc where CId = '01') as t1, (select SId, score as class2 from sc where CId = '02') as t2 where t1.SId = t2.SId */ -- 1.2 查询存在\" 01 \"课程但可能不存在\" 02 \"课程的情况(不存在时显示为 null ) /* select t1.SId, class1, class2 from (select SId, score as class1 from sc where CId = '01') as t1 left JOIN (select SId, score as class2 from sc where CId = '02') as t2 on t1.SId = t2.SId */ -- 1.3 查询不存在\" 01 \"课程但存在\" 02 \"课程的情况 /* select * from sc where sc.SId not in ( select SId from sc where sc.CId = '01' ) AND sc.CId= '02'; */ -- 2. 查询平均成绩大于等于 60 分的同学的学生编号和学生姓名和平均成绩 /* select s.SId,Sname,t.avgscore from student s INNER JOIN (select SId,avg(score) as avgscore from sc GROUP BY SId HAVING AVG(score)>= 60) t on s.SId=t.SId */ -- 3. 查询在 SC 表存在成绩的学生信息 /* select distinct s.* from student s , sc t where s.SId=t.SId */ -- 4. 查询所有同学的学生编号、学生姓名、选课总数、所有课程的总成绩(没成绩的显示为 null ) /* select s.SId, Sname, counts, sums from student s LEFT JOIN (select SId, count(score) as counts, sum(score) as sums from sc GROUP BY SId) t on s.SId=t.SId */ -- 4.1 查有成绩的学生信息 /* select * from student s where exists(SELECT 1 from sc where s.SId=sc.SId) */ -- 5. 查询「李」姓老师的数量 /* select count(TId) from teacher where Tname LIKE '李%' */ -- 6. 查询学过「张三」老师授课的同学的信息 /* select student.* from student,teacher,course,sc where student.sid = sc.sid and course.cid=sc.cid and course.tid = teacher.tid and tname = '张三'; */ -- 7. 查询没有学全所有课程的同学的信息 /* SELECT s.* from student s where s.SId not in (select SId from sc GROUP BY SId HAVING count(CId)=(select count(CId) from course)) */ -- 8. 查询至少有一门课与学号为\" 01 \"的同学所学相同的同学的信息 /* select s.* from student s, (select DISTINCT SId from sc where CId in (select CId from sc where SId = '01') and SId != '01') t where s.SId=t.SId */ -- 9. 查询和\" 01 \"号的同学学习的课程 完全相同的其他同学的信息 /* select s.* from student s, (select SId from sc GROUP BY SId having GROUP_CONCAT(CId ORDER BY CId)=(select GROUP_CONCAT(CId ORDER BY CId) from sc where SId = '01' ) and SId != '01') t where s.SId=t.SId */ -- 10. 查询没学过\"张三\"老师讲授的任一门课程的学生姓名 /* select * from student where SId not in (select SId from sc where CId in (select CId from course,teacher where course.TId=teacher.TId and Tname='张三')) */ -- 11. 查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩 /* select t.SId,Sname,avgs from student,( select SId,avg(score) as avgs from sc where score=2) t where student.SId=t.SId */ -- 12. 检索\" 01 \"课程分数小于 60，按分数降序排列的学生信息 select student.* from student,( select SId from sc where CId='01' and score=60，中等为：70-80，优良为：80-90，优秀为：>=90 -- 要求输出课程号和选修人数，查询结果按人数降序排列，若人数相同，按课程号升序排列 /* select sc.CId,count(SId) as counts,Cname,max(score),min(score),avg(score), sum(case when score >= 60 then 1 else 0 end)/count(SId) '及格率', sum(case when score >= 70 and score = 80 and score = 90 then 1 else 0 end)/count(SId) '优秀率' from sc RIGHT JOIN course c on c.CId=sc.CId group by sc.CId order by counts desc, sc.CId asc */ -- 15. 按各科成绩进行排序，并显示排名， Score 重复时保留名次空缺 /* select a.CId,a.SId,a.score,count(b.score)+1 as rank from sc a left JOIN sc b on a.CId = b.CId and a.score=60 and score =60 and score =70 and score =70 and score =85 and score =85 and score 1; */ -- 24. 查询 1990 年出生的学生名单 /* select * from student where YEAR(student.Sage)=1990; */ -- 25. 查询每门课程的平均成绩，结果按平均成绩降序排列，平均成绩相同时，按课程编号升序排列 /* select sc.cid, course.cname, AVG(SC.SCORE) as average from sc, course where sc.cid = course.cid group by sc.cid order by average desc,cid asc; */ -- 26. 查询平均成绩大于等于 85 的所有学生的学号、姓名和平均成绩 /* select student.sid, student.sname, AVG(sc.score) as aver from student, sc where student.sid = sc.sid group by sc.sid having aver > 85; */ -- 27. 查询课程名称为「数学」，且分数低于 60 的学生姓名和分数 /* select student.sname, sc.score from student, sc, course where student.sid = sc.sid and course.cid = sc.cid and course.cname = \"数学\" and sc.score = 70) t, course c where s.SId = t.SId and c.CId=t.cid */ -- 30. 查询不及格的课程 /* select DISTINCT sc.CId from sc where sc.score =80 and student.sid = sc.sid; */ -- 32. 求每门课程的学生人数 /* select sc.CId,count(*) as 学生人数 from sc GROUP BY sc.CId; */ -- 33. 成绩不重复，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩 /* select student.*, sc.score, sc.cid from student, teacher, course,sc where teacher.tid = course.tid and sc.sid = student.sid and sc.cid = course.cid and teacher.tname = \"张三\" order by score desc limit 1; */ -- 34. 成绩有重复的情况下，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩 /* UPDATE sc SET score=90 where sid = \"07\" and cid =\"02\"; select student.*, sc.score, sc.cid from student, teacher, course,sc where teacher.tid = course.tid and sc.sid = student.sid and sc.cid = course.cid and teacher.tname = \"张三\" and sc.score = ( select Max(sc.score) from sc,student, teacher, course where teacher.tid = course.tid and sc.sid = student.sid and sc.cid = course.cid and teacher.tname = \"张三\" ); */ -- 35. 查询不同课程成绩相同的学生的学生编号、课程编号、学生成绩 /* select a.cid, a.sid, a.score from sc as a inner join sc as b on a.sid = b.sid and a.cid != b.cid and a.score = b.score group by cid */ -- 36. 查询每门课程成绩最好的前两名 /* select a.sid,a.cid,a.score from sc as a left join sc as b on a.cid = b.cid and a.score5; */ -- 38. 检索至少选修两门课程的学生学号 /* select sid, count(cid) as cc from sc group by sid having cc>=2; */ -- 39. 查询选修了全部课程的学生信息 /* select student.* from sc ,student where sc.SId=student.SId GROUP BY sc.SId HAVING count(*) = (select DISTINCT count(*) from course ) */ -- 40. 查询各学生的年龄，只按年份来算【看第41题】 -- 41. 按照出生日期来算，当前月日 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section15/":{"url":"chapter8/section15/","title":"8.15 名词解释","keywords":"","body":"名词解释 https://www.cnblogs.com/fudashi/p/6856628.html 数据：数据就是数据库中存储的基本数据，比如学生的学号、学生的班级 数据库：存放数据的仓库 数据库管理系统：数据库软件，如MySQL、Oracle 数据库系统：数据库+数据库管理系统+应用程序+数据库管理员（大佬） 实体：客观存在的对象，比如一个学生，一位老师 属性：实体的特性，比如学生的学号、姓名、院系 码：可唯一标识实体的属性集。比如学号是学生的码，一个学号唯一标识一名学生。学号和课程号是成绩的码，因为学号和课程号唯一标识一门课程的成绩 实体型：对实体的描述，比如学生（学号，姓名，院系） 实体集：实体的集合 联系：实体集之间的关系。一名学生对应一个寝室（一对一），一个院系对应多名学生（一对多），多位教师对应多名学生（多对多） 关系：若干元组的集合，说白了就是指数据库表 关系模式：对关系的描述称为关系模式，最后会详细描述 关系模型：若干关系的集合，也就是一个数据库 属性（关系）：相对于前面的属性的意义，这里特指数据库表中的某列 元组：一条数据库记录 分量：元组中某一属性值 域：一组具有相同数据类型的值的集合，是属性的取值范围，比如性别属性的域就是{男，女}，学生学历属性的域就是{学士、硕士、博士、院士} 候选码：可唯一标识某一元组的属性组，属性组中各个属性缺一不可。【t_student】（学号，姓名，学院），姓名可能会重复，所以其中学号可以唯一标识一条记录，学号就是t_student的候选码。那么假设姓名不会重复，那么候选码就有学号和姓名两个。 又比如【t_grade】（学号，课程，成绩），其中一个学生可以有多条成绩记录，所以需要学号和课程号组合才可以唯一标识一条数据库记录，所以学号、课程号就是t_student的一个候选码。 超码：只要一个属性组可以唯一标识一个元组，那么就说这个属性组是超码 【t_student】（学号，姓名，学院），姓名可能会重复，所以（学号）是一个超码同时也是候选码，（学号，姓名）可唯一标识一个元组，所以其也是超码，但不是候选码，因为少了姓名也可以唯一标识。 主属性：候选码中的属性称为主属性。【t_student】（学号，姓名，学院），学号就是主属性 非主属性：不是主属性就是非主属性呗。【t_student】（学号，姓名，学院），姓名、学院就是非主属性 全码：极端情况下表的所有属性组成该表的候选码，则称为全码 主键/主码：primary key，一个表可能有多个，往往选中一个作为主键 外键/外码：foreign key，假设表A的某个属性attr是另一表B中的主码，且A和B有某种联系，则称attr是外码 参照表：外码所在的表 被参照表：外码所引用（foreign key references）的表 数据完整性：数据完整性就是指数据的正确性和相容性（符合逻辑），又分为实体完整性、参照完整性、用户自定义完整性 实体完整性：主码唯一且不为空 参照完整性：不允许引用不存在的实体。参照表插入某条记录，这条记录的外码在被参照表中必须存在 用户自定义完整性：由用户自定义的数据约束。比如性别只能用男、女表示，人的年龄在0-120之间。常见的用户自定义完整性有NOT NULL，UNIQUE，CHECK等 内模式：对数据库的物理存储结构和存储方式的描述，是数据库在数据库内部的存储方式。拿MySQL来讲，每建一个表，都会在文件系统上生成一个或多个文件，这些文件存储了数据、表信息、索引信息，这就称为内模式 模式：对内模式的抽象，即数据库 外模式：对模式的抽象，即用户直接使用的应用程序 外模式-模式映像：保证数据的逻辑独立性。当模式改变时（增加表，增加表的结构），可以保证外模式不变 模式-内模式映像：保证数据的物理独立性。当内模式改变时（比如MySQL切换了存储引擎），可以保证模式不变，从而外模式也不会变。 关系模式 关系模式是对关系的描述（有哪些属性，各个属性之间的依赖关系如何）， 模式的一个具体值称为模式的一个实例。 模式反应是数据的结构及其联系，是型，是相对稳定的， 实例反应的是关系某一时刻的状态，是值，是相对变动的。 想要查看t_student的关系模式？DESC t_student 想要查看t_student的关系实例？SELECT * FROM student 另外，关系模式有约定的数学表示，R（U，D，DOM，F）， R指关系名， U指一组属性， D指域， DOM指属性到域的映射， F就是指数据依赖。 举个栗子，假设一个学生表t_student，拥有属性学号，姓名，性别，学院，其数学表示如图。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section16/":{"url":"chapter8/section16/","title":"8.16 视图","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 定义 语法 视图的作用 对视图进行更新操作(INSERT或UPDATE) 视图 https://blog.csdn.net/kxbarcode/article/details/81660934 定义 视图(VIEW)也被称作虚表，即虚拟的表，是一组数据的逻辑表示,其本质是对应于一条SELECT语句，结果集被赋予一个名字，即视图名字。 视图本身并不包含任何数据，它只包含映射到基表的一个查询语句，当基表数据发生变化，视图数据也随之变化。 说白了，视图就是一条select语句。 根据视图所对应的子查询种类分为几种类型: 简单视图：SELECT语句是基于单表建立的，且不包含任何函数运算、表达式或分组函数，此时视图是基表的子集； 复杂视图：SELECT语句同样是基于单表，但包含了单行函数、表达式、分组函数或GROUP BY子句； 连接视图：SELECT语句是基于多个表的。 语法 创建一个简单视图V_EMP_10，来显示部门10中的员工的编码、姓名和薪水： CREATE VIEW v_emp_10 [alias] AS SELECT empno, ename, sal, deptno FROM emp WHERE deptno = 10; 查看视图结构： DESC v_emp_10; 查询视图和查询表的操作相同： SELECT * FROM v_emp_10; #此时视图的列名，和创建视图时的列名一致， 视图的作用 简化复杂查询：如果需要经常执行某项复杂查询，可以基于这个复杂查询建立视图，此后查询此视图即可； 限制数据访问：视图本质上就是一条SELECT语句，所以当访问视图时，只能访问到所对应的SELECT语句中涉及到的列，对基表中的其它列起到安全和保密的作用。 对视图进行更新操作(INSERT或UPDATE) 简单视图能够执行DML操作，除了： 在基表中定义了非空列，但简单视图对应的SELECT语句并没有包含这个非空列，导致这个非空列对视图不可见； 如果视图定义中包含了函数、表达式、分组语句、DISTINCT关键字或ROWNUM伪列； 违反基表的约束条件。 # 简单视图可以通过DML操作影响到基表数据。 INSERT INTO v_emp_10 VALUES(1234, ‘DOCTOR’, 4000, 10); Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section17/":{"url":"chapter8/section17/","title":"8.17 information_schema","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 查询例子 INFORMATION_SCHEMA实例数据表参考文档 information_schema INFORMATION_SCHEMA在每一个MySQL都存在一个实例对象，该实例可以使用，但是只能读取表的内容，不能对其执行INSERT、UPDATE、DELETE操作。 INFORMATION_SCHEMA 提供对数据库元数据、有关MySQL服务器的信息（如数据库或表的名称、列的数据类型或访问权限）的访问。有时用于此信息的其他术语是数据字典和系统目录。 官方推荐使用INFORMATION_SCHEMA替代SHOW方式（SHOW DATABASES, SHOW TABLES）。 对于INFORMATION_SCHEMA中的大多数信息，每个MySQL用户都有权访问它们，但只能看到表中与用户具有适当访问权限的对象相对应的行。在使用表时注意INFORMATION_SCHEMA您必须对某个对象具有某种特权才能查看有关该对象的信息 查询例子 查询MySQL某个数据库下所有的表信息：SELECT table_name 表名称 , table_type 表类型 , engine 存储引擎 FROM information_schema.tables WHERE table_schema = 'test' ----- table_schema: 数据库名称 ORDER BY table_name; 查看当前已登录数据库可以：将'test'替换为(SELECT DATABASE()) 查询当前数据库某个表列以及列的属性信息： SELECT column_name -- 列名称 , CASE WHEN is_nullable = 'no' AND column_key != 'PRI' THEN '1' ELSE NULL END AS is_required -- 是否必须 , CASE WHEN column_key = 'PRI' THEN '1' ELSE '0' END AS is_pk, -- 是否主键 ordinal_position AS sort, -- 列位置 column_comment -- 列注释 , CASE WHEN extra = 'auto_increment' THEN '1' ELSE '0' END AS is_increment -- 是否自增 , column_type -- 列类型 FROM information_schema.columns WHERE table_schema = ( SELECT DATABASE() ) AND table_name = 'scores' ORDER BY ordinal_position; 查询数据库存储引擎属性 SELECT * from INFORMATION_SCHEMA.ENGINES 查询当前正在执行的线程的信息 SELECT * from INFORMATION_SCHEMA.PROCESSLIST 查询所有数据库模式信息 SELECT * from INFORMATION_SCHEMA.SCHEMATA 查询所有的触发器 SELECT * from INFORMATION_SCHEMA.TRIGGERS 查询库中所有用户的权限信息 SELECT * from INFORMATION_SCHEMA.USER_PRIVILEGES 查询所有的视图信息SELECT * from INFORMATION_SCHEMA.VIEWS INFORMATION_SCHEMA实例数据表参考文档 https://dev.mysql.com/doc/refman/8.0/en/information-schema-table-reference.html Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter8/section18/":{"url":"chapter8/section18/","title":"8.18 mysql的乐观锁和悲观锁","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 乐观锁实现 悲观锁实现 mysql的乐观锁和悲观锁 乐观锁本质上也是cas，而悲观锁就是排他锁。 一样的，乐观锁只适合高并发读，低并发写，而悲观锁则相反。 只是实现方式的问题。 乐观锁实现 version方式：一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 悲观锁实现 是由数据库自己实现的，要用的时候，我们直接调用数据库的相关语句就可以了(原理：共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程)，如行锁、读锁和写锁等，都是在操作之前加锁，在Java中，synchronized的思想也是悲观锁。 要使用悲观锁，我们必须关闭mysql数据库的自动提交属性。 set autocommit=0;　　 //设置完autocommit后，我们就可以执行我们的正常业务了。具体如下： //0.开始事务 begin;/begin work;/start transaction; (三者选一就可以) //1.查询出商品信息 select status from t_goods where id=1 for update; //2.根据商品信息生成订单 insert into t_orders (id,goods_id) values (null,1); //3.修改商品status为2 update t_goods set status=2; //4.提交事务 commit;/commit work; 　　注：上面的begin/commit为事务的开始和结束，因为在前一步我们关闭了mysql的autocommit，所以需要手动控制事务的提交，在这里就不细表了。 　　上面的第一步我们执行了一次查询操作：select status from t_goods where id=1 for update;与普通查询不一样的是，我们使用了select…for update的方式，这样就通过数据库实现了悲观锁。此时在t_goods表中，id为1的那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。 　　注：需要注意的是，在事务中，只有SELECT ... FOR UPDATE 或LOCK IN SHARE MODE 相同数据时会等待其它事务结束后才执行，一般SELECT ... 则不受此影响。拿上面的实例来说，当我执行select status from t_goods where id=1 for update;后。我在另外的事务中如果再次执行select status from t_goods where id=1 for update;则第二个事务会一直等待第一个事务的提交，此时第二个查询处于阻塞的状态，但是如果我是在第二个事务中执行select status from t_goods where id=1;则能正常查询出数据，不会受第一个事务的影响。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter9/section1/":{"url":"chapter9/section1/","title":"9.1 总览","keywords":"","body":"总览 缓存key设计：表名:列名:主键名:主键值 1.Redis 支持更丰富的数据类型 2.Redis 支持数据的持久化 3.Redis 目前是原生支持 cluster 模式 4.Redis 使用单线程的多路 IO 复用模型 5.Redis 同时使用了惰性删除与定期删除 Redis6引进的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。因此不需要担心线程安全问题。 淘汰策略：allkeys-lru（least recently used） Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter9/section2/":{"url":"chapter9/section2/","title":"9.2 数据类型","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 string: list: hash: set: sorted set bitmap: Stream 数据类型 string: expire key 60 # 数据在 60s 后过期 setex key 60 value # 数据在 60s 后过期（该命令字符串类型独有） strlen key # 返回 key 所储存的字符串值的长度。 场景：计数 list: rpush,lpop,lpush,rpop,lrange,llen 场景：消息队列 hash: hset,hmset,hexists,hget,hgetall,hkeys,hvals 场景：对象 set: sadd,spop,smembers,sismember,scard,sinterstore,sunion scard mySet # 查看 set 的长度 sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中 场景：求交集或并集 sorted set 相较于set增加了一个权重参数 score: zadd,zcard,zscore,zrange,zrevrange,zrem zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重 zscore myZset value1 # 查看某个 value 的权重 zrevrange myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start 1 为 stop 场景：排行榜 bitmap: setbit 、getbit 、bitcount、bitop setbit mykey 7 1 # 生成7位（这7位全部默认为0），并且设置第7位为1 setbit mykey 8 1 # 增加第8位，设置第8位为1 bitcount mykey # 统计被被设置为 1 的位的数量,return 2; bitop (and/or/not/xor) destkey key1 key2 [key3 ...] and/or/not/xor是后面的key1,key2之间的位运算操作符，将结果保存进destkey 场景：统计 Stream Redis 5.0 新增加的一个数据结构 Stream 可以用来做消息队列，Stream 支持： 发布 / 订阅模式 按照消费者组进行消费 消息持久化（ RDB 和 AOF） 不过，和专业的消息队列相比，还是有很多欠缺的地方比如消息丢失和堆积问题不好解决。 我们通常建议是不需要使用 Redis 来做消息队列的，你完全可以选择市面上比较成熟的一些消息队列比如 RocketMQ、Kafka。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter9/section3/":{"url":"chapter9/section3/","title":"9.3 事务","keywords":"","body":"事务 Redis 中的事务就理解为 ：Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。 multi: 开始事务(在开始事务后可以使用discard丢弃之前输入过的命令） exec: 提交事务 不过一旦我watch过某个变量，要是在事务中你更改了它并提交事务就会让在事务中执行过的操作全部失败。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter9/section4/":{"url":"chapter9/section4/","title":"9.4 穿透与雪崩","keywords":"","body":"穿透与雪崩 缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上 解决：使用布隆过滤器，它说某个元素存在，小概率会误判。布隆过滤器说某个元素不在， 那么这个元素一定不在。 缓存雪崩指缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库 短时间内承受大量请求。 解决：1.避免缓存单点问题，2.设置不同的失效时间比如随机设置缓存的失效时间。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter9/section5/":{"url":"chapter9/section5/","title":"9.5 从单机锁到分布式锁","keywords":"","body":"从单机锁到分布式锁 单机锁选择synchronized还是reentrantlock根据业务需要来。 集群架构下，单机锁无法保证在同一时刻，相同的代码只有一份代码在执行，因此去掉单机锁，改为分布式锁，使用redis的setnx命令存key加锁，在业务完成后再delete掉key进行解锁。 在获得锁后，执行业务过程中，有可能抛出异常，导致没有解锁，因此加finally释放锁。 执行业务过程中，程序所在的机器宕机了，走不到finally，导致没有解锁，需要给key设置过期时间。 setnx与expire不是一个原子操作，如果程序执行完第一步后异常了，第二步jedis.expire(lockKey, expireTime)没有得到执行，相当于这个锁没有过期时间，有产生死锁的可能。因此设置锁à过期时间，这两个步骤加在一起必须是原子的。 当线程A处理业务的实际时间大于key的过期时间，redis会删除掉已经过期的A设置的key,此时B重新设置key加锁，当A处理完业务后，会进行代码的finally删锁，但这时删除的是B设置的key（key名相同）。因此一个线程只能删除自己设置的锁。 和第6点相同情景，理论上会出现在A执行完第一步if判断操作后锁其实已经过期，并且被其它线程获取，这是时候在执行del(lockKey)操作，相当于把别人的锁释放了，因此要保证判断+删除得是原子操作： ①事务 ②lua脚本 扩展： ①如果业务时间大于key的过期时间，给key续期。 ②redis集群主从架构下，为保证高可用，采取主从异步复制，只要主节点存入了key则返回响应成功，如果主节点挂掉，从从结点中新选举出来的主结点将有可能缺少数据，降低了数据一致性。 zookeeper采取主从同步复制，只有从节点完全同步了主节点的数据，才返回响应成功。但降低了并发，即可用性。 因此这种情况下，自己写的有点不靠谱，直接使用redisson. 问题 采用redis方式的分布式锁，如果有集群，当主挂了之后，还未同步到从，那么另外的线程会到从拿锁，引起超卖问题。根本原因是，分布式锁要求的是CP，redis集群是AP，用AP去实现CP是不现实的。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter9/section6/":{"url":"chapter9/section6/","title":"9.6 redis线程模型","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 性能瓶颈 引入多线程 redis线程模型 Redis 服务器是一个事件驱动程序，基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。 性能瓶颈 单线程编程容易并且更容易维护； Redis 的性能瓶颈不在 CPU ，主要在内存和网络； 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。 引入多线程 为了解决性能瓶颈，Redis6.0 引入多线程主要是为了提高网络 IO 读写性能， Redis6.0 虽然引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter9/section7/":{"url":"chapter9/section7/","title":"9.7 缓存过期","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 判断数据过期 过期数据的删除策略 Redis 内存淘汰机制 缓存过期 判断数据过期 redisDb 这个结构体存储着过期字典： typedef struct redisDb { ... dict *dict; //数据库键空间,保存着数据库中所有键值对 dict *expires // 过期字典,保存着键的过期时间 ... } redisDb; 过期字典（可以看作是 hash 表）保存数据过期的时间。 过期字典的key指向 Redis 数据库中的某个 key(键)， 过期字典的value是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。 过期数据的删除策略 常用的过期数据的删除策略就两个： 懒汉删除 ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。 定期删除 ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。 定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 定期删除+懒汉式删除 。 不过，懒汉对没使用到的不会检查，而这部分没被检查到的又没被定期抽到，那么这一部分本该过期的却长期滞留内存造成了内存泄露，继而oom，因此仅仅设置过期时间是不够的。 Redis 内存淘汰机制 Redis 提供 6 种数据淘汰策略： volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的） allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！ 4.0 版本后增加以下两种： volatile-lfu（least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰 allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter9/section8/":{"url":"chapter9/section8/","title":"9.8 redis 持久化机制","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 快照（snapshotting）【RDB】 只追加文件（append-only file）【AOF】 redis 持久化机制（恢复数据） Redis 的持久化方式： 快照（snapshotting，RDB） 只追加文件（append-only file, AOF） 快照（snapshotting）【RDB】 RDB：Redis DataBase 快照持久化是 Redis 默认采用的持久化方式， Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。 Redis 创建快照之后， 可以对快照进行备份，然后将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能）， 还可以将快照留在原地以便重启服务器的时候使用 （恢复数据）。 只追加文件（append-only file）【AOF】 与快照持久化相比，AOF 持久化的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启： appendonly yes 开启 AOF 持久化后，每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到内存缓存 server.aof_buf 中，然后再根据 appendfsync 配置来决定何时将其同步到硬盘中的 AOF 文件。 AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof。 在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是： appendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度 appendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘 appendfsync no #让操作系统决定何时进行同步 为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter9/section9/":{"url":"chapter9/section9/","title":"9.9 缓存常用的3种读写策略","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 旁路（Cache Aside Pattern） 问题 缺陷 读写穿透（Read/Write Through Pattern） 异步缓存写入（Write Behind Pattern） 缓存常用的3种读写策略(保证缓存与数据库的一致性) 3 种缓存读写策略各有优劣，不存在最佳，需要我们根据具体的业务场景选择更适合的。 旁路（Cache Aside Pattern） 平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。 写 ： 先更新 DB； 然后直接删除 cache 。 读 : 从 cache 中读取数据，读取到就直接返回； cache中读取不到的话，就从 DB 中读取数据返回； 再把数据放到 cache 中。 问题 在写数据的过程中，可以先删除 cache ，后更新 DB 么？ 不行，可能会造成多线程读取的数据不一致，即数据库（DB）和缓存（Cache）数据不一致， 比如： 请求1先把cache中的A数据删除 -> 请求2从DB中读取数据->请求1再把DB中的A数据更新。 就和volatile一样，必须保证读之前的写入要对所有的线程可见。 在写数据的过程中，先更新DB，后删除cache就没有问题了么？ 理论上可能会出现数据不一致，不过概率非常小，因为缓存的写入速度远快于数据库的写入速度。 出现不一致的情况，比如： 请求1从DB读数据A->请求2写更新数据 A 到数据库并把删除cache中的A数据->请求1将数据A写入cache。 缺陷 缺陷1：首次请求数据一定不在 cache 的问题 解决办法：可以将热点数据可以提前放入cache 中。 缺陷2：写操作比较频繁的话导致cache中的数据会被频繁被删除，这样会影响缓存命中率 。 解决办法： 数据库和缓存数据强一致场景 ：更新DB的时候同样更新cache，不过我们需要加一个锁/分布式锁来保证更新cache的时候不存在线程安全问题。 可以短暂地允许数据库和缓存数据不一致的场景 ：更新DB的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。 读写穿透（Read/Write Through Pattern） 在 \"旁路\" 之上进行了封装， 写（Write Through）： 先查 cache，cache 中不存在，直接更新 DB。 cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（同步更新 cache 和 DB）。 读(Read Through)： 从 cache 中读取数据，读取到就直接返回 。 读取不到的话，先从 DB 加载，写入到 cache 后返回响应。 异步缓存写入（Write Behind Pattern） \"异步\" 和 \"读写穿透\" 很相似，两者都是由 cache 服务来负责 cache 和 DB 的读写。 \"读写穿透\" 是同步更新 cache 和 DB， 而 \"异步\" 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter10/section1/":{"url":"chapter10/section1/","title":"10.1 认证","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 cookie和session 集群下session-cookie方案 token防止CSRF XSS Json Web Token SSO单点登录 认证 cookie和session cookie和session说白了就是个map。 cookie存放在客户端（如浏览器），记录的内容通常是加密的。 记录用户当前的状态（HTTP 协议是无状态）； 记录和分析用户行为（如看了哪些商品）等。 session保存在服务器端 集群下session-cookie方案 服务器中的session保存已经登录的用户信息，然后将可以识别当前登录用户的id发送给客户端的cookie保存。 通常情况下为了解决集群下的可用性和一致性会有3个方案： hash策略总能让同一个用户的请求落到同一台服务器上； 主从同步，让所有的集群服务器的数据都相同，才返回响应成功； 引入第三方，如redis，来保存用户的信息，替代传统的服务器单机session。 即使cookie被客户端禁用了，也可以用其它方代替，毕竟它本身存的就是一个可以验证用户身份的识别码，随便用个请求参数一样可以代替。 token防止CSRF CSRF（Cross Site Request Forgery）： 跨站请求伪造 。用你的身份去发送一些对你不友好的请求。 使用cookie验证身份时，如果误点击了别人精心构造的恶意链接，而这条链接符合正常链接的请求形式，只不过是你根本不打算做的操作，比如，向某人转账，此时当你点击了这条不知道真正内容是啥的链接，并携带了该网站的cookie（包含身份验证信息）发送到服务器，服务器识别，是本人发起的请求，然后向某人进行了转账。这就是CSRF攻击。【攻击者不需要知道cookie的内容】 而使用token就可以避免这种恶意链接带来的恶果，token本质上就是当用户登录后一串由服务器生成的随机数字，并将该token绑定好该用户，并规定只有请求中包含token参数时，才是一条合法的链接。然后将该token串返回给客户端，由localStorage保存，之后每次发起请求时都应携带该参数（放在请求参数中或在请求头都可以）。 token的两个作用： 必须携带token参数，链接才是合法链接。 服务器验证token参数是否有已经登录的用户进行了合法绑定。 攻击者如果想攻击成功，必须得知道token的具体值，才能伪造某用户的请求 XSS token阻止了CSRF攻击，如果想攻击成功，就必须得知道token的具体值，而XSS就可以获得这些信息。 XSS(Cross Site Scripting)：跨站脚本攻击，为了不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为XSS。恶意攻击者往Web页面里插入恶意Script代码，当用户浏览该页之时，嵌入其中Web里面的Script代码会被执行，从而达到恶意攻击用户的目的。XSS攻击针对的是用户层面的攻击！ 分为两种： 反射型（临时的） 存储型（持久化到数据库） 反射型：请求中有个参数，后台接收到后不做任何检查，也不存放到数据库，总之是在业务中用完了，基于某种需求，需要返回给前台，并将其动态输出在了dom页面（当然，页面刷新一下就没了），如果是参数内容是js，将会被浏览器解释执行。 此时，如果攻击者A发现这个参数可以存放js脚本，并且还会被浏览器解释执行，那么他可以尝试构造一段通过js获取本地cookie或者localStorage里的内容之类的东西，然后将这些内容再发送到他准备好的一个服务器上。A将这段js脚本压缩一下然后放在参数内容里，并将这条请求随便发给某个受害者B， B是该网站的用户，他的浏览器中当然存放着cookie等信息，然后B收到了A给的链接请求，他不知道是啥，反正B点了，然后B构造的js就开始在A的浏览器中执行了，因此A得到了B的cookie和localStorage的信息。 存储型：请求中有个参数，后台仍然不做检查，但是这个参数的内容根据业务需求，需要被存到数据库中，然后再将其返回到前台显示。（如评论一样的东西） 攻击者A构造同样的脚本，只不过这次他不需要构造链接，让其他用户去点击了，他直接利用评论所在的页面会被所有访问过该页面的人看到这一特性，将js拼接到参数中发给服务器。像B这样的用户，只要访问了评论页面，那么脚本执行，A就会收到B的所有存储在本地的信息（只要A想）。 因此即使是token存放进localStorage，只要被XSS攻击，一样以获取到信息，从而替代原用户进行操作。 Json Web Token 之前要验证用户，必须得是前端也存，后端也存，而JWT则只需要前端存，在发起请求到后台后，只需要验证它的真实性即可。 JWT：带签名的 JSON 格式的token。由于它是带有签名的，因此接收者便可以验证它的真实性。 JWT 由 3 部分构成: Header : 描述 JWT 的元数据，定义了生成签名的算法以及 Token 的类型。 Payload : 用来存放实际需要传递的数据（用户id啥的可以表明是哪个用户的信息） Signature（签名）：服务器使用 Header 里面指定的签名算法（默认是 HMAC SHA256），将Header、Payload和一个secret (密钥)做入参，计算生成。 使用JWT 由于cookie不能跨域，因此服务器生成的JWT最好别放cookie里，更好的做法是放在 HTTP Header 的 Authorization 字段中：Authorization: Bearer {Token}。 用户向服务器发送用户名和密码用于登陆系统。 身份验证服务响应并返回了签名的 JWT，上面包含了用户是谁的内容。 用户以后每次向后端发请求都在 Header 中带上 JWT。 服务端检查 JWT 并从中获取用户相关信息。 同样的，JWT只要保存在客户端，就可能被XSS获得。 SSO单点登录 https://www.cnblogs.com/ywlaker/p/6113927.html#!comments 基于JWT。 sso-client 拦截子系统未登录用户请求，跳转至sso认证中心 接收并存储sso认证中心发送的令牌 与sso-server通信，校验令牌的有效性 建立局部会话 拦截用户注销请求，向sso认证中心发送注销请求 接收sso认证中心发出的注销请求，销毁局部会话 sso-server 验证用户的登录信息 创建全局会话 创建授权令牌 与sso-client通信发送令牌 校验sso-client令牌有效性 系统注册 接收sso-client注销请求，注销所有会话 假设认证中心和系统2的url分别是：sso.com、system2.com， 访问system2.com 时因未登录而跳转到sso.com，跳转地址：http://sso.com?service=http://system2.com`（不需要额外信息）`， 此时，就变成了浏览器与http://sso.com站点之间的会话，这个会话因为系统1登录的原因已经被标记为已登录，所以认证中心取一块令牌，根据service参数回跳，并附上令牌，回跳地址：http://system2.com?token=token Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter10/section2/":{"url":"chapter10/section2/","title":"10.2 授权","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 RBAC OAuth 2.0协议 授权码 隐藏式 密码式 凭证式 授权 RBAC 即基于角色的权限访问控制（Role-Based Access Control）：用户通过成为适当角色的成员而获得这些角色的权限。 OAuth 2.0协议 一种授权机制，它的最终目的是为第三方应用颁发一个有时效性的令牌 Token，使得第三方应用能够通过该令牌获取相关的资源。 OAuth 2.0 比较常用的场景就是应用程序的第三方登录或者支付场景。 比如登录王者荣耀，登录界面会用提示用QQ还是微信登录，此时王者荣耀想获得QQ或微信的用户信息用来填充王者荣耀本身的登录信息，此时点击通过QQ登录，紧接着会出现叫你选通过哪一个账号，还询问是否授权的步骤，此时王者荣耀就是第三方应用，而我们通过点击确定授权（发放令牌），之后王者荣耀可以携带令牌访问QQ提供的API获得QQ的用户信息，当然，这些信息是有限制的，而且这个授权的令牌是有时限的（是不是点过授权后，有一段时间都不会再叫你登录了），当时限过去后，表示你给的授权的令牌失效了，需要重新授权，即重新登录。 OAuth 引入了一个授权层，用来分离不同的角色： 客户端（王者荣耀） 资源所有者（我） 资源服务器（QQ） 四种授权方式 授权码（authorization-code）：前后端分离的web应用 隐藏式（implicit）：纯前端 密码式（password） 客户端凭证（client credentials） 不管哪一种授权方式，第三方应用申请令牌之前，都必须先到系统备案，说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client ID）和客户端密钥（client secret）。这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。 以下通过B网站授权给A说明。 授权码 指的是第三方应用先申请一个授权码，然后再用该码获取令牌。 ①A网站前台提供一个链接到B申请获得授权码（将A接收授权码的后台地址传过去）。 ②A网站后台收到授权码，在后端向 B 网站发起RPC，请求令牌（将A接收令牌的后台地址传过去）。 ③A网站后台收到一段包含令牌的json数据。 隐藏式 直接返回令牌 ①A网站前台提供一个链接到B申请获得令牌（将A接收授权码的前台地址传过去）。 ②A网站前台通过锚点接收令牌（https://a.com/callback#token=ACCESS\\_TOKEN） OAuth 2.0 允许跳转网址是 HTTP 协议，因此存在\"中间人攻击\"的风险，而浏览器跳转时，锚点不会发到服务器，就减少了泄漏令牌的风险。 用于一些安全要求不高的场景，并且令牌的有效期必须非常短，通常就是会话期间（session）有效，浏览器关掉，令牌就失效了。 密码式 如果你高度信任某个应用，RFC 6749 也允许用户把用户名和密码，直接告诉该应用。该应用就使用你的密码，申请令牌，这种方式称为\"密码式\"（password）。 ①A 网站要求用户提供 B 网站的用户名和密码。 ②A 有了用户名和密码就直接向 B 请求令牌（请求成功后，直接返回包含令牌的json）。 凭证式 命令行获得令牌，针对第三方应用，而不是针对用户的，即有可能多个用户共享同一个令牌。 ①A通过命令行直接向B申请获得令牌（请求成功后，直接返回包含令牌的json）。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter11/details.html":{"url":"chapter11/details.html","title":"11. shiro篇","keywords":"","body":"shiro篇 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter12/section1/":{"url":"chapter12/section1/","title":"12.1 $(document)&$(window)","keywords":"","body":"$(document)&$(window) document是window的一个属性 $(document)在dom结构绘制完毕后，就执行 $(window)必须等到页面内包括加载完各种js、css、image、iframe/frame资源才执行。 $(parent)parent就是父元素的window对象(iframe中用到） 所有浏览器都支持 window 对象。它表示浏览器窗口。 所有 JavaScript 全局对象、函数以及变量均自动成为 window 对象的成员。 全局变量是 window 对象的属性。 全局函数是 window 对象的方法。 甚至 HTML DOM 的 document 也是 window 对象的属性之一 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter12/section2/":{"url":"chapter12/section2/","title":"12.2 宽高自适应","keywords":"","body":"宽高自适应 有两种 一、子元素设固定宽高，父元素设置inline-block，父元素宽高就可以随子元素的宽高变化 不过当父元素设置了inline-block后就不仅会受到block特性的换行符影响，还会受到inline的lineheight、fontsize以及vertical-align的共同影响， 其中最重要的是line-height,因为当你为父元素设置了inline-block后，你会发现父元素的实际高度总是要比子元素高一些，这就是line-height在起作用，此时只要把父元素的line-height设为0，就可以解决此问题。 二、父元素设固定宽高，子元素设置宽高100%，子元素随父元素变化 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter12/section3/":{"url":"chapter12/section3/","title":"12.3 div垂直居中","keywords":"","body":"div垂直居中 子div在父div垂直居中的最好方法 父div设display:flex;align-items:center; 此处注明一个以前我一直以为可以垂直居中的使用方法，其实是错误的，如果不信，可以自己自行试一遍就知道了。 下面是详细的错误方法 父div设vertical-align:middle;还要设line-height 子div设display:inline-block; 两个div都是有高度的。 事实上子div在父div中并没有垂直居中（文字垂直居中了，但是也不是绝对意义上的），自行尝试以上设置。 这里讲一下为什么我会被骗，以为可以垂直居中。 首先一个父div，两个子div. 其中两个子div高度不同。 然后通过上述设置后，会发现两个子div是默认底部对齐，并且两个子div相对父div也绝不是垂直居中（绝对意义上的） 这时有意思的就来了，你在两个子div中相对较高的那个插入vertical-align:middle; 你看一下效果，是不是好像两个子div就相对于父div垂直居中了。 解释： 其实，当你对较高的子div设置了vertical-align:middle后，就是指这个子div（inline-block）里的内容要垂直居中，那么相对于子div来说（因为之前里面的东西是底部对齐），它就往下移了。 不懂的，仔细看两遍，或者自己实验一下就明白了。 以前一直没注意过这个问题，希望能帮助到大家。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter12/section4/":{"url":"chapter12/section4/","title":"12.4 css渲染过程及reflow和repaint","keywords":"","body":"css渲染过程及reflow和repaint css的渲染过程 1、根据HTML的结构生成DOM树（DOM树中包含了display:none的节点） 2、在DOM树的基础上，根据节点的几何属性（margin/padding/width/height/left等）生成render树 3、在render树的基础上继续渲染color,font等属性 其中如果1中和2中的属性发生变化会发生reflow(回流)，如果仅仅3中的属性发生改变，只会发生repaint（重绘）。显然从css的渲染过程我们也可以看出来：reflow(回流）必伴随着重绘。 reflow(回流)：当render树中的一部分或者全部因为大小边距等问题发生改变而需要重建的过程叫做回流 repaint(重绘)：当元素的一部分属性发生变化，如外观背景色不会引起布局变化而需要重新渲染的过程叫做重绘 reflow（回流）会影响浏览器css的渲染速度，因此在做网页性能优化的时候要减少回流的发生。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter12/section5/":{"url":"chapter12/section5/","title":"12.5 闭包","keywords":"","body":"闭包 function f1(){ 　　　var n=999; //闭包 　　　nAdd=function(){n+=1} //闭包 　　　function f2(){ 　　　　　alert(n); 　　　} 　　　return f2; 　} 　var result=f1(); 　result(); // 999，函数f1外部访问f1内部的局部变量 　nAdd(); 　result(); // 1000 例子： var name = \"The Window\"; var object = { 　　name : \"My Object\", 　　getNameFunc : function(){ 　　　　return function(){ 　　　　　　return this.name; 　　　　}; 　　} }; alert(object.getNameFunc()());//The Window var name = \"The Window\"; var object = { 　　name : \"My Object\", 　　getNameFunc : function(){ 　　　　var that = this; 　　　　return function(){ 　　　　　　return that.name; 　　　　}; 　　} }; alert(object.getNameFunc()());//My Object Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter12/section6/":{"url":"chapter12/section6/","title":"12.6 原型链与继承理解","keywords":"","body":"原型链与继承理解 https://www.jianshu.com/p/dee9f8b14771 https://www.jianshu.com/p/652991a67186 https://www.jianshu.com/p/a4e1e7b6f4f8 https://www.cnblogs.com/Yirannnnnn/p/4896542.html https://www.cnblogs.com/thonrt/p/5900510.html http://www.cnblogs.com/onepixel/p/5143863.html https://blog.csdn.net/qq_29820901/article/details/89636619(继承) 普通对象/函数对象/原型对象（三者本质上是json格式的普通对象） 一定要把原型对象想象成是一个独立的对象，或者用一个方框来代表它 var o1 = {}; var o2 =new Object(); var o3 = new f1(); function f1(){}; var f2 = function(){}; var f3 = new Function('str','console.log(str)'); console.log(typeof Object); //function console.log(typeof Function); //function console.log(typeof f1); //function console.log(typeof f2); //function console.log(typeof f3); //function console.log(typeof o1); //object console.log(typeof o2); //object console.log(typeof o3); //object 凡是通过 new Function() 创建的对象都是函数对象，其他的都是普通对象。Function Object 也都是通过 New Function()创建的。 f1,f2,归根结底都是通过 new Function()的方式进行创建的。 例： function Person(){} var person = new Person(); 函数对象，当在new创造实例时，函数对象又可称为构造函数，指的是同一个东西 实例（new出来的）的属性constructor指向构造函数本身(按规定一般首字母大写） ①即：实例对象.constructor === 函数对象 => person.constructor === Person 每个对象都有 proto 属性，但只有函数对象才有 prototype 属性 函数对象都有一个prototype 属性，这个属性指向构造函数的原型对象。 ②即：函数对象.prototype === 构造函数.原型对象 JS 在创建对象（不论是普通对象还是函数对象）的时候，都有一个叫做proto 的内置属性，用于指向创建它的构造函数的原型对象。 ③即：实例对象.proto === 构造函数.原型对象 由②③推出 实例对象.proto === 实例对象的构造函数.prototype => person.proto === Person.prototype 原型对象都会自动获得一个 constructor（构造函数）属性，这个属性（是一个指针）指向 prototype 属性所在的函数 ④即：原型对象.constructor === 函数对象 ==> Person.prototype.constructor === Person 所以，原型链 person.constructor == Person; person.__proto__ == Person.prototype; Person.prototype.constructor == Person; 注意：constructor属性是定义在原型对象上面，意味着也可以被实例对象继承 Person.prototype.constructor一般是指向Person，但若是直接改变Person.prototype的指向，比如Person.prototype = {}，那么此时Person.prototype.constructor指向的便是Object;即Person.prototype.constructor===Object，而person.constructor也===Object 问题： person1.proto 是什么？ Person.proto 是什么？ Person.prototype.proto 是什么？ Object.proto 是什么？ Object.prototypeproto 是什么？ 答案： 第一题： 因为 person1.proto === person1 的构造函数.prototype 因为 person1的构造函数 === Person 所以 person1.proto === Person.prototype 第二题： 因为 Person.proto === Person的构造函数.prototype 因为 Person的构造函数 === Function 所以 Person.proto === Function.prototype 第三题： Person.prototype 是一个普通对象，我们无需关注它有哪些属性，只要记住它是一个普通对象。 因为一个普通对象的构造函数 === Object 所以 Person.prototype.proto === Object.prototype 第四题，参照第二题， 因为 Person 和 Object 一样都是构造函数 第五题： Object.prototype 对象也有proto属性，但它比较特殊，为 null 。 因为 null 处于原型链的顶端，这个只能记住。 Object.prototype.proto === nul Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section1/":{"url":"chapter13/section1/","title":"13.1 react-native项目结构","keywords":"","body":"react-native项目结构 ├── android // android原生部分 ├── ios // ios原生部分 ├── node_modules // 项目依赖包 ├── src // Ract Native ├── index.js // 项目注册入口文件 ├── package.json // 项目配置信息 ├── .babelrc // 设置转码的规则,插件,文件地址映（自动生成的） ├── .buckconfig // 为buck 的配置文件，buck是Fcebook 开源的高效编译系统（自动生成的） ├── .flowconfig // 为 flow 的配置文件，flow 用于代码静态检查 （自动生成的） ├── .gitattributes // git生成的文件，可以指定项目预约，方便GitHub查询（自动生成的） ├── .gitignore // 告诉Git哪些文件不需要添加到版本管理中（自动生成的） ├── .watchmanconfig // 为 watchman 的配置文件，watchman 用于监控文件变化，辅助实现工程修改所见即所得 ├── android.bat // 启动android项目指令文件，点击即可打开cmd运行react-native run-android ├── .eslintrc // 代码校验规则配置 ├── README.md // help └── yarn.lock // 依赖的版本信息管理 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section2/":{"url":"chapter13/section2/","title":"13.2 安卓相关","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 修改版本号 修改app名称 proguard混淆 安卓相关 修改版本号 app/build.gradle defaultConfig { applicationId \"com.qgao2021\" minSdkVersion rootProject.ext.minSdkVersion targetSdkVersion rootProject.ext.targetSdkVersion versionCode 2 //自己看的 versionName \"0.1.2\" //用户看的 } 修改app名称 android\\app\\src\\main\\res\\values\\strings.xml 点子 proguard混淆 ProGuard工作原理：https://blog.csdn.net/ljd2038/article/details/51308768 proguard 混淆规则：https://www.cnblogs.com/skymxc/p/proguard.html Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section3/":{"url":"chapter13/section3/","title":"13.3 rn 引入firebase/crashlytics","keywords":"","body":"rn 引入firebase/crashlytics https://rnfirebase.io/crashlytics/usage 用于app崩溃时生成报告，便于定位错误。firebase是google的。 在谷歌注册自己的项目 https://console.firebase.google.com/u/0/ 添加第1个app，包名必须和本地的一模一样 下载google-services.json 保存到android/app目录下 按照说明分别修改项目级和app级下的build.gradle 确认/android/app/src/main/AndroidManifest.xml中的manifest标签中的包名和真实的包名一样。 cd android && ./gradlew signingReport生成多份variant key，将其中debugAndroidTest分类下的sha1和sha-256复制并添加到google的firebase console的自己的app中的SHA certificate fingerprints。 Valid until: 2051年12月19日 星期二 ---------- > Task :react-native-safe-area-context:signingReport Variant: debugAndroidTest Config: debug Store: C:\\Android\\.android\\debug.keystore Alias: AndroidDebugKey MD5: 48:B7:35:9E:FC:F5:79:44:D2:F0:6A:D5:D5:A4:53:EA SHA1: DD:4A:84:46:F3:98:56:86:05:DE:76:32:D9:1A:6C:60:ED:56:48:FA SHA-256: 11:B7:CA:22:F6:28:42:CF:50:A4:95:C9:04:8C:0A:D5:95:31:5C:90:2F:EC:D4:AD:FB:A0:57:56:61:37:97:44 yarn add ‘@react-native-firebase/app’ yarn add ’@react-native-firebase/crashlytics‘ 然后额外配置：https://rnfirebase.io/crashlytics/android-setup 网址里面少了依赖，加上android/app/build.gradle: dependencies implementation 'com.google.firebase:firebase-crashlytics' Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section4/":{"url":"chapter13/section4/","title":"13.4 rn linking","keywords":"","body":"rn linking https://engineering.brigad.co/demystifying-react-native-modules-linking-964399ec731b Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section5/":{"url":"chapter13/section5/","title":"13.5 rn打包","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 release模式 切换为debug模式 rn打包 release模式 生成签名： 将生成后的 my-release-key.keystore 放到你工程中的android/app文件夹下 打开编辑项目目录下的android/app/build.gradle文件，添加如下的签名配置（signingConfigs ） signingConfigs { // 将默认的debug 注释或者去掉都可以 // debug { // storeFile file('debug.keystore') // storePassword 'android' // keyAlias 'androiddebugkey' // keyPassword 'android' // } release { keyAlias 'my-key-alias' //别名 keyPassword 'zkr123521' //密钥密码 之前设置秘钥口令 storeFile file('app.keystore') //my-release-key.keystore文件的绝对路径 storePassword 'zkr123521' //存储密码 } } 修改android/app/build.gradle 中buildTypes 配置;buildTypes { debug { signingConfig signingConfigs.debug } release { // Caution! In production, you need to generate your own keystore file. // see https://reactnative.dev/docs/signed-apk-android. signingConfig signingConfigs.release //将默认的debug 改成 release minifyEnabled enableProguardInReleaseBuilds proguardFiles getDefaultProguardFile(\"proguard-android.txt\"), \"proguard-rules.pro\" } } 修改android/app/build.gradle 中的enableProguardInReleaseBuilds属性/** * Run Proguard to shrink the Java bytecode in release builds. */ def enableProguardInReleaseBuilds = true //将默认的false 改成true 进入 react native 的andriod 目录 运行【在生成之前，最后先测试下，连上数据线，输入gradlew installRelease在手机上测试通过后，再发布不迟】gradlew assembleRelease //windows命令 ./gradlew assembleRelease //在macOS和Linux系统 执行完毕后在 你的项目下\\android\\app\\build\\outputs\\apk\\release中可以找到 app-release.apk 切换为debug模式 正常使用即可 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section6/":{"url":"chapter13/section6/","title":"13.6 使用函数式组件替代类组件","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 函数组件中的钩子函数 1. useState 2. useRef 3. useImperativeHandle 4. useEffect 5. useMemo 6. useCallBack 7. 自定义hook 使用函数式组件替代类组件 类组件中相较于函数组件比较特殊的功能，如state,生命周期等可以使用钩子函数hooks替代。 类组件中不能使用钩子函数 函数组件中的钩子函数 https://zh-hans.reactjs.org/docs/hooks-overview.html https://blog.csdn.net/landl_ww/article/details/102158814 1. useState useState替换state, 见坑 const [msg, setMsg] = useState(''); 2. useRef uesRef 返回的对象将在组件的整个生命周期内保持。 2个作用： 获取子组件的实例(只有子组件是类组件时可用)【访问DOM节点，ref.current 即可访问到组件实例】 在函数组件中的一个全局变量，不会因为重复 render 重复申明， 类似于类组件的 this.xxx【通用容器，其 current 属性是可变的，可以保存任何值】 例子： 3秒内先点击增加button，后点击减少button，3秒后先alert 1，后alert 0【capture value特性】， 而不是alert两次0【预想结果】。 function App() { const [count, setCount] = useState(0); useEffect(() => { setTimeout(() => { alert(\"count: \" + count); }, 3000); }, [count]); return ( You clicked {count} times setCount(count + 1)}>增加 count setCount(count - 1)}>减少 count ); } useRef 创建一个引用，就可以有效规避 React Hooks 中 Capture Value 特性，总会获取到最新的值 3. useImperativeHandle 可以让你在使用 ref 时自定义暴露给父组件的实例值，说简单点就是，子组件可以选择性的暴露给副组件一些方法，这样可以隐藏一些私有方法和属性，官方建议，useImperativeHandle应当与 forwardRef 一起使用， 同时也解决了useRef只能获得子组件是类组件的缺点。 function Kun (props, ref) { const kun = useRef() const introduce = useCallback (() => { console.log('i can sing, jump, rap, play basketball') }, []) useImperativeHandle(ref, () => ({ introduce: () => { introduce() } })); return ( { props.count } ) } const KunKun = forwardRef(Kun) function App () { const [ count, setCount ] = useState(0) const kunRef = useRef(null) const onClick = useCallback (() => { setCount(count => count + 1) kunRef.current.introduce() }, []) return ( 点击次数: { count } 点我 ) } 4. useEffect useEffect替换生命周期函数，如下所示。 什么都不传，组件每次 render 之后 useEffect 都会调用，相当于 componentDidMount 和 componentDidUpdate 传入一个空数组 [], 只会调用一次，相当于 componentDidMount 和 componentWillUnmount 传入一个数组，其中包括变量，只有这些变量变动时，useEffect 才会执行 const [ count, setCount ] = useState(0) useEffect(() => { // 相当于 componentDidMount console.log('add resize event') window.addEventListener('resize', onChange, false) return () => { // 相当于 componentWillUnmount window.removeEventListener('resize', onChange, false) } }, []) useEffect(() => { // 相当于 componentDidUpdate document.title = count }) useEffect(() => { console.log(`count change: count is ${count}`) }, [ count ]) 5. useMemo useMemo 会在渲染的时候执行，而不是渲染之后执行，这一点和 useEffect 有区别，所以 useMemo 不建议有 副作用相关的逻辑 同时，useMemo 可以作为性能优化的手段，但不要把它当成语义上的保证，将来，React 可能会选择“遗忘”以前的一些 memoized 值，并在下次渲染时重新计算它们。 6. useCallBack useMemo 的语法糖，能用 useCallback 实现的，都可以使用 useMemo, 向子组件传递函数props时，每次 render 都会创建新函数，导致子组件不必要的渲染，浪费性能，这个时候，就是 useCallback 的用武之地了，useCallback 可以保证，无论 render 多少次，我们的函数都是同一个函数，减小不断创建的开销， 7. 自定义hook 假设我们有诸多组件都需要这个逻辑，那么我们只需要将其抽取成一个自定义 hook 即可. 获取屏幕宽度变化的例子 function useWidth (defaultWidth) { const [width, setWidth] = useState(document.body.clientWidth) const onChange = useCallback (() => { setWidth(document.body.clientWidth) }, []) useEffect(() => { window.addEventListener('resize', onChange, false) return () => { window.removeEventListener('resize', onChange, false) } }, [onChange]) return width } function App () { const width = useWidth(document.body.clientWidth) return ( 页面宽度: { width } ) } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section7/":{"url":"chapter13/section7/","title":"13.7 react-native的第三方组件","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 react-native-render-html redux中配置store react-native的第三方组件 react-native-render-html 主要是想实现阅读文章时，点击其中的图片，可以放大对应的图片。 如果要获得对应的图片，就需要对应的索引index，那么需要给标签img自定义属性index 而这个组件中默认的render已经规定好了从dom到tTree，再到vdom中有哪些标签中的属性会被接收，然后渲染到vdom中。 因此若想自定义，必须得自己处理这两个过程，新增对index属性的接收。 来自 https://meliorence.github.io/react-native-render-html/docs/guides/custom-renderers 映射： const customHTMLElementModels = { img: defaultHTMLElementModels.img.extend({ getReactNativeProps(tnode) { const attributes = tnode.attributes; return { native: { index: attributes[\"index\"] //可将标签中的index属性映射到rendererProps.containerProps对象中 }, }; }, }) }; 获得： const renderers = { img: CustomImageRenderer }; function CustomImageRenderer(props) { const { Renderer, rendererProps } = useInternalRenderer('img', props); console.log(rendererProps.containerProps.index) } redux中配置store function rootReducer(state = {}, action) { return { users: usersReducer(state.users, action), posts: postsReducer(state.posts, action), comments: commentsReducer(state.comments, action) } } //上面等价于 const rootReducer = combineReducers({ users: usersReducer, posts: postsReducer, comments: commentsReducer }) //传递rootReducer给store const store = configureStore({ reducer: rootReducer }) //而事实上，上面所有的操作等价于下面这个，简化了上面繁琐的操作 export default configureStore({ reducer: { users: usersReducer, posts: postsReducer, comments: commentsReducer } }) Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section8/":{"url":"chapter13/section8/","title":"13.8 js的replace","keywords":"","body":"js的replace 首先是直接写正则表达式和new RegExp()里的正则表达式的不同之处，注释里写了。 其次是正则表达式的/g标志只针对replace时起作用，如果只单独执行exec只返回第1个，要想全部匹配，可以使用字符串的match方法：str.match(pattern)返回匹配到的数组。 最后是replace第2个可以为函数，而函数的参数为复数个， 第1个：每次匹配到的字符串， 第2个之后的复数个参数：正则中的分组()有多少个，就有多少个参数， 之后的1个参数：每次匹配到的字符串在字符串中的位置， 最后1个参数：原始字符串。 //将*替换成* export const transformFontTag = (html) => { //new RegExp内空格不用\\s，改为直接空格，\\d要改为\\\\d // const array = new RegExp(\"\",'g').exec(htmlSource.html); let pattern = /(.*?)/g;//g这些标志位用在replace的时候 return htmlSource.html.replace(pattern,(val,p1,p2)=>{ // let str = val.match(//g); // let px = mapFontToPx[parseInt(str[0].split('\\\"')[1])]; // return val.replace(pattern,\"$4\") return \"\"+p2+\"\" }) } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section9/":{"url":"chapter13/section9/","title":"13.9 promise","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 并行执行(结果有序) 并行执行(结果无序) promise new Promise(function (resolve, reject) { log('start new Promise...'); var timeOut = Math.random() * 2; log('set timeout to: ' + timeOut + ' seconds.'); setTimeout(function () { if (timeOut resolve函数的参数就是传到then中的函数的参数（回调函数）。 reject函数的参数就是传到catch中的函数的参数。 并行执行(结果有序) var p1 = new Promise(function (resolve, reject) { setTimeout(resolve, 500, 'P1'); }); var p2 = new Promise(function (resolve, reject) { setTimeout(resolve, 600, 'P2'); }); // 同时执行p1和p2，并在它们都完成后执行then: Promise.all([p1, p2]).then(function (results) { console.log(results); // 获得一个Array: ['P1', 'P2'] }); 并行执行(结果无序) 只取最先返回的结果： var p1 = new Promise(function (resolve, reject) { setTimeout(resolve, 500, 'P1'); }); var p2 = new Promise(function (resolve, reject) { setTimeout(resolve, 600, 'P2'); }); Promise.race([p1, p2]).then(function (result) { console.log(result); // 'P1' }); Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section10/":{"url":"chapter13/section10/","title":"13.10 es6 fetch","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 概述 基本使用 请求配置对象： fetch 函数返回一个 Promise 对象 使用样例 es6 fetch https://www.cnblogs.com/libin-1/p/6853677.html 概述 XMLHttpRequest和axios 所有的功能全部集中在同一个对象中，容易书写出混乱不易维护的代码. 采用传统的事件驱动模式，无法适配新的Promise API. Fetch API 并非取代AJAX，而是对AJAX传统 API的改进。 精细的功能分割：头部信息、请求信息、响应信息等均分布到不同的对象，更利于处理各种复杂的 AJAX 场景。 使用 Promise API，更利于异步代码的书写。 Fetch API 并非 ES6内容，而是属于 HTML5 新增 Web API。 需要掌握网络通信知识。 基本使用 使用fetch函数即可立即向服务器发送网络请求 参数： 必填, 字符串, 请求地址 选填, 对象, 请求配置 请求配置对象： method: 字符串, 请求方法, 默认值是 GET headers: 对象, 请求头信息 body: 请求体的内容, 必须匹配请求头中的 Content-Type mode: 字符串, 请求模式 credentials: 如何携带凭据( cookie ) cache: 配置缓存模式 default: 表示 fetch 请求之前将检查下http的缓存 no-store: 表示 fetch 请求将完全忽略 http 缓存的存在. 这意味着请求之前将不再检查下http 的缓存, 拿到响应后, 它也不会更新 http 缓存. no-cache: 如果存在缓存, 那么 fetch 将发送一个条件查询 request 和一个正常的 request, 拿到响应后, 它会更新 http 缓存. reload: 表示 fetch 请求之前将忽略 http 缓存的存在, 但是请求拿到响应后, 它将主动更新 http 缓存 force-cache: 表示 fetch 请求不顾一切的依赖缓存, 即使缓存过期了, 它依然从缓存中读取, 除非没有任何缓存, 那么它将发送一个正常的 request only-if-cached: 表示 fetch 请求不顾一切的依赖缓存, 即使缓存过期了, 它依然从缓存中读取. 如果没有缓存, 它将抛出网络错误( 该设置只是 mode为\"same-origin\"时有效 ) fetch 函数返回一个 Promise 对象 当收到服务器的返回结果后, Promise 进入 resolved 状态, 状态数据为 Response 对象， 当网络发生错误( 或其他导致无法完成交互的错误 ) 时, Promise 进入 rejected 状态, 状态数据为错误信息 Response 对象 ok : boolean, 当响应消息码在 200 ~ 299 之间时为 true, 其他为 false status: number, 响应的状态码 text(): 用于处理文本格式 Ajax 响应. 它从响应中获取文本流, 将其读完, 然后返回一个被解决为 String对象的 Promise blob(): 用于处理二进制文件格式 (比如图片或电子表格) 的 Ajax 响应. 它读取文件的原始数据, 一旦读取完整个文件, 就返回一个对解决为 blob 对象的 Promise. json(): 用于处理 JSON 格式的 Ajax 的响应. 它将 JSON 数据流转换为一个被解决为 JavaScript 对象的 Promise. redirect(): 可以用于重定向到另一个 url. 它会创建一个新的 Promise, 以解决来自重定向的 URL 的响应. 使用样例 fetch('some-url') .then(handleResponse) .then(data => console.log(data)) . catch (error => console.log(error)) function handleResponse (response) { let contentType = response.headers.get('content-type') if (contentType.includes('application/json')) { return handleJSONResponse(response) } else if (contentType.includes('text/html')) { return handleTextResponse(response) } else { // Other response types as necessary. I haven't found a need for them yet though. throw new Error(`Sorry, content-type ${contentType} not supported`) } } function handleJSONResponse (response) { return response.json() .then(json => { if (response.ok) { return json } else { return Promise.reject(Object.assign({}, json, { status: response.status, statusText: response.statusText })) } }) } function handleTextResponse (response) { return response.text() .then(text => { if (response.ok) { return json } else { return Promise.reject({ status: response.status, statusText: response.statusText, err: text }) } }) } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section11/":{"url":"chapter13/section11/","title":"13.11 typeScript类型-Partial、Pick、Omit","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 partial omit typeScript类型-Partial、Pick、Omit partial //Partial 类型的定义 /** * Make all properties in T optional */ type Partial = { [P in keyof T]?: T[P]; }; //使用Partial interface IUser { name: string age: number department: string } type optional = Partial // optional的结果如下 type optional = { name?: string | undefined; age?: number | undefined; department?: string | undefined; } omit pick和它相反. //Omit类型让我们可以从另一个对象类型中剔除某些属性，并创建一个新的对象类型： //K：是对象类型名称，T：是剔除K类型中的属性名称 type UserProps = { name?:string; age?:number; sex?:string; } // 但是我不希望有sex这个属性我就可以这么写 type NewUserProps = Omit // 等价于 type NewUserProps = { name?:string; age?:number; } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section12/":{"url":"chapter13/section12/","title":"13.12 点、像素、分辨率","keywords":"","body":"点、像素、分辨率 点：表示一个点，是屏幕的物理尺寸。 像素：px，组成图象的最基本单元要素。 分辨率：长方向上拥有的像素个数宽方向上拥有的像素个数。如（19201080），这样的写法叫分辨率，但如果乘出来的结果，称为有这么多像素点 px / dp = dpi / 160 dpi：实际每英寸所打印的点数。 160：标准dip，认为1英寸应该有160个点(dpi)，每个点应该对应1px，即1英寸160px（像素密度） 从公式推出在标准情况下，1px刚好等于1dp，因此1英寸应该有160dp。 解析上述公式：即当dpi为160时，那么1dp=1px，但如果dpi不为160，即假设dpi=80，也就是1英寸只有80个点，此时1dp=0.5px， 如果按照标准，那么实际使用中1inch=160dp，则1dp=1/160inch，是一个固定值。 总结： 在保持dp数值和标准dip不变的情况下，当在屏幕总面积不变时，分辨率增加，其实就是像素密度（单位英寸内的像素）增加，也就是dpi（每英寸打印的点数）增加， 通过公式，可以得出，在dp设置保持不变时，px可以随分辨率动态变化，这也就是设置dp可以适配不同分辨率的屏幕的原因。 ps：屏幕的像素密度=对角线的分辨率（通过长和宽的像素个数，然后勾股）/屏幕的尺寸（对角线的长度） Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section13/":{"url":"chapter13/section13/","title":"13.13 安卓获得对应hdpi目录中的图片","keywords":"","body":"安卓获得对应hdpi目录中的图片 按照我的例子，则是先计算像素密度，即dpi，分辨率为2400*1080，那么对角线分辨率为2631，尺寸或者说对角线长为6.67英寸，那么dpi = 2631/6.67=394, 然后x(px) = dpi/160 = 394/160 = 2.4625，使用进一法等于3，即图片应存放在xxhdpi。 系统加载图片是，会优先寻找对应文件夹的图片，假设是xxhdpi目录，如果没有，则按照xxxhdpi ---> xhdpi ---> hdpi ---> mdpi 的顺序进行查找，直至找到为止。 解析： 首先通过计算1dp等于多少px，来筛选目录，通过公式px = 1dp * (dpi / 160)计算，结果使用进一法，即ceiling。 比例对应目录： 如果计算出的结果对应的目录没有想要的图片，那么从xxx开始往下找，如果xxx有，那么会将图片变为xxx的3/4倍即缩小，如果xxx没有，再找xhdpi，有的话，将图片变为x的1.5倍（3/2）即扩大，剩下的同理。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section14/":{"url":"chapter13/section14/","title":"13.14 appLogo","keywords":"","body":"appLogo https://blog.csdn.net/adminlxb89/article/details/82492059 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter13/section15/":{"url":"chapter13/section15/","title":"13.15 react-native踩过的坑","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 钩子函数 useRef不可成为依赖项 useState 异步回调获取不到最新值及解决方案 scrollable-tab-view和tab-view react-navigation集成redux 打包失败 扩大使用的堆空间 uploadCrashlyticsMappingFileXXXRelease 打包connect timed out 打包安装后，打开闪退 第1次发布版本包 第2次发布版本包 启动页 默认props PanResponder 没有声明文件t.ds Touchable组件 react-navigation无法全屏 绝对布局 触摸事件的event defaultProps ${} {}表达式 ref.measure 获得遍历中每一项的ref react-native踩过的坑 钩子函数 useRef不可成为依赖项 ref.current 不可以作为其他 hooks（useMemo, useCallback, useEffect）依赖项；ref.current 的值发生变更并不会造成 re-render, Reactjs 并不会跟踪 ref.current 的变化。 useState 异步回调获取不到最新值及解决方案 https://www.cnblogs.com/hymenhan/p/14991789.html 用ref保存再改变状态， 或回调方式获取以前的值，再进行更新状态。 使用 useReducer 仿造类组件中的 forceUpdate 实现组件强制渲染 scrollable-tab-view和tab-view scrollable-tab-view tab-view 1 没维护了，使用的pager-view也是老版本的 一直在维护 2 bug多，如左右滑动时会触发flatlist中的触摸事件 bug也多，和tab-view同层级的其它组件涉及到高度的动画时，掉帧严重 3 滑动时，标签没有动画 有动画 4 对ios的兼容不好 android和ios都兼容 react-navigation集成redux 因为在react-navigation v4.x的时候，官网就说了不建议用redux来管理navigation的state,说是会拖慢运行速度，不过仍然提供了redux-helper来集成navigation的state,不过在5.x和6.x中，有关redux的集成，在官网中已经不写了， 也就是说，navigation官网希望navigation自己管理自己的state，redux一边去。 而从redux-helper的github中也可以发现，在2年前提供的最新的代码v4.1中依赖的是5.x的@react-navigation/core，但我在使用后，发现有bug，而redux-helper后期也没继续更新，估计也不想搞了，haha 好吧。 打包失败 扩大使用的堆空间 android - Execution failed for task ':app:minifyReleaseWithR8'老是抛堆内存不够out of memory 在android目录下的gradle.properties增加 #增大使用的堆空间 org.gradle.jvmargs=-Xms1024m -Xmx4096m uploadCrashlyticsMappingFileXXXRelease 打包connect timed out https://blog.csdn.net/m0\\_37587256/article/details/112028327 Firebase千般好，但是有一样就是他会自动生成mapping之类的文件(android\\app\\build\\crashlytics\\release\\mappings目录)并打包 .gz 压缩包，自己上传Google，这对国外当然没问题，国内就别想了， 因此关闭自动上传 啥时候手动上传，太简单，发布google play 新版本的时候，自己把生成的 .gz 文件上传就ok了， buildTypes { debug { signingConfig signingConfigs.debug proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro' minifyEnabled false versionNameSuffix \"_debug\" } release { // Caution! In production, you need to generate your own keystore file. // see https://reactnative.dev/docs/signed-apk-android. signingConfig signingConfigs.release //将默认的debug 改成 release minifyEnabled enableProguardInReleaseBuilds proguardFiles getDefaultProguardFile(\"proguard-android.txt\"), \"proguard-rules.pro\" shrinkResources true // Zipalign优化 zipAlignEnabled true // 设置firebase是否要自动上传 firebaseCrashlytics { mappingFileUploadEnabled false } } } 打包安装后，打开闪退 第1次发布版本包 使用android studio的logcat（sdk目录下的tools目录中的工具，打开命令窗口，直接输入monitor） 关键字，在过滤那输入java.lang 然后打开app，然后app闪退，在logcat找到报错原因： java.lang.IllegalStateException: java.lang.NoSuchFieldException: fill 参考： http://www.uwenku.com/question/p-fhlllpqy-kr.html https://stackoverflow.com/questions/68643215/how-to-use-minifyenable-in-release-apk 解决： https://www.codeleading.com/article/27112954688/ 我项目里使用了一个 react-native-svg 的库，是它导致的，需要在{project_path}/android/app/proguard-rules.pro 文件里面添加一行: -keep public class com.horcrux.svg.** {*;} 第2次发布版本包 由于logcat打印的错误不清晰，定位不准确，因此使用了google的firebase中的crashlytics 这次发布包，先后出现了两个错误， 一是no such field exception 是因为这个类被混淆后，另外的类在反射调用的时候找不到字段了，因此不允许该类被混淆， 通过混淆后生成的mapping.txt中找到对应的映射类，然后将其写进proguard-rule.pro中，保留该类，不被混淆 -keep class com.facebook.react.uimanager.** { *; } 第二个异常是com.facebook.jni.CppException https://github.com/facebook/react-native/issues/26930 通过了解，这个是新js引擎hermes无法运行的异常，将android/app/build.gradle中的IntlJsc注释掉 // 想使用hermes就得注释这个 // def useIntlJsc = false // if (useIntlJsc) { // implementation 'org.webkit:android-jsc-intl:+' // } else { // implementation 'org.webkit:android-jsc:+' // } 这个运行，会导致hermes的停止。 并同时保证hermes的相关类不被混淆(不知道起作用没) -keep class com.facebook.hermes.unicode.** { *; } 启动页 https://github.com/crazycodeboy/RNStudyNotes/blob/master/React%20Native%20%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E5%90%88%E9%9B%86/React%20Native%20%E5%90%AF%E5%8A%A8%E7%99%BD%E5%B1%8F%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%95%99%E7%A8%8B/React%20Native%20%E5%90%AF%E5%8A%A8%E7%99%BD%E5%B1%8F%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%95%99%E7%A8%8B.md https://www.jianshu.com/p/78571e5435ec react-native是0.64.0 首先安装yarn add react-native-splash-screen 1. //android/app/src/main/res/layout/launch_screen.xml //drawable是res中以该字符串为开头，然后加上”-xhdpi/-xxhdpi”之类的文件夹， //launch_screen是文件夹中的图片的名字，即想放的启动页的图片名 2. //android\\settings.gradle //通过该设置找到源文件位置 include ':react-native-splash-screen' project(':react-native-splash-screen').projectDir = new File(rootProject.projectDir, '../node_modules/react-native-splash-screen/android') //android\\app\\build.gradle //通过该配置将上述找到的源代码依赖到当前android项目 dependencies { implementation project(':react-native-splash-screen') # 确认存在, 如果不存在则需要手动增加这行。 } 3. //MainApplication.java @Override protected List getPackages() { @SuppressWarnings(\"UnnecessaryLocalVariable\") List packages = new PackageList(this).getPackages();// 会自动添加 new SplashScreenReactPackage() // Packages that cannot be autolinked yet can be added manually here, for example: // packages.add(new MyReactNativePackage()); return packages; } //MainActivity.java @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(null); SplashScreen.show(this,true); // 添加这一句 } 4. //最后在js里关掉，一般写在入口页app.js里 import SplashScreen from 'react-native-splash-screen'; componentDidMount(){ SplashScreen.hide(); } 默认props static defaultProps设置的默认的父组件的props和父组件传进来的props， constructor() 无法获得默认props. constructor(props)可以获得props. PanResponder react-native中的手势控制组件，坑是在 onStartShouldSetResponderCapture//单点 onStartShouldSetResponder 和 onMoveShouldSetResponderCapture//滑动 onMoveShouldSetPanResponder 不能同时存在，说白了就是，这个手势组件要么控制单点，要么控制滑动，这两个控制事件是互相独立的，官网都没说，在stackOverFlow网站上找到的答案。 https://blog.csdn.net/tianyitianyi1/article/details/107426381这个博客没直说，但是也是这么用的。 gestureState:{ stateID 此次触摸事件的ID moveX 移动时当前的屏幕坐标 moveY x0 响应器产生时的屏幕坐标（手势开始时的第一个坐标） y0 dx 触摸开始累积的横向路程 dy vx 当前的横向移动速度 vy numberActiveTouches 触摸点数量 } 没有声明文件t.ds 在src目录下新建一个types目录,然后在types 目录下新建一个 index.d.ts文件然后在文件中添加代码 declare module ‘第三方类库名’ Touchable组件 TouchableWithoutFeedback只接受一个直接子组件 react-navigation无法全屏 如果有需要全屏的组件如视频(video)之类的组件存在于导航页面内(navigation-tab)，使用orientation转为横屏后，并将video的宽高设为屏幕高宽后，无法关掉navigation的显示。 此时只能使用react-navigation其中的一个fullScreen的modal,并且只能设置在nativeStackNavigator里，之后使用navigation.navigate进行跳转。 绝对布局 在relative的布局内，如果有多个absolute布局的同级直接子组件，且这些组件中含有Touchable组件时（无论在外层还是在内层），触摸事件只有这些同级子组件中的最后一个能触发。 触摸事件的event 触摸事件处理的回调都有一个 event参数，包含一个触摸事件数据 nativeEvent. event.nativeEvent:{ changedTouches - 在上一次事件之后，所有发生变化的触摸事件的数组集合（即上一次事件后，所有移动过的触摸点） identifier - 触摸点的 ID locationX - 触摸点相对于当前元素的横坐标 locationY - 触摸点相对于当前元素的纵坐标 pageX - 触摸点相对于根元素的横坐标 pageY - 触摸点相对于根元素的纵坐标 target - 触摸点所在的元素 ID timestamp - 触摸事件的时间戳，可用于移动速度的计算 touches - 当前屏幕上的所有触摸点的集合 } defaultProps 修改了这个对象，需要reload才能生效。 ${} let name = '彭于晏' console.log( '名字为：'+name ) console.log( `名字为：${name} ` ) //在 `` 中可以使用 ${} 直接把变量和字符串拼接起来 {}表达式 在jsx里的{}表达式里，若调用无参函数可以直接写上函数名。 但是若要传参数，则必须写成箭头函数，然后在函数体里调用想调的函数。（否则this绑定丢失）。 ref.measure 只有组件带有press事件，只有在press事件的回调方法中可以调用该组件的ref.measure，调用其它组件的ref.measure都是undefined. 获得遍历中每一项的ref 预先定义存储各子项的对象，然后通过索引给每个子项赋值ref. ref={(ref)=>{ this.downArrowRef[index] = ref; }} Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter14/section1/":{"url":"chapter14/section1/","title":"14.1 C编译的四个阶段","keywords":"","body":"C编译的四个阶段 -I（大i，可以指定头文件的目录） -D（指定宏定义，一般是控制log输出） -Wall(提示一些编译时的警告信息) -g（在可执行文件中加入一些信息，可以在之后对程序进行调试） Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter14/section2/":{"url":"chapter14/section2/","title":"14.2 结构体变量的空间分配","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1. 例1 2. 例2 3. 例2变体 4. 例3 结构体变量的空间分配 结构体按最大类型增量分配空间，且从上往下在内存中按顺序分配 最大类型：结构体内的成员中最大宽度（占用内存）的变量类型 增量：所占字节大小 1. 例1 以上例来说，最大类型为int，增量为4B（字节） 那么，从成员依次从上往下看来，首先： int num; 4B char name[20]; 20B char sex; 4B int age; 4B char addr[30]; 32B 加起来就是64B。 2. 例2 再举一个特殊的例子 struct stu{ char a; int b; char c; }; 上例， char a; 4B int b; 4B char c; 4B 也就是12B 3. 例2变体 如果是这样： struct stu{ char a; char c; int b; }; 首先给a分配4B，接下来是c，由于跟上一个分配的变量是同一类型，先看上一个分配的还有没有剩余空间，若有，就不用再给c分配，没有再重新按最大类型增量分配； 在这里，c的上一个，即char a;分了4B，还剩下3B，可以容纳c，就不再为c重新分配； 即char a 与char c共用4B，接下来是int b;再分配4B，整个结构体的内存分配就为8B。 4. 例3 char name[20];刚好20个字节，可以用5个int（4B）的大小分配完，这里就由于sex上一个同类型的已分配空间容量不足，只能再开辟新的4B，再加上int age;分配的4B因此整个结构体的内存分配为28B. Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter14/section3/":{"url":"chapter14/section3/","title":"14.3 三大指针","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1、行指针：数据类型 (*p)[m]; 2、指针数组：数据类型 *a[3]; 3、二级指针 总结： 三大指针 行指针 指针数组 二级指针 “三大指针”这个是自己命名的，应该是指针中比较难理解的一块，所以拿出来写了个笔记。 友情提示：在看下面部分之前，需要对指针指向二维数组有个比较清楚的了解 在介绍三个指针之前，一定要牢记下面这个图，也就是二级指针的概念。 1、行指针：数据类型 (*p)[m]; 定义：指向由m个元素组成的一维数组的行指针变量 经测试，不能直接指向一维数组，如： int a[3]; int (*p)[3]; p = a; 以上代码是错误的。 看接下来的代码： 所谓“行指针”，对上图代码中的二维数组a[2][3]来说，就指的是a[0],a[1]这两行，那么如果行指针加数字的话，如上图如果p+1，那么这时指向的就是a[1]，p本身指向的是a[0]。 通过不同的测试输出发现： 第一个：*(*p+1)输出的是2，第一行的第二个元素。根据指针与数组的关系我们知道，数组名可以当成指针来用，而这里明显a[0]是第一行的一维数组名，也是第一行的首地址，参考第六个输出不难发现，这里的*p可以换成a[0]，即*(a[0]+1)，所以验证了上面的推测：*p = a[0]; 第二个就不用说了。 第三个：**(p+1)输出为4，同样，*(p+1) = a[1]，那么再加一个**(p+1)就等于*a[1]，输出为4。 第四个与第五个依然是同样来验证*p是否等于a[0]，输出结果和推测的一样。第六个也不说了。 说这么多，可能有些人认为是废话，也有可能有人是懵逼状态。 但我想说的是，对行指针，用上面那个例子来说：p其实是一个二级指针，而a[0],a[1]是一个一级指针，而记忆行指针的用法也很简单： 二维数组：int a[2][3] 行指针：int (*p)[3] 然后：p = a; 忽略后面的[3]，那么一眼就可以看出来*p = a[2]，即p指向a[0]，p+1指向a[1]； 2、指针数组：数据类型 *a[3]; []的优先性大于，所以a先和[]匹配，表示一个3个元素的数组，然后再与结合，表示这个数组中的元素每一个都是指针变量。 有些同学可能不是很明白为啥指针数组相当于二级指针，这里就来仔细的解析一下。请看下面: 我相信来看这篇文章的，对指针数组应该有个了解，所以第一行的输出就不作解答了， 来看第二行输出，（先回忆一下文章首部的那张图）可以看见在代码中只传了地址进去，就输出了“aaaa”。 好的，再往下看*b输出了“张三”，为什么？先不说， 再往下看，b[0]b[1]b[2]（这里是地址哦）先后输出了数组中的内容，可以看出：*b的结果是等于b[0]的，即*b依然是个地址； 再看最后一行输出，确定*(b+1)等于b[1]，然后最后一行输出的第一个值是一个地址。大家应该看出来为什么指针数组是二级指针的变形了。 其实b是二级指针，b[0]b[1]这样的是一级指针，大家应该发现了，行指针与指针数组是不是感觉都是二级指针的变形？只是代表的意义不同！ 3、二级指针 在上面的内容中，已经涉猎到了大量的二级指针内容，这里再说一个容易出错的地方。 来看第一行输出，在代码中是将name赋给p，再上一个指针数组，已经说过，name就是一个二级指针，那么将一个二级指针赋给一个二级指针，这没什么好说的，代码成功运行。 在这里想说的是代码注释里已经写了，当是int类型的时候是不能像字符串那样初始化的，所以指针数组一般是用来接收字符串，减少内存消耗。 总结： 是不是感觉二级指针老是要跟二维数组挂钩，二级指针名就是二维数组名，一级指针名就是二维数组中的一维数组行名，这里只是为了好理解才这么说，当然里面会有些差别。如果有错，还请各位大佬多多指教。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter14/section4/":{"url":"chapter14/section4/","title":"14.4 makefile","keywords":"","body":"makefile 项目的代码管理工具。 记录了如何编译程序的步骤。 规则三要素：目标、依赖、命令。 格式: 目标：依赖条件。 命令。 最终目标必须写在文件最上面。 例: app:main.c add.c sub.c mul.c gcc main.c add.c sub.c mal.c –o app 命令前必须是tab缩进。 执行makefile：make命令就是去找makefile里的终极“目标”，然后执行对应的命令。 为了让编译效率提高，可修改为: app:main.o add.o sub.o mul.o gcc main.o add.o sub.o mal.o –o app main.o:main.c gcc –c main.c add.o:add.c gcc –c add.c sub.o: sub.c gcc –c sub.c mul.o: mul.c gcc –c mul.c 此时如果只修改了add.c，再make时，只会对add.c进行重新编译（原理是在寻找add.o依赖时，会对add.o和add.c的修改时间进行对比） makefile中有【变量】【模式匹配】【自动变量】 自动变量只能在某条规则内部的【命令】里使用。 $ $@：所属规则中目标; $^：规则中的所有依赖; 因此上面的makefile可以改为: obj =main.o add.o sub.o mul.o # obj:变量，引用时用$()，和shell编程一样 target=app $(target):$(obj) gcc $(obj) –o $(target) % .o:%.c # %:模式匹配，当上面规则在找依赖时会自动将其代入到%，如查找第一个main.o时，会将%.o替换成main.o gcc –c $makefile里还有函数，所有的函数都有返回值。 就不用再手动给obj变量赋值需要的.o文件了，只需要通过函数调用即可完成，makefile可被修改为: src=$(wildcard ./*.c) ##查找某目录下的.c (wildcard: 函数名，后面跟参数) obj=$(patsubst ./%.c, ./%.o, $(src)) ##将.c替换成.o CC=gcc ##makefile本身维护的变量（大写）（有默认值）， ##用户可以修改 target=app $(target):$(obj) gcc $(obj) –o $(target) %.o:%.c gcc –c $上面的clean用来清理.o和可执行程序 使用命令：make clean（此时不会再执行上面的规则，只会执行make后面对应的目标） Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter16/section1/":{"url":"chapter16/section1/","title":"16.1 MESI协议","keywords":"","body":"MESI协议 https://www.cnblogs.com/itqczzz/p/12670782.html 缓存一致性协议（modified,exclusive,shared,invalid） 1.当CPU A将主存中的x cache line读入缓存中时，此时X副本的状态为E独占。 2.当CPU B将主存中的X cache line读入缓存中时，AB同时嗅探总线，得知X cache line不止一个副本，此时X的状态变为S共享 3,当CPU A将CACHE A中的x cache line修改为1后，Cache A中的X cache line 的状态变为M修改，并发送消息给CPU B，CPU将X cache line的状态变为I无效 4.当CPU A确认所有CPU缓存中的都提交了I无效状态，将修改后的值刷新到主存中，此时主存中的X变为了1，此时Cache A中的x cache line变为E独享 5.当CPU B需要用到X，发出读取X指令，于是读取主存中的x，于是重复第二步 更愿意称之为ESMI协议，好记。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter16/section2/":{"url":"chapter16/section2/","title":"16.2 操作系统内存管理","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 局部性原理 内存管理机制 页式管理：快表和多级页表 快表（TLB） 多级页表 页式管理和段式管理的同异 虚拟内存 虚拟内存的技术实现 操作系统内存管理 内存管理主要负责： 分配内存（malloc 函数：申请内存） 回收内存（free 函数：释放内存） 也负责：地址转换->将逻辑地址转换成相应的物理地址等功能（cpu中的MMU负责）。 注： 编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。 物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。 局部性原理 早在 1968 年的时候，就有人指出我们的程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。 局部性原理表现在以下两个方面： 时间局部性 ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。 空间局部性 ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。 时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。 空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。 内存管理机制 连续分配管理方式：是指为一个用户程序分配一个连续的内存空间，常见的如 块式管理 非连续分配管理方式：允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如页式管理 和 段式管理。 块式管理 ： 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为内存碎片。 页式管理 ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。 段式管理 ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多，划分力度更大 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。 段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 段页式管理机制中段与段之间以及段的内部的都是离散的。 页式管理：快表和多级页表 页式管理（分页管理）需要解决两个核心问题： 虚拟地址到物理地址的转换速度。 虚拟地址空间大，页表也会很大（页表膨胀）的问题。 快表（TLB） 为了解决虚拟地址到物理地址的转换速度，操作系统在 页表方案 基础之上引入了 快表 来加速虚拟地址到物理地址的转换。 我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。 作为页表的 Cache（局部性原理），它的作用与页表相似，但是提高了访问速率。 由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存（读一次，写一次）。 有了快表，有时只要访问一次高速缓冲存储器（读），一次主存（写），这样可加速查找并提高指令执行速度。 使用快表之后的地址转换流程是这样的： 根据虚拟地址中的页号查快表； 如果该页在快表中，直接从快表中读取相应的物理地址； 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中； 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。 看完了之后你会发现快表和我们平时经常在我们开发的系统使用的缓存（比如 Redis）很像，的确是这样的，操作系统中的很多思想、很多经典的算法，你都可以在我们日常开发使用的各种工具或者框架中找到它们的影子。 多级页表 引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景，具体可以查看下面这篇文章 多级页表如何节约内存：https://www.polarxiong.com/archives/多级页表如何节约内存.html 页式管理和段式管理的同异 共同点 ： 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。 区别 ： 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。 虚拟内存 逻辑地址又叫虚拟地址，每个进程都有自己的虚拟地址空间。 一个虚拟地址，大小4个字节(32bit)，包含着找到物理地址的信息，分为3个部分： 第22位到第31位这10位（高10位）是页目录中的索引（哪一个数据页）， 第12位到第21位这10位（中10位）是页表中的索引（该索引对应的地址为物理地址基址）， 第0位到第11位这12位（低12位）是页内偏移（上一步的基址加偏移得到真正的物理地址）。 该概念和下面要讲的东西有矛盾，暂时原因不解。 没有虚拟地址空间的时候，程序都是直接访问和操作的都是物理内存： 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。 程序编写困难。想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。 通过虚拟地址访问内存有以下优势： 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB，即8个扇区）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动（局部性原理）。 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。 虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，并且 把内存扩展到硬盘空间, 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上， 它通常是被分隔成多个物理内存碎片， 还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换（局部性原理）。 与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等。From:https://zh.wikipedia.org/wiki/虚拟内存 注： 局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。 虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现高速缓存。 虚拟内存的技术实现 虚拟内存的实现有以下三种方式： 请求分页存储管理 ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。 请求分段存储管理 ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。 请求段页式存储管理 请求分页管理和分页管理的根本区别是： 分页管理：将程序全部所需的全部地址空间都装入主存，无法提供虚拟内存 请求分页管理：不要求将作业全部地址空间同时装入主存。可以提供虚存 “请求式管理”都需要： 一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了； 缺页中断：地址映射过程中（查看页表），若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。，则由处理器通知操作系统将相应的页面或段调入到内存（请求调页），然后继续执行程序，这个时候，被内存映射的磁盘上的文件实际上成了一个分页交换文件； 虚拟地址空间 ：逻辑地址到物理地址的变换。 当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。 OPT 页面置换算法（最佳页面置换算法） ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。 FIFO（First In First Out） 页面置换算法（先进先出页面置换算法） : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。 LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法） ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。【最近在用的保留下来】 LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法） : 该置换算法选择在之前时期使用最少的页面作为淘汰页。【用的最多的保留下来】 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter17/details.html":{"url":"chapter17/details.html","title":"17. webSocket篇","keywords":"","body":"webSocket -原生servlet: https://blog.csdn.net/zy846771221/article/details/51037885 -springmvc: https://blog.csdn.net/rentian1/article/details/80753753 -springboot: https://blog.csdn.net/java_mindmap/article/details/105898152 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter18/section1/":{"url":"chapter18/section1/","title":"18.1 子网划分","keywords":"","body":"子网划分 【https://blog.csdn.net/weixin\\_43941364/article/details/105573765】IP 地址分为哪几类? 【https://halen.blog.csdn.net/article/details/82971644】子网掩码与子网划分 IP address 1.192.168.1.0/24 使用掩码255.255.255.240 划分子网，其可用子网数为（16 ），每个子网内可用主机地址数为（14）？ 子网掩码为255.255.0.0 ，下列哪个 IP 地址不在同一网段中（C ） A. 172.25.15.201 B. 172.25.16.15 C. 172.16.25.16 D. 172.25.201.15 3.B类地址子网掩码为 255.255.255.248 ，则每个子网内可用主机地址数为？6 对于B类 IP地址，子网掩码为 255.255.255.248 ，则能提供子网数为？ 2^13 5.三个网段 192.168.1.0/24 ， 192.168.2.0/24 ， 192.168.3.0/24 能够汇聚成下面哪个网段（D）？ A. 192.168.1.0/22 B. 192.168.2.0/22 C. 192.168.3.0/22 D. 192.168.0.0/22 6.IP 地址219.25.23.56 的缺省子网掩码有几位？C A.8 B.16 C.24 D.32 7.某公司申请到一个C 类IP 地址，但要连接6 个的子公司，最大的一个子 公司有26 台计算机，每个子公司在一个网段中，则子网掩码应设为？D A.255.255.255.0 B.255.255.255.128 C.255.255.255.192 D.255.255.255.224 8.一台IP 地址为10.110.9.113/21 主机在启动时发出的广播IP 是？ B A.10.110.9.255 B.10.110.15.255 C.10.110.255.255 D.10.255.255.255 9.规划一个C 类网，需要将网络分为9 个子网，每个子网最多15 台主机， 下列哪个是合适的子网掩码？ D A.255.255.224.0 B.255.255.255.224 C.255.255.255.240 D.没有合适的子网掩码 10.与10.110.12.29 mask 255.255.255.224 属于同一网段的主机IP 地址是 (B) A.10.110.12.0 B.10.110.12.30 C.10.110.12.31 D.10.110.12.32 11.IP 地址190.233.27.13/16 的网络部分地址是？ (B) A.190.0.0.0 B.190.233.0.0 C.190.233.27.0 D.190.233.27.1 12.没有任何子网划分的IP 地址125.3.54.56 的网段地址是？ (B) A.125.0.0.0 B.125.3.0.0 C.125.3.54.0 D.125.3.54.32 13.一个子网网段地址为2.0.0.0 掩码为255.255.224.0 网络，他一个有效子 网网段地址是？ (B) A.2.1.16.0 B.2.2.32.0 C.2.3.48.0 D.2.4.172.0 14.一个子网网段地址为5.32.0.0 掩码为255.224.0.0 网络，它允许的最大主 机地址是？ (C) A.5.32.254.254 B.5.32.255.254 C.5.63.255.254 D.5.63.255.255 15.在一个子网掩码为255.255.240.0 的网络中，哪些是合法的网段地址？D A.150.150.0.0 B.150.150.0.8 C.150.150.8.0 D.150.150.16.0 16.如果C 类子网的掩码为255.255.255.224，则包含的子网位数.子网数目. 每个子网中可用主机数目正确的是？B A.2，2，62 B.3，8，30 C.4，14，14 D.5，30，6 17.网络地址 :172.16.0.0 ，如果采用子网掩码255.255.192.0 ，那么以下说法正确的是B A. 划分了 2 个有效子网； B. 划分了 4 个有效子网； C. 其中一个子网的广播地址为： 172.16.191.255 ； D. 其中一个子网的广播地址为： 172.16.128.255 18.关于主机地址 192.168.19.125 （子网掩码： 255.255.255.248 ），以下说法正确AC A. 子网地址为： 192.168.19.120 ； B. 子网地址为： 192.168.19.121 ； C. 广播地址为： 192.168.19.127 ； D. 广播地址为： 192.168.19.128 ; 19.一个 C 类地址： 192.168.5.0 ，进行子网规划，要求每个子网有10 台主机，使用哪个子网掩码划分最合理C A. 使用子网掩码255.255.255.192 ； B. 使用子网掩码255.255.255.224 ； C. 使用子网掩码255.255.255.240 ； D. 使用子网掩码255.255.255.252 。 20.网络地址 192.168.1.0/24 ，选择子网掩码为255.255.255.224 ，以下说法正确的是BC A. 划分了 4 个有效子网； B. 划分了 6 个有效子网； C. 每个子网的有效主机数是30 个； D. 每个子网的有效主机数是31 个； E. 每个子网的有效主机数是32 个。 21.IP 地址:192.168.12.72 ，子网掩码为:255.255.255.192，该地址所在网段的网络地址和广播地址D A. 192.168.12.32 ， 192.168.12.127 ； B. 192.168.0.0 ， 255.255.255.255 ； C. 192.168.12.43 ， 255.255.255.128 ； D. 192.168.12.64 ， 192.168.12.127 。 22.172.16.10.32/24 代表的是B A. 网络地址； B. 主机地址； C. 组播地址； D. 广播地址。 23.一个子网网段地址为10.32.0.0 掩码为 255.224.0.0 的网络，它允许的最大主机地址是C A. 10.32.254.254 ； B. 10.32.255.254 ； C. 10.63.255.254 ； D. 10.63.255.255 。 1、已知某主机的IP地址为：192.168.100.200，子网掩码为：255.255.255.192，请推导出： 该主机所在的网络地址： 192.168.100.192 网络内允许的最大主机数： (2^2)*(2^6-2)=248 网络内主机IP地址的范围： 192.168.100.193~192.168.100.254 广播地址： 192.168.100.255 2、一个IP地址VLSM表示的方法为169.178.57.100/27，则此IP地址的子网掩码为 (F) 。 A、255.255.255.0 B、255.255.0.0 C、255.255.224.0 D、255.255.240.0 E、255.255.255.240 F、255.255.255.224 3、一台主机的IP地址为10.10.10.10/18，则该主机位于的网络的地址为 (B) ； A、10.10.10.0 B、10.10.0.0 C、10.10.4.0 D、10.10.8.0 E、10.10.16.0 F、10.10.32.0 G、10.10.64.0 H、10.10.96.0 4、现有一个B类网络地址160.18.0.0，如要划分子网，每个子网最多允许40台主机，则划分时容纳最多子网时，其子网掩码为(E) 。 A、255.255.192.0 B、255.255.224.0 C、255.255.240.0 D、255.255.252.0 E、255.255.255.192 F、255.255.255.224 G. 255.255.255.240 H、255.255.255.252 5、现有一个B类网络地址160.18.0.0，如要划分子网，需要最多划分40个子网，则划分时容纳最多主机时，其子网掩码为 (D) 。 A、255.255.192.0 B、255.255.224.0 C、255.255.240.0 D、255.255.252.0 E、255.255.255.192 F、255.255.255.224 G、255.255.255.240 H、255.255.255.252 6、现有一个VLSM地址160.171.219.125/21，则其所处的网络地址为 (F)。 A、160.171.219.64 B、160.171.219.0 C、160.128.0.0 D、160.171.192.0 E、160.171.208.0 F、160.171.216.0 G、160.171.218.0 H、160.171.219.21 7、现有一个VLSM地址160.171.219.125/20，则其所处的网络的广播地址为 (C) 。 A、160.171.208.255 B、160.171.216.255 C、160.171.223.255 D、160.171.192.255 E、160.171.200.255 F、160.171.224.255 G、160.171.218.255 H、160.171.255.255 1：200.1.1.1/26 分别写出这个地址所属的网络地址、广播地址、子网掩码、可用主机数；并算出有多少个子网，并罗列出所有子网 网络地址：200.1.1.0 广播地址：200.1.1.63 子网掩码：255.255.255.192 可用主机数：62 子网数：4 子网：200.1.1.0,200.1.1.64,200.1.1.128,200.1.1.192 2：169.33.33.33/20 分别写出这个地址所属的网络地址、广播地址、子网掩码、可用主机数；并算出有多少个子网，并罗列出所有子网 网络地址： 广播地址： 子网掩码： 可用主机数： 子网数： 子网： 3: 30.1.43.1/14 分别写出这个地址所属的网络地址、广播地址、子网掩码、可用主机数；并算出有多少个子网，并罗列出所有子网 网络地址： 广播地址： 子网掩码： 可用主机数： 子网数： 子网： 4:一个公司有5个部门，每个部门有20个人，公司申请了一个201.1.1.0/24的网络，请你为改公司做一下ip地址规划。(需要算出子网数、每个子网的可用主机数、子网掩码、可用的子网范围) 子网数：8 每个子网的可用主机数：30 子网掩码：201.1.1.224 可用子网范围：0，32，64，96，128，160，192，224 5：一个公司有50个部门，每个部门有300个人，公司申请了一个130.1.0.0/16的网络，请你为改公司做一下ip地址规划。(需要算出子网数、每个子网的可用主机数、子网掩码、可用的子网范围) 子网数： 每个子网的可用主机数： 子网掩码： 可用子网范围： 6:将下面的地址精确的汇总成一个网络：172.15.1.0/24、172.15.2.0/24、172.15.3.0/24 172.15.0.0/22 7：对下面的地址做一下精确的汇总：10.1.1.0/24、10.1.2.0/24、10.1.3.0/24、10.1.4.0/24 10.1.5.0/24 10.1.0.0/21 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter18/section2/":{"url":"chapter18/section2/","title":"18.2 网络间主机通信原理","keywords":"","body":"网络间主机通信原理 上图有正确的地方也有不正确的地方。 二层转发IP和MAC都不变（指的是局域网内通信） 三层转发IP不变，MAC变成路由器出接口MAC（网络之间通信） NAT的时候IP会依据策略改变，有可能变成源，也有可能是目标的IP。一般我们称他为SNAT和DNAT 处在局域网内的主机如何向网站发起请求: 首先要知道，局域网中的主机使用的是私网ip，而私网ip是在A,B,C三类网络中各截取的一段网段。 ipconfig查出来的是你本机的IP地址，也就是内网私有地址，此类地址仅在局域网使用，不能联通外网。 百度搜索IP查出来的地址是你上网的公有地址，并不是你主机的地址，而是运营商（电信或联通）分给你的地址，用于连接互联网。 网络之间的通迅实际上是某个软件和软件之间的通讯， 利用的是套接字（ip+端口）。 当局域网的主机想访问外网时，通过端口映射，端口映射是 NAT （网络地址转换）的一种，它将外网主机的 IP 地址的一个端口映射到内网中一台机器，提供相应的服务。当用户访问该 IP 的这个端口时，服务器自动将请求映射到对应局域网内部的机器上。 网关提供NAT服务，而通常路由器的ip地址即为网关， 路由器至少有两个端口：WAN 口和 LAN 口。 WAN：接外部 IP 地址用，通常指的是出口，转发来自内部 LAN 接口的 IP 数据包，这个口的 IP 是唯一的。 LAN：接内部 IP 地址用，LAN 内部是交换机。 LAN口到WAN口有一个NAT转换，WAN口到公网之间也通过NAT转换。 租用（申请）公有 IP 是需要钱的。A 家庭的局域网 IP 和 B 家庭的局域网 IP 相同很正常，但是，最终 A 和 B 能上网（数据走出去）还是通过运营商的公有 IP。 假如 A 和 B 的局域网 IP 相同（192.168.31.11），他们的公有IP也相同，当他们同时访问百度服务器的时候，百度服务器还是能够区分A，B。如下图所示。 以上是SNAT,还有DNAT，如下图。 百度的网站其实也是放在局域网内的，但为了让局域网外的主机能够访问也做了访问映射，看起来我是直接访问的公网上的ip加端口，其实是路由器把外来的访问给映射到了局域网的机器（DNAT）。当然同样的，自己写的网站也可以利用这样的原理，将其映射到公网ip上的端口，这样其他网络中的主机也就能访问自己的网站了。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter18/section3/":{"url":"chapter18/section3/","title":"18.3 tcp","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 tcp数据报格式 tcp保证传输可靠性 tcp tcp数据报格式 tcp保证传输可靠性 https://blog.csdn.net/liuchenxia8/article/details/80428157 建立连接(三次握手/四次挥手) 校验和 确认应答(通过序列号) 超时重传 流量控制 拥塞控制 ICMP Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter18/section4/":{"url":"chapter18/section4/","title":"18.4 DNS域名解析全过程","keywords":"","body":"DNS域名解析全过程 检查浏览器缓存 检查系统缓存（hosts文件） 检查本地域名服务器（LDNS），这台服务器一般在你的城市的某个角落，距离你不会很远 LDNS请求根域名服务器（Root Server），返回给LDNS一个所查询域的主域名服务器（gTLD Server，国际顶尖域名服务器，如.com .cn .org等） LDNS再发送请求给上一步返回的gTLD gTLD查找并返回这个域名对应的Name Server的地址，这个Name Server就是网站注册的域名服务器 Name Server根据映射关系表找到目标ip，返回给LDNS LDNS缓存这个域名和对应的ip LDNS把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束 浏览器缓存->系统缓存->本地域名服务器->根域名服务器->国际顶尖域名服务器->网站注册的域名服务器 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter18/section5/":{"url":"chapter18/section5/","title":"18.5 http","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 http头 http缓存机制 http完整请求过程 http http头 常见请求头: Accept: text/html,image/ 浏览器可以接收的类型 Accept-Charset: ISO-8859-1 浏览器可以接收的编码类型 Accept-Encoding: gzip,compress 浏览器可以接收压缩编码类型 Accept-Language: en-us,zh-cn 浏览器可以接收的语言和国家类型 Host: www.lks.cn:80 浏览器请求的主机和端口 If-Modified-Since: Tue, 11 Jul 2000 18:23:51 GMT 某个页面缓存时间 Referer: http://www.lks.cn/index.html 请求来自于哪个页面 User-Agent: Mozilla/4.0 compatible; MSIE 5.5; Windows NT 5.0 浏览器相关信息 Cookie： 浏览器暂存服务器发送的信息 Connection: close1.0/Keep-Alive1.1 HTTP请求的版本的特点 Date: Tue, 11 Jul 2000 18:23:51GMT 请求网站的时间 Allow:GET 请求的方法 GET 常见的还有POST Keep-Alive：5 连接的时间；5 Connection：keep-alive 是否是长连接 Cache-Control：max-age=300 缓存的最长时间 300s 常见响应头: Location: http://www.lks.cn/index.html 控制浏览器显示哪个页面 Server:apache nginx 服务器的类型 Content-Encoding: gzip 服务器发送的压缩编码方式 Content-Length: 80 服务器发送显示的字节码长度 Content-Language: zh-cn 服务器发送内容的语言和国家名 Content-Type: image/jpeg; charset=UTF-8 服务器发送内容的类型和编码类型 Last-Modified: Tue, 11 Jul 2000 18:23:51GMT 服务器最后一次修改的时间 Refresh: 1;url=http://www.lks.cn 控制浏览器1秒钟后转发URL所指向的页面 Content-Disposition: attachment; filename=lks.jpg 服务器控制浏览器发下载方式打开文件 Transfer-Encoding: chunked 服务器分块传递数据到客户端 Set-Cookie:SS=Q0=5Lb_nQ; path=/search 服务器发送Cookie相关的信息 Expires: -1 资源的过期时间，提供给浏览器缓存数据,-1永远过期 Cache-Control: no-cache 告诉浏览器，一定要回服务器校验，不管有没有缓存数据。 Pragma: no-cache 服务器控制浏览器不要缓存网页 Connection: close/Keep-AliveHTTP 请求的版本的特点 Date: Tue, 11 Jul 2000 18:23:51 GMT 响应网站的时间 ETag：“ihfdgkdgnp98hdfg” 资源实体的标识(唯一标识，类似md5值，文件有修改md5就不 http缓存机制 https://blog.csdn.net/qq_41648631/article/details/106895782 http完整请求过程 https://www.cnblogs.com/xuzekun/p/7527736.html Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter18/section6/":{"url":"chapter18/section6/","title":"18.6 https","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 浏览器验证证书的合法性 中间人无法冒充服务器 防http劫持，却防不了DNS劫持 可以抓包https SSL会降低网站速度吗？ https https://www.cnblogs.com/imteck4713/p/12016313.html HTTPS的整体过程分为证书验证和数据传输阶段： 在证书验证阶段传递密钥时使用非对称加密。 在数据传输的加密上使用的是对称加密。 通过查看非对称加密的原理，知道其算法加解密效率非常低，因此只适合用来加解密短小的数据。 具体的交互过程如下： 上图解析之握手环节： 浏览器：发送自己支持的密钥算法套件（简称Cipher） 服务器：判断自己支持的与其是否有交集，无则断开连接，否则返回： 证书（包含对称加密算法、hash算法等） 非对称加密的公钥 浏览器： 验证证书的合法性 生成随机数（对数据传输进行对称加密的密钥） 使用服务器返回的公钥和非对称加密算法对随机数进行加密并发送 握手信息 生成握手信息，使用hash算法对握手信息进行加密，组成“握手信息+加密后的hash值”，最后随机数和对称加密算法对其加密后再发送 服务器： 使用私钥解密得到密钥（随机数）， 再用随机数和对称加密算法对数据解密，取出握手信息后使用hash算法生成hash值，判断结果和浏览器发过来的hash值是否一样 然后用随机密码加密一段握手消息(握手消息+握手消息的HASH值 )给客户端 浏览器： 客户端用随机数解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束， 之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。 因为这串密钥只有客户端和服务端知道，所以即使中间请求被拦截也是没法解密数据的，以此保证了通信的安全。 总结： 非对称加密只用来加解密：对称加密的密钥（随机数） 浏览器验证证书的合法性 证书由权威机构发布，包含： 1）颁发机构信息； 2）公钥； 3）公司信息； 4）域名； 5）有效期； 6）指纹； 7）...... 浏览器需要对证书做以下验证： 1）验证域名、有效期等信息是否正确：证书上都有包含这些信息，比较容易完成验证； 2）判断证书来源是否合法：每份签发证书都可以根据验证链查找到对应的根证书，操作系统、浏览器会在本地存储权威机构的根证书，利用本地根证书可以对对应机构签发证书完成来源验证 3）判断证书是否被篡改：需要与 CA 服务器进行校验； 4）判断证书是否已吊销：通过CRL（Certificate Revocation List 证书注销列表）和 OCSP（Online Certificate Status Protocol 在线证书状态协议）实现，其中 OCSP 可用于第3步中以减少与 CA 服务器的交互，提高验证效率。 以上任意一步都满足的情况下浏览器才认为证书是合法的。 中间人无法冒充服务器 证书是公开的，如果要发起中间人攻击，我在官网上下载一份证书作为我的服务器证书，那客户端肯定会认同这个证书是合法的，如何避免这种证书冒用的情况？ 虽然中间人可以得到证书，但私钥是无法获取的，一份公钥是不可能推算出其对应的私钥，中间人即使拿到证书也无法伪装成合法服务端，因为无法对客户端传入的加密数据进行解密。 防http劫持，却防不了DNS劫持 因为https传输的数据都是加了密的，即使中间有人劫持了访问，也无法对内容进行更改， 但DNS劫持是发生在客户端与服务端建立连接之前，因此，如果有中间人劫持了域名解析，代替客户端与服务端发生连接，这其中就产生了两个https连接， 客户端中间人(拥有合法证书) 中间人服务端 因此HTTP 协议被认为不安全是因为传输过程容易被监听者勾线监听、伪造服务器，而 HTTPS 协议主要解决的便是网络传输的安全性问题。 可以抓包https 不过要主动安装证书（HTTPS 抓包工具生成的）到本地浏览器。 SSL会降低网站速度吗？ 握手过程结束后，才会开始数据的传输交换，显然这个过程会比HTTP复杂的多，加密又解密，可在实际的使用中，用户的感觉其实相差不大，这主要是因为这个过程的所需耗费的时间不过是几百毫秒（0.1秒=100毫秒），所以用户的体验并没有感觉到网速慢了多少。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter19/details.html":{"url":"chapter19/details.html","title":"19. linux篇","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 vi编辑器 makefile nginx nginx 简介 反向代理 nginx安装前序 PCRE pcre-devel安装 zlib-gzip安装 gcc C++安装 OpenSSL安装 解压nginx压缩包 配置nginx编译环境 开始nginx编译 开始运行nginx 退出运行nginx 开启外部访问权限 nginx与tomcat的配置 nginx与SpringBoot的配置 nginx分布式集群负载均衡 额外知识点 mysql 1 下载并安装MySQL官方的 Yum Repository 2 MySQL数据库设置 redis linux篇 vi编辑器 vim是vi发展过来的文本编辑器，现在普通使用vi，即是使用vim，所以前提是已经装了vim， vi有三种模式： 1.命令模式：打开文件之后，默认 2.编辑模式：输入命令切换到该模式（a,i,o,s）,退出跳到命令模式按ESC 3.末行模式：可以输入一些命令进行一些操作，要进入该模式需要从命令模式进入（输入冒号即可），退出该模式跳到命令模式按两下ESC 命令模式下: 光标移动：H,J,K,L 0行首，$行尾 gg文件头，G文件尾 移动到某行：按完数字加G，如第500行（500G） x删除后面的字符（X删除前面）【本质上是剪切】，u撤销（恢复ctrl+r），p粘贴 yy复制行， v：可视模式（选中），y复制 /：查找模式，n切换 #：选中相同的单词 保存退出：ZZ 末行模式： 跳转行，直接输数字。 字符串替换：:s/tom/jack（替换光标所在的tom为jack）加/g替换整行，加在冒号后加$替换整个文件的。 如： :s/tom/jack/g替换整行 :$s/tom/jack/g替换整个文件 实际使用中要将$换成%才行。 在末行模式下可以输入命令，冒号加感叹号加命令 在vi编辑器中垂直分屏，末行模式下vsp，切换ctrl+w(ctrl+ww) makefile 项目的代码管理工具。 记录了如何编译程序的步骤。 规则三要素：目标、依赖、命令。 格式【 目标：依赖条件。 命令。 】 最终目标必须写在文件最上面。 例【 app:main.c add.c sub.c mul.c gcc main.c add.c sub.c mal.c –o app 】 命令前必须是tab缩进。 执行makefile：make命令就是去找makefile里的终极“目标”，然后执行对应的命令。 为了让编译效率提高，可修改为【 app:main.o add.o sub.o mul.o gcc main.o add.o sub.o mal.o –o app main.o:main.c gcc –c main.c add.o:add.c gcc –c add.c sub.o: sub.c gcc –c sub.c mul.o: mul.c gcc –c mul.c 】 此时如果只修改了add.c，再make时，只会对add.c进行重新编译（原理是在寻找add.o依赖时，会对add.o和add.c的修改时间进行对比） makefile中有【变量】【模式匹配】【自动变量】 自动变量只能在某条规则内部的【命令】里使用。 $\\ $@：所属规则中目标 $\\^：规则中的所有依赖 因此上面的makefile可以改为【 obj=main.o add.o sub.o mul.o target=app $(target):$(obj) gcc $(obj) –o $(target) %.o:%.c gcc –c $\\ 】 makefile里还有函数，所有的函数都有返回值。 就不用再手动给obj变量赋值需要的.o文件了，只需要通过函数调用即可完成，makefile可被修改为【 src=$(wildcard ./*.c) ##查找某目录下的.c obj=$(patsubst ./%.c, ./%.o, $(src)) ##将.c替换成.o CC=gcc ##makefile本身维护的变量（大写）（有默认值）， ##用户可以修改 target=app $(target):$(obj) gcc $(obj) –o $(target) %.o:%.c gcc –c $\\ clean: rm $(obj) $(target) 】 上面的clean用来清理.o和可执行程序 使用命令：make clean（此时不会再执行上面的规则，只会执行make后面对应的目标） nginx nginx 简介 nginx (engine x) 是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP服务器。nginx是由伊戈尔·赛索耶夫为俄罗斯访问量第二的Rambler.ru站点（俄文：Рамблер）开发的，第一个公开版本0.1.0发布于2004年10月4日。 其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。2011年6月1日，nginx 1.0.4发布。 nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的静态网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、京东、新浪、网易、腾讯、淘宝等。 反向代理 首先要明白什么是代理，什么是反向代理，客户端使用的是代理，而服务端使用的是反向代理。 反向代理的实现规则 (1)首先需要一个负载均衡设备来处理用户的请求，将用户的请求再分发到空闲的服务器上 (2)服务器得到响应之后，处理数据并返回对应的响应数据到负载均衡设备 (3)负载均衡设备最后再将服务器返回的响应数据返回给用户 用户《-》负载均衡、分布式、集群设备《-》服务器 再举一个现实中的场景，比较容易理解一些 当我们拨打一个集团客户电话的时候，比如保险公司电话、10086移动客服电话、10000电信客服电话、110、119等等，可能拨打的号码后面对应的客服有几十个甚至几百个，但是你不会知道到底是谁接了电话，是谁在帮助你解决问题，因为整个分配过程是由系统自动完成，你可能每一次拨打，对应接听的客服都不一样，这里所拨打的号码分配机制就是反向代理。 反向代理的好处在于隐藏了真实的服务端，当我们请求某一个网址的时候，就像拨打集团号码一样，背后可能有成千上万台服务器为我们服务，但具体是哪一台，用户不会知道，用户也不关心这些，用户关心的只是能不能获取到自己想看到的内容而已，所以用户输入的网址就是反向代理服务器的地址，反向代理服务器会帮我们把请求转发到真实的服务器那里去。 在反向代理服务中，nginx因为其良好的自身性能、稳定性和特性，占据全球领域大部分业务场景，所以国内的互联网巨头，几乎都是使用nginx完成的反向代理服务。 nginx安装前序 nginx是C语言开发的，尽量建议在Linux上部署运行，当然，也可以安装 Windows 版本，这里只演示怎样在Linux环境中使用。 下面的所有安装过程，为了简化安装步骤，建议使用超级管理员来完成，否则会出现权限不够的错误提示。 PCRE pcre-devel安装 PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令： yum install -y pcre pcre-devel (PS：yum命令会根据Linux当前环境中缺少的内容进行网络下载，所以首先确定是否能上网，否则会出现错误状态，后面不再标注说明) zlib-gzip安装 zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Linux上安装 zlib 库，执行以下命令安装： yum install -y zlib zlib-devel gcc C++安装 nginx 需要在本地Linux环境中进行编译，编译依赖 gcc C++环境，如果没有 gcc 环境，则需要执行以下命令进行安装： yum install gcc-c++ OpenSSL安装 OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。 nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Linux 安装 OpenSSL 库。 yum install -y openssl openssl-devel 解压nginx压缩包 Nginx官方下载地址，建议使用稳定版本，也就是Stable version版本 https://nginx.org/en/download.html 下载完成之后，copy到Linux中，然后到对应的目录通过命令解压缩 tar -zxvf nginx-****.tar.gz 配置nginx编译环境 通过cd命令进入解压完成的nginx目录中，通过命令开始配置 ./configure 这里需要注意的时候，Linux系统会自动检查需要使用哪些配置项来完成这次编辑，并自动加入对应的内容，不需要手动配置，这次编译的时候，Linux系统会自动加入pcre、zlib、openssl、gcc进行对应编译操作 开始nginx编译 在解压完成的nginx目录中，首先执行编译命令 make 等执行编译完毕之后，再执行安装命令 make install 到这里nginx已经编译、安装、并部署到Linux系统中，下面我们来测试下是否已经成功 开始运行nginx 如果前面全部安装成功，这时候输入下面的命令可以到nginx的目录中 cd /usr/local/nginx/sbin/ 然后通过命令启动nginx ./nginx 启动以后，不会有任何提示，现在我们需要打开一个网页来访问下就知道是否运行成功，因为nginx默认需要80端口支持，前面知识已经讲述过，80是不需要输入端口号的，所以只需要输入 http://电脑IP地址 这个时候如果成功，应该看到下面的效果 退出运行nginx 一般情况下，服务器不会轻易关闭，如果一定要关闭，输入命令 ./nginx -s quit ./nginx -s reload 开启外部访问权限 跟前面讲述在Linux上部署java-web项目一样，我们需要手动开启80端口对外访问权限 首先开启外部网络访问80端口 firewall-cmd --permanent --add-port=80/tcp 然后重启防火墙 firewall-cmd --reload 这时候，在外部同局域网电脑也可以正常访问了 查看 firewall-cmd --zone= public --query-port=80/tcp 删除 firewall-cmd --zone= public --remove-port=80/tcp --permanent nginx与tomcat的配置 在修改配置文件之前，一定要记得备份一份原始文件到本地，避免修改错误，导致重新安装nginx 进入到nginx的配置文件中，直接打开它，操作命令 vi /usr/local/nginx/conf/nginx.conf 然后修改下图中的两个位置 server_name localhost; location / { root html; index index.html index.html; } 然后为下面的效果： server_name localhost:8080; location / { proxy_pass http://localhost:8080; } 接着，需要重启nginx，不需要重启tomcat，然后在访问服务器IP，直接就跳转到tomcat中了 nginx与SpringBoot的配置 因为SpringBoot中自带tomcat，所以如果在没有修改SpringBoot中tomcat的端口的情况下，可以直接使用上面修改好的nginx，在启动SpringBoot前，记得退出前面加载的tomcat，否则端口会冲突，最后通过服务器IP访问SpringBoot中的内容，如果访问到代表成功 nginx分布式集群负载均衡 Nginx负载均衡的分发方式有4种： 轮询，默认采取此方式，Nginx会按照请求时间的先后顺序进行轮询分发，若某台Web Server宕机，Nginx自动将其摘掉。 weight，权重，即轮询的几率，值越大，被分发的可能性越大，用于后端服务器性能不均的情况。所有服务器默认的weight都是1 ip_hash,每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决共享session的问题。 自定义规则 upstream thinknovo { server 192.168.1.11:80 down; server 192.168.1.12:80 weight=2; server 192.168.1.13:80; server 192.168.1.14:80 backup; } down 表示当前的Web Server暂时不参与负载，处于离线状态，通常和ip_hash一起使用 weight 默认为1.weight越大，负载的权重就越大。 backup： 其它所有的非backup 服务器宕机或者忙的时候，请求backup服务器，通常在项目中配置的是备用服务器 thinknovo在这里只是别名，为了在location里面引用 upstream thinknovo{ server localhost:8080 weight=1; server localhost:8081 weight=1; server localhost:8082 weight=1; } server { listen 80; server_name localhost:8080 localhost:8081; location / { proxy_pass http://thinknovo; proxy_connect_timeout 3; proxy_read_timeout 3; proxy_send_timeout 10; } proxy_connect_timeout 默认60（s） 后端服务器连接的超时时间_发起握手协议等候响应超时时间（web服务器启动后，nginx发起握手，服务器回复，注意，此并非response响应时间，而是连接等待时间） proxy_read_timeout 默认60（s） 连接成功后等候后端服务器响应时间其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间。即response的响应时间，并非response全部返回的时间） proxy_send_timeout 默认60（s） 后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据的超时时间 在项目实际部署中，首先榨干web服务器的性能，再通过分布式和负载均衡来完成集群 反向代理服务器=nginx web服务器=tomcat 额外知识点 tomcat两个重要的默认端口 访问端口8080 关闭端口8005 linux centos 默认占据内存200M左右 windows server 默认占据内存1~1.5G tomcat 默认200并发，最高可以修改为500并发（server.xml）/ 占据的内存一般在512M~1G 并发：意思是同时在使用后台服务功能的请求，200并发，代表每一秒同时可以支持200个任务处理 mysql 在CentOS中默认安装有MariaDB，这个是MySQL的分支，但为了需要，还是要在系统中安装MySQL，而且安装完成之后可以直接覆盖掉MariaDB。 1 下载并安装MySQL官方的 Yum Repository [root@localhost ~]# wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm 使用上面的命令就直接下载了安装用的Yum Repository，大概25KB的样子，然后就可以直接yum安装了。 [root@localhost ~]# yum -y install mysql57-community-release-el7-10.noarch.rpm 之后就开始安装MySQL服务器。 [root@localhost ~]# yum -y install mysql-community-server 这步可能会花些时间(注：不是花些时间，是贼慢，你完全可以看两部电影再来看看下完没有)，安装完成后就会覆盖掉之前的mariadb。 至此MySQL就安装完成了，然后是对MySQL的一些设置。 2 MySQL数据库设置 首先启动MySQL [root@localhost ~]# systemctl start mysqld.service 查看MySQL运行状态，运行状态如图： [root@localhost ~]# systemctl status mysqld.service 此时MySQL已经开始正常运行，不过要想进入MySQL还得先找出此时root用户的密码，通过如下命令可以在日志文件中找出密码： [root@localhost ~]# grep \"password\" /var/log/mysqld.log 如下命令进入数据库： [root@localhost ~]# mysql -uroot -p 输入初始密码，此时不能做任何事情，因为MySQL默认必须修改密码之后才能操作数据库： mysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'new password'; 这里有个问题，新密码设置的时候如果设置的过于简单会报错： 原因是因为MySQL有密码设置的规范，具体是与validate_password_policy的值有关： MySQL完整的初始密码规则可以通过如下命令查看： mysql> SHOW VARIABLES LIKE 'validate_password%'; +--------------------------------------+-------+ | Variable_name | Value | +--------------------------------------+-------+ | validate_password_check_user_name | OFF | | validate_password_dictionary_file | | | validate_password_length | 4 | | validate_password_mixed_case_count | 1 | | validate_password_number_count | 1 | | validate_password_policy | LOW | | validate_password_special_char_count | 1 | +--------------------------------------+-------+ 7 rows in set (0.01 sec) 密码的长度是由validate_password_length决定的，而validate_password_length的计算公式是： validate_password_length = validate_password_number_count + validate_password_special_char_count + (2 * validate_password_mixed_case_count) 我的是已经修改过的，初始情况下第一个的值是ON，validate_password_length是8。可以通过如下命令修改： mysql> set global validate_password_policy=0; mysql> set global validate_password_length=1; 设置之后就是我上面查出来的那几个值了，此时密码就可以设置的很简单，例如1234之类的。到此数据库的密码设置就完成了。 但此时还有一个问题，就是因为安装了Yum Repository，以后每次yum操作都会自动更新，需要把这个卸载掉： [root@localhost ~]# yum -y remove mysql57-community-release-el7-10.noarch 此时才算真的完成了。 redis CENTOS7下安装REDIS 1、安装redis 第一步：下载redis安装包 wget http://download.redis.io/releases/redis-4.0.6.tar.gz 1 2 3 4 5 6 7 8 9 10 11 [root@iZwz991stxdwj560bfmadtZ local]# wget http://download.redis.io/releases/redis-4.0.6.tar.gz --2017-12-13 12:35:12-- http://download.redis.io/releases/redis-4.0.6.tar.gz Resolving download.redis.io (download.redis.io)... 109.74.203.151 Connecting to download.redis.io (download.redis.io)\\ 109.74.203.151\\ :80... connected. HTTP request sent, awaiting response... 200 OK Length: 1723533 (1.6M) [application/x-gzip] Saving to: ‘redis-4.0.6.tar.gz’ 100%[==========================================================================================================>] 1,723,533 608KB/s in 2.8s 2017-12-13 12:35:15 (608 KB/s) - ‘redis-4.0.6.tar.gz’ saved [1723533/1723533] 第二步：解压压缩包 tar -zxvf redis-4.0.6.tar.gz 1 [root@iZwz991stxdwj560bfmadtZ local]# tar -zxvf redis-4.0.6.tar.gz 第三步：yum安装gcc依赖 yum install gcc 1 [root@iZwz991stxdwj560bfmadtZ local]# yum install gcc 1 遇到选择,输入y即可\\\\\\ 第四步：跳转到redis解压目录下 cd redis-4.0.6 1 [root@iZwz991stxdwj560bfmadtZ local]# cd redis-4.0.6 第五步：编译安装 make MALLOC=libc 1 [root@iZwz991stxdwj560bfmadtZ redis-4.0.6]# make MALLOC=libc 将/usr/local/redis-4.0.6/src目录下的文件加到/usr/local/bin目录 cd src && make install 1 2 3 4 5 6 7 8 9 10 [root@iZwz991stxdwj560bfmadtZ redis-4.0.6]# cd src && make install CC Makefile.dep Hint: It's a good idea to run 'make test' ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL install 第六步：测试是否安装成功 先切换到redis src目录下 1 [root@iZwz991stxdwj560bfmadtZ redis-4.0.6]# cd src 1、直接启动redis ./redis-server 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 [root@iZwz991stxdwj560bfmadtZ src]# ./redis-server 18685:C 13 Dec 12:56:12.507 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 18685:C 13 Dec 12:56:12.507 # Redis version=4.0.6, bits=64, commit=00000000, modified=0, pid=18685, just started 18685:C 13 Dec 12:56:12.507 # Warning: no config file specified, using the default config. In order to specify a config file use ./redis-server /path/to/redis.conf _._ _.-``\\ ''-._ _.-`` `. `. ''-.\\ Redis 4.0.6 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ ''-._ ( ' , .-` \\ `, ) Running in standalone mode \\ `-.`-...-` __...-.``-.\\ '` _.-'\\ Port: 6379 \\ `-._ `._ / _.-' \\ PID: 18685 `-._ `-._ `-./ _.-' _.-' \\ `-.`-.\\ `-._.-' \\.-'_.-'\\ \\ `-.`-.\\ _.-'_.-' \\ http://redis.io `-._ `-.`-.__.-'.-' _.-' \\ `-.`-.\\ `-._.-' \\.-'_.-'\\ \\ `-.`-.\\ _.-'_.-' \\ `-._ `-.`-.__.-'.-' _.-' `-._ `-..-' _.-' `-._ _.-' `-..-' 18685:M 13 Dec 12:56:12.508 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 18685:M 13 Dec 12:56:12.508 # Server initialized 18685:M 13 Dec 12:56:12.508 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect. 18685:M 13 Dec 12:56:12.508 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 18685:M 13 Dec 12:56:12.508 * Ready to accept connections 如上图：redis启动成功，但是这种启动方式需要一直打开窗口，不能进行其他操作，不太方便。 按 ctrl + c可以关闭窗口。 2、以后台进程方式启动redis 第一步：修改redis.conf文件 将 1 daemonize no 修改为 1 daemonize yes 第二步：指定redis.conf文件启动 1 ./redis-server /usr/local/redis-4.0.6/redis.conf 1 2 3 4 [root@iZwz991stxdwj560bfmadtZ src]# ./redis-server /usr/local/redis-4.0.6/redis.conf 18713:C 13 Dec 13:07:41.109 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 18713:C 13 Dec 13:07:41.109 # Redis version=4.0.6, bits=64, commit=00000000, modified=0, pid=18713, just started 18713:C 13 Dec 13:07:41.109 # Configuration loaded 第三步：关闭redis进程 首先使用ps -aux | grep redis查看redis进程 1 2 3 [root@iZwz991stxdwj560bfmadtZ src]# ps -aux \\ grep redis root 18714 0.0 0.1 141752 2008 ? Ssl 13:07 0:00 ./redis-server 127.0.0.1:6379 root 18719 0.0 0.0 112644 968 pts/0 R+ 13:09 0:00 grep --color=auto redis 使用kill命令杀死进程 1 [root@iZwz991stxdwj560bfmadtZ src]# kill -9 18714 第七步：设置redis开机自启动 1、在/etc目录下新建redis目录 mkdir redis 1 [root@iZwz991stxdwj560bfmadtZ etc]# mkdir redis 2、将/usr/local/redis-4.0.6/redis.conf 文件复制一份到/etc/redis目录下，并命名为6379.conf 1 [root@iZwz991stxdwj560bfmadtZ redis]# cp /usr/local/redis-4.0.6/redis.conf /etc/redis/6379.conf 3、将redis的启动脚本复制一份放到/etc/init.d目录下 1 [root@iZwz991stxdwj560bfmadtZ init.d]# cp /usr/local/redis-4.0.6/utils/redis_init_script /etc/init.d/redisd 4、设置redis开机自启动 先切换到/etc/init.d目录下 然后执行自启命令 1 2 [root@iZwz991stxdwj560bfmadtZ init.d]# chkconfig redisd on service redisd does not support chkconfig 看结果是redisd不支持chkconfig 解决方法： 使用vim编辑redisd文件，在第一行加入如下两行注释，保存退出 1 2 # chkconfig: 2345 90 10 # description: Redis is a persistent key-value database 注释的意思是，redis服务必须在运行级2，3，4，5下被启动或关闭，启动的优先级是90，关闭的优先级是10。 再次执行开机自启命令，成功 1 [root@iZwz991stxdwj560bfmadtZ init.d]# chkconfig redisd on 现在可以直接已服务的形式启动和关闭redis了 启动： service redisd start 1 2 3 4 5 [root@izwz991stxdwj560bfmadtz ~]# service redisd start Starting Redis server... 2288:C 13 Dec 13:51:38.087 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 2288:C 13 Dec 13:51:38.087 # Redis version=4.0.6, bits=64, commit=00000000, modified=0, pid=2288, just started 2288:C 13 Dec 13:51:38.087 # Configuration loaded 关闭： service redisd stop 1 2 3 [root@izwz991stxdwj560bfmadtz ~]# service redisd stop Stopping ... Redis stopped 如果出现如下问题： 1 2 [root@iZwz991stxdwj560bfmadtZ ~]# service redisd start /var/run/redis_6379.pid exists, process is already running or crashed 引起这类问题一般都是强制关掉电源或断电造成的，也是没等linux正常关机 科学的处理办法2种 1：可用安装文件启动 redis-server /etc/redis/6379.conf 2：shutdown -r now 软重启让系统自动恢复下就行了 注：网上的说法不可取，不要改动任何文件，其实什么配置等变化都没有 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter19/section1/":{"url":"chapter19/section1/","title":"19.1 vi编辑器","keywords":"","body":"vi编辑器 vim是vi发展过来的文本编辑器，现在普通使用vi，即是使用vim，所以前提是已经装了vim， vi有三种模式： 1.命令模式：打开文件之后，默认 2.编辑模式：输入命令切换到该模式（a,i,o,s）,退出跳到命令模式按ESC 3.末行模式：可以输入一些命令进行一些操作，要进入该模式需要从命令模式进入（输入冒号即可），退出该模式跳到命令模式按两下ESC 命令模式下: 光标移动：H,J,K,L 0行首，$行尾 gg文件头，G文件尾 移动到某行：按完数字加G，如第500行（500G） x删除后面的字符（X删除前面）【本质上是剪切】，u撤销（恢复ctrl+r），p粘贴 yy复制行， v：可视模式（选中），y复制 /：查找模式，n切换 #：选中相同的单词 保存退出：ZZ 末行模式： 跳转行，直接输数字。 字符串替换：:s/tom/jack（替换光标所在的tom为jack）加/g替换整行，加在冒号后加$替换整个文件的。 如： :s/tom/jack/g替换整行 :$s/tom/jack/g替换整个文件 实际使用中要将$换成%才行。 在末行模式下可以输入命令，冒号加感叹号加命令 在vi编辑器中垂直分屏，末行模式下vsp，切换ctrl+w(ctrl+ww) Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/":{"url":"chapter20/","title":"20. 数据结构篇","keywords":"","body":"王道https://www.bilibili.com/video/BV1b7411N798 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section1/":{"url":"chapter20/section1/","title":"20.1 常见应用","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 栈 队列 矩阵的压缩存储 常见应用 栈 括号匹配， 计算表达式： 中缀转后缀（运算符栈） 后缀表达式计算（操作数栈） 中缀表达式：a+b 后缀表达式：ab+ 队列 图和树的广度遍历（层次遍历） 矩阵的压缩存储 稀疏矩阵：十字链表法 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section2/":{"url":"chapter20/section2/","title":"20.2 kmp字符串匹配","keywords":"","body":"kmp字符串匹配 主串的指针一直往前移动，不回溯。 只移动模式串的指针。 比较字符不匹配时，重新定位模式串的指针， 通过提前计算：主串的后缀和模式串的前缀相等的个数，可以得到模式串重新定位的指针位置。 重新定位的模式串指针位置由一个额外的数组保存：jr = next[j]. j表示当前比较错误的位置 jr表示重新定位的位置 优化next数组—>nextval 在计算next数组时，计算出的重新定位的指针位置jr所对应的字符若是与当前匹配失败位置j指向的字符相同时，则将next[jr]的值赋给next[j]。 实例： public Boolean kmp(List sOrder, List tOrder) { int sLen = sOrder.size(), tLen = tOrder.size(); int[] fail = new int[tOrder.size()]; Arrays.fill(fail, -1); for (int i = 1, j = -1; i Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section3/":{"url":"chapter20/section3/","title":"20.3 二叉树","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 二叉树的遍历 完全、满二叉树 线索二叉树 二叉树分别和树、森林之间的转换 二叉排序树（bst） 调整最小不平衡子树 LL（右旋） RR（左旋） LR（先左旋后右旋） RL（先右旋后左旋） 二叉树 二叉树的遍历 二叉树为有序树，即左右子树不可交换。 广度遍历：队列 深度遍历：先序、中序、后序 由遍历造树：两种遍历可确定，必须得有中序，另一种为先序或后序或层序（广度遍历） 完全、满二叉树 完全二叉树（Complete Binary Tree） 满二叉树（Perfect Binary Tree） Full Binary Tree 完全二叉树（Complete Binary Tree）：每一层都是紧凑靠左排列 满二叉树（Perfect Binary Tree）：特殊的完全二叉树，每层都是是满的 Full Binary Tree 是指一棵二叉树的所有节点要么没有孩子节点，要么有两个孩子节点 线索二叉树 方便便历（利用前驱、后继） 将树的结点里，其中左右子树指向null的指针利用起来，让它们分别指向前驱和后继。 这里的前驱和后继，指的是遍历时排列出的结点顺序，在某结点前面的一个结点为前驱，后面的一个结点为后继。 遍历可分为先序、中序、后序：不同方法的遍历，前驱后继也不同。 在线索二叉树中，其中空的指针域可以用来指向前驱或后继，在查找时可以很方便地查到当前结点的前驱或后继，但是若结点无空指针域，需要根据不同方法的遍历来找，如： 查找某结点的中序后继，即找到该结点的右子树中最左的结点； 查找某结点的中序前驱，即找到该结点的左子树中最右的结点； 二叉树分别和树、森林之间的转换 树：不限定分支数量。 森林：多棵树。 树转二叉树：二叉树的左指针指向树的最左边的第一个孩子，该孩子的右指针接着指向自己的兄弟结点。 森林转二叉树：先把每棵树转成二叉树，然后每棵树的根结点当成兄弟结点，因此，根结点的右指针依次指向兄弟结点。 二叉排序树（bst） 从而有了平衡二叉树。 调整最小不平衡子树 这个与排序树有关，因为排序树的构造会因为不同的序列造成树的结构不同，也就可能导致查找或插入时的时间复杂度增大。 而平衡二叉树的时间复杂度能保证时间复杂度最低【log2(n)】，因此如何在插入结点时保证构造的二叉树一直是平衡二叉树至关重要。 LL（右旋） BL RR（左旋） AL LR（先左旋后右旋） BL RL（先右旋后左旋） AL Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section4/":{"url":"chapter20/section4/","title":"20.4 红黑树","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 需要红黑树的理由 红黑树的性质 满足红黑树的性质 插入（主要处理当前结点为红色） 步骤1 步骤2 步骤3 删除（主要处理当前结点为黑色） 1.删除无子结点的红色结点 2.删除无子结点的黑色结点 约定： 分析： 总结： 3.删除有一个子结点的黑色结点 4.删除有两个子结点的红色或黑色结点 红黑树 需要红黑树的理由 从二叉搜索树（AVL&bst）到红黑树。 因为二叉搜索树要保证平衡二叉树的特性，所以在插入删除时，容易破坏平衡，所以需要经常地对树进行旋转操作（但查找效率高），因此引进了红黑树处理这种情况。 红黑树的特性保证了对红黑树进行插入删除时不会经常对树进行旋转操作，提高了时间效率。 红黑树的性质 红黑树性质（树上的结点要么是黑色，要么是红色）： 根结点必须是黑色结点； 红色结点的子结点必须是黑色结点（红色结点不能相连）； 从任一结点到其下最底部的任意NIL结点（设为黑色）的黑色结点数量是相等的（NIL结点是叶子结点的左右指针指向的虚拟结点，其不存储数据）。 满足红黑树的性质 满足红黑树的性质，就能满足对红黑树进行查找时能达到最高的效率。而不像二叉查找树一样需要保持平衡才能达到查找最高效率。 新插入的结点的颜色必须是红色的。 当新插入的结点不满足红黑树的性质时，则需要对红黑树进行处理：改变结点颜色，旋转子树。 例：以下是一棵红黑树。 插入（主要处理当前结点为红色） 去除NIL虚拟结点，方便查看，并且此时要插入一个新的结点。 将新的结点插入树中，却不满足红黑树的性质2。 步骤1 条件：如果插入的当前结点的父亲结点与叔叔结点均为红色， 操作：则将当前结点的父亲结点、叔叔结点、祖父结点均反转颜色（红变黑，黑变红），再令当前结点指向为祖父结点。 步骤2 条件：如果当前结点的父结点为红色，而叔叔结点为黑色，且当前结点为父结点的右子结点时； 操作：将当前结点与其父结点进行左旋操作，并将当前结点指向为父结点。 步骤3 条件：如果当前结点的父结点为红色，而叔叔结点为黑色，且当前结点为父结点的左子结点时； 操作：将当前结点的父亲结点、祖父结点进行反转颜色，再让父亲结点和祖父结点进行右旋操作。 删除（主要处理当前结点为黑色） 分情况有： 被删结点为红色，且无子结点（最简单）； 被删结点为黑色，且无子结点（最复杂）； 被删结点为黑色，且有一个子结点； 被删除点为红色或黑色，且有两个子结点； 1.删除无子结点的红色结点 直接删掉。 2.删除无子结点的黑色结点 约定： N为被删除结点。 分析： 1）当前结点为根结点，直接删除 2）兄弟节点为黑色（S=黑） 2.1）兄弟的子节点全黑（SL=SR=黑） 将兄弟结点变成红色，再看父结点是红色还是黑色。 2.1.1）父节点为黑色（P=黑） 此时将S涂红，父节点作为新的平衡节点N，递归上去处理（从分析最开始判断）。 2.1.2）父节点为红色（P=红） 此时将S涂红，P涂黑，平衡结束。 2.2）兄弟的子节点不全黑 2.2.1）S为左子，SL红；S为右子，SR红 ①S为左子，SL红 以P为支点右旋；交换P和S颜色，SL涂黑；平衡结束。 ②S为右子，SR红 以P为支点左旋；交换P和S颜色，SR涂黑；平衡结束。 2.2.2）S为左子，SL黑；S为右子，SR黑 ①S为黑色，S为左子，SL黑 以S为支点左旋，交换S和SR颜色（SR涂黑，S涂红） ，此时转至情形2.2.1-① S左-SL红 进行处理。 ②S为右子，SR黑 3）兄弟节点为红色（S=红） ①S为左子时，以P进行右旋； ②S为右子时，以P进行左旋； 分别旋转后交换P和S的颜色（S涂黑，P涂红），N兄弟节点变为黑色，进入情形2-兄弟节点为黑色进行处理。 总结： 3.删除有一个子结点的黑色结点 将该结点的子结点变黑，然后让其与该结点的父结点相连，最后删除该结点。 4.删除有两个子结点的红色或黑色结点 用删除结点的中序后继结点中的值替换被删除结点的值，然后删除中序后继结点，此问题转化为情形1、2或情形3。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section5/":{"url":"chapter20/section5/","title":"20.5 如何存图","keywords":"","body":"如何存图 邻接矩阵（二维数组） 邻接表（数组+链表） 十字链表法：只存有向图 邻接多重表：只存无向图 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section6/":{"url":"chapter20/section6/","title":"20.6 生成树","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 广度优先生成树 深度优先生成树 最小生成树（图） 生成树 图中有n个顶点，它的生成树有n-1条边，即连通图的生成树是包含图中全部顶点的一个极小连通子图。 对生成树来说： 若删去一条边，则会变成非连通图。 若增加一条边，则会形成回路。 广度优先生成树 使用bfs得到的生成树 邻接表的生成树可能因为链表中结点的顺序会不一样，但邻接矩阵的生成树保持不变。 深度优先生成树 dfs生成的树 最小生成树（图） 边有权值，所有的结点都连接，但代价最小。同一个图可能有多个最小生成树。 代价边权和值最小 prim算法（算法实现有点像dijkstra算法）【适合边稠密图】 原理：从某一个顶点开始构建生成树，每次将代价最小的新顶点加入生成树。 如从p城开始： isjoin保存的是哪些结点已经加入了当前的生成树中。 lowCost保存的是还没有加入的结点能够加入当前生成树，直接相连的边的最小权值。 kruskal算法（克鲁斯卡尔）【适合边稀疏图】 每次选择一条权值最小的边，使这条边的两头进行连通，原本已经连通的不选。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section7/":{"url":"chapter20/section7/","title":"20.7 最短路径","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 单源 各顶点间 最短路径 这些算法都有个额外的数组对每个结点的直接前驱进行记录，即path数组。 带权路径长度：一条路径所有边的权值之和。 单源 bfs：无权图最短路径 dijkstra：带权图、无权图最短路径（不能解决带负权值的图） https://blog.csdn.net/lbperfect123/article/details/84281300 final记录的是起点是否找到了到达其它顶点的最短路径。 dist记录的是已经加入了最短路径的顶点是否有能到其它未加入顶点的边，有则记录下最短的距离值。 path记录的是最短距离的直接前驱，如这一轮V1的前驱是V0，所以记录下0， 原理：根据dist数组更新final数组，然后再更新dist和path数组。 各顶点间 floyd算法：带权图、无权图最短路径（能解决带负权值的图，但不能解决“负权回路”） 负权回路 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section8/":{"url":"chapter20/section8/","title":"20.8 查找","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 顺序查找 折半查找 分块查找 B树 B树的插入、删除 B+树 B树与B+树的区别 1 2为了树不要太高（太空） 3 4 散列查找 冲突 查找 不同类型的数据表使用不同的数据结构进行存储，在增删改查时有不同的效率。 数据存储好后，便不再改的数据，称之为静态数据表 若需要再改，则为动态数据表 查找算法的指标：查找长度，平均查找长度ASL ASL的数量级反应了查找算法的时间复杂度。 顺序查找 折半查找 分块查找 B树 结合了平衡二叉树，分块、折半等思想，并且b树为绝对平衡，没有相差1的说法 B树的插入、删除 插入时由下而上：上一级的节点，是由下一级的节点中关键字数量满了脱胎出来的。 删除时保证下面的核心要求，来改变结点中关键字的位置。 B+树 应用了分块查找的算法。 B树与B+树的区别 1 2为了树不要太高（太空） 3 4 散列查找 存储的数据（关键字）与存储地址直接相关。 通过某种映射关系将数据(x)映射到存储地址(y)：y=f(x) 冲突 链地址法：冲突后，紧接着在相同的位置以链表的形式插入。 开放地址法：各个地址中存储的将是实实在在的数据，而不是链地址法中有可能存在的链表。如果经过哈希函数后计算出的位置已经有数据了，再通过某种算法（线性探测法）将计算出的位置向其他空位挪移。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section9/":{"url":"chapter20/section9/","title":"20.9 内部排序","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 拓扑排序 插入排序 希尔排序 冒泡排序 快速排序 简单选择排序 堆排序 归并排序 基数排序 内部排序 动态演示算法https://www.cs.usfca.edu/~galles/visualization/Algorithms.html 排序的稳定性：排序后，相同数据的相对顺序保持不变，即该算法稳定。 拓扑排序 后序遍历的逆序即拓扑排序的结果. 找到做事的先后顺序（可以应用在找“关键路径”中） 邻接表实现，时间复杂度低，逆拓扑排序（找出度为0）用邻接矩阵或逆邻接表，也可以用dfs实现 插入排序 希尔排序 对插入排序的优化 定义： 冒泡排序 冒泡排序定义： 快速排序 先序遍历 选择基准元素， low指针：比基准元素小 high指针：比基准元素大 两个指针若谁的指向为空，则让另一个指针指向的元素和基准元素比较大小， 若不满足条件，将该指针指向的元素赋值到指向为空的指针； 若满足条件，则移动指向不为空的指针（low向后移，high向前移）。 public void fastSort(int[] nums, int begin, int end){ if(begin >= end) return ; int index = process(nums,begin,end); fastSort(nums,begin,index-1); fastSort(nums,index+1, end); } public int process(int[] nums, int begin, int end){ int base = nums[end]; while(begin = base && begin = nums[end] && begin 简单选择排序 简单选择排序定义： 堆排序 大根堆递增，小根堆递减。 要使用堆排序， 1.首先必须将原始数组排成大根堆（小根堆）。 2.处理非终端结点：顺序存储的（数组）完全二叉树，其中非终端结点为i≤n/2的结点。令其满足大根堆（小根堆）的要求。 \\3. 堆排序：每一趟将堆顶元素加入有序子序列，每一趟之后，整理剩下的二叉树（不算有序子序列）为大根堆（小根堆）。【重复3】 public class HelloWorld { public static void main(String []args) { int[] array = new int[]{4, 5, 8, 2}; int k = 3; for(int i = array.length / 2 - 1; i >= 0; i--){ adjustBigHeap(array, i, array.length); } for(int i = 0; i归并排序 后序遍历 public ListNode sortInList (ListNode head) { // write code here if(head == null || head.next == null) return head; //使用快慢指针找到中点 ListNode slow = head, fast = head.next; while(fast!=null && fast.next !=null){ slow = slow.next; fast = fast.next.next; } //分割为两个链表 ListNode newList = slow.next; slow.next = null; //将两个链表继续分割 ListNode left = sortInList(head); ListNode right = sortInList(newList); ListNode lhead = new ListNode(-1); ListNode res = lhead; //归并排序 while(left != null && right != null){ if(left.val 基数排序 递减 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section10/":{"url":"chapter20/section10/","title":"20.10 外部排序","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 败者树（增大k） 置换-选择排序（减小r） 最佳归并树 外部排序 优化 败者树（增大k） 置换-选择排序（减小r） 最佳归并树 2路（多路）最佳归并树：使用哈夫曼树构造法 注意（当k>2时） Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter20/section11/":{"url":"chapter20/section11/","title":"20.11 排序算法优劣","keywords":"","body":"排序算法优劣 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section1/":{"url":"chapter21/section1/","title":"21.1 递归","keywords":"","body":"递归 相信递归函数的定义 永远不要跳进递归细节【不要试图让函数的栈桢进入人脑的栈中】。 相信函数的定义，然后具体到某一次函数调用，根据定义，确定该次调用应该做什么，然后用代码表示出来。 public ListNode reverseList(参数0) { if (终止条件) return; 逻辑处理（可能有，也可能没有，具体问题具体分析） //递归调用 ListNode reverse = reverseList(参数1); 逻辑处理（可能有，也可能没有，具体问题具体分析） } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section2/":{"url":"chapter21/section2/","title":"21.2 动态规划","keywords":"","body":"动态规划 三要素： 重叠子问题 最优子结构 状态转移方程 重叠子问题：递归调用的函数会有重复的出现； 最优子结构：子问题之间互相独立，不能互相干扰； 状态转移方程：“选择”而来。 【比如说，你的原问题是考出最高的总成绩，那么你的子问题就是要把语文考到最高，数学考到最高…… 为了每门课考到最高，你要把每门课相应的选择题分数拿到最高，填空题分数拿到最高…… 当然，最终就是你每门课都是满分，这就是最高的总成绩。 得到了正确的结果：最高的总成绩就是总分。因为这个过程符合最优子结构，“每门科目考到最高”这些子问题是互相独立，互不干扰的。 但是，如果加一个条件：你的语文成绩和数学成绩会互相制约，此消彼长。这样的话，显然你能考到的最高总成绩就达不到总分了，按刚才那个思路就会得到错误的结果。因为子问题并不独立，语文数学成绩无法同时最优，所以最优子结构被破坏。】 思考方法 明确「状态」 定义 dp 数组（迭代，自底向上）/函数（递归，自顶向下，备忘录）的含义 明确「选择」 明确 base case。 状态： 令y=f(x),则自变量x为状态，f为函数或者说dp数组，y则为该函数对应的人为定义。 通常小时候做数学题，是令问题中的未知数为x，根据相等关系列出方程，最后求得的x解则是问题的答案。 但在动态规划题目中，y才是我们要求的解，而x是我们需要穷举的。 选择： 如何穷举x，则是通过题目的要求，人为选择而来，即通过循环或者是递归，令当前x等于不同值的情况下，y对应的人为定义哪一个更符合问题的解，而进行的选择题。 base case: 最开始的初始值，在令x=0或者是其它初始情况时，我们必须得给y=f(0)【给f(0)赋初值】,因为母问题的解是由子问题的解得来的。而这一步的初始赋值根据实际情况不同具体赋值。 注：备忘录解决重叠子问题，有了备忘录的递归就相当于迭代的动态规划了。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section3/":{"url":"chapter21/section3/","title":"21.3 回溯(dfs)","keywords":"","body":"回溯(dfs) result = [] def backtrack(路径, 选择列表): if 满足结束条件: result.add(路径) return for 选择 in 选择列表: 做选择 backtrack(路径, 选择列表) 撤销选择 由递归函数的定义可以看见，【路径】是函数的形参，随着函数的入栈在不停地添加值，或出栈而删除值，路径就像一根触手，去试探地触摸每一个结点（做决策），如果不满足要求，则将触手收回来，去摸另一个结点，因为这种回收动作的特性，这种方法称之为回溯。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section4/":{"url":"chapter21/section4/","title":"21.4 多叉树的两种遍历区别","keywords":"","body":"多叉树的两种遍历区别 //正确打印所有节点的进入和离开信息 void traverse(TreeNode root) { if (root == null) return; System.out.println(\"enter: \" + root.val); for (TreeNode child : root.children) { traverse(child); } System.out.println(\"leave: \" + root.val); } //少打印整棵树根节点的进入和离开信息 void traverse(TreeNode root) { if (root == null) return; for (TreeNode child : root.children) { System.out.println(\"enter: \" + child.val); traverse(child); System.out.println(\"leave: \" + child.val); } } 前者会正确打印所有节点的进入和离开信息，而后者唯独会少打印整棵树根节点的进入和离开信息。 为什么回溯算法框架会用后者？因为回溯算法关注的不是节点，而是树枝，不信你看 回溯算法核心套路 里面的图，它可以忽略根节点。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section5/":{"url":"chapter21/section5/","title":"21.5 图的遍历","keywords":"","body":"图的遍历 显然，对于这里「图」的遍历，我们应该把visited的操作放到 for 循环外面，否则会漏掉起始点的遍历。 当然，当有向图含有环的时候才需要visited数组辅助，如果不含环，连visited数组都省了，基本就是多叉树的遍历。 Graph graph; boolean[] visited; /* 图遍历框架 */ void traverse(Graph graph, int s) { if (visited[s]) return; // 经过节点 s visited[s] = true; for (TreeNode neighbor : graph.neighbors(s)) traverse(neighbor); // 离开节点 s visited[s] = false; } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section6/":{"url":"chapter21/section6/","title":"21.6 bfs","keywords":"","body":"bfs // 计算从起点 start 到终点 target 的最近距离 int BFS(Node start, Node target) { Queue q; // 核心数据结构 Set visited; // 避免走回头路 q.offer(start); // 将起点加入队列 visited.add(start); int step = 0; // 记录扩散的步数 while (q not empty) { int sz = q.size(); /* 将当前队列中的所有节点向四周扩散 */ for (int i = 0; i Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section7/":{"url":"chapter21/section7/","title":"21.7 双指针","keywords":"","body":"双指针 1、合并两个有序链表 双指针分别指向两个有序链表，使用带头结点的新链表保存新的合并链表，然后比较各指向的大小，比较完后，把剩下的指针不为空的结点再存到新的合并链表上。 2、合并k个有序链表 利用PriorityQueue，默认是小根堆，先存放进k个链表的第一个结点，然后取根结点，再重新往小根堆里添加取出结点的下一个结点，循环得到合并链表。 3、寻找单链表的倒数第k个节点 双指针，让第一个指针先走k步，然后第二个指针从头开始走，和第一个指针保持相同的速度，当第一个指针走到链尾时，则第二个指针指向倒数第k个结点。 4、寻找单链表的中点 快慢指针，第一个指针走两步，第二个指针走一步，当第一个指针走到链尾时，则第二个指针指向中间结点。 5、判断单链表是否包含环并找出环起点 快慢指针，第一个指针走两步，第二个指针走一步，当两个指针相遇时，则为有环，第一个指针走了2k,第二个指针走了k, 相遇之后，将第二个指针移到链头，假设相遇点离环起点为m步，表示，第二个指针从相遇点走k-m步则为环起点，而第一个指针也要走k-m也到环起点，也就是说，只要在两个指针相遇后，将第二个指针移到链头，然后再和第一个指针一起走，当再次相遇时就是环起点。 6、判断两个单链表是否相交并找出交点 假设第一个链表: 1->5->6 第一个链表: 3->4->5->7 让双指针分别指向两个链表，当走完各自的链表后，再移动到下一个链表，那么当两个指针所指向的结点相等时，则证明有交点。 156->3457 3457->156 7、反转数组 左右指针分别指向头和尾，然后交换，再++、--。 滑动窗口 /* 滑动窗口算法框架 */ void slidingWindow(string s, string t) { unordered_map need, window; for (char c : t) need[c]++; int left = 0, right = 0; int valid = 0; while (right Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section8/":{"url":"chapter21/section8/","title":"21.8 二分查找","keywords":"","body":"二分查找 int binary_search(int[] nums, int target) { int left = 0, right = nums.length - 1; while (left target) { right = mid - 1; } else if (nums[mid] == target) { // 别返回，锁定左侧边界 right = mid - 1; // 别返回，锁定右侧边界 //left = mid + 1; } } // 最后要检查 left 越界的情况 if (left >= nums.length || nums[left] != target) return -1; return left; // 最后要检查 right 越界的情况 //if (right Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section9/":{"url":"chapter21/section9/","title":"21.9 单调系列","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 单调栈 单调队列 单调系列 单调栈 单调栈实际上就是栈，只是利用了一些巧妙的逻辑，使得每次新元素入栈后，栈内的元素都保持有序（单调递增或单调递减）。 单调队列 就是一个「队列」，只是使用了一点巧妙的方法，使得队列中的元素全都是单调递增（或递减）的，使用这种结构解决某种特定算法。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section10/":{"url":"chapter21/section10/","title":"21.10 二叉堆","keywords":"","body":"二叉堆 使用数组实现，空出arr[0]，把 arr[1] 作为整棵树的根的话，每个节点的父节点和左右孩子的索引都可以通过简单的运算得到，这就是二叉堆设计的一个巧妙之处。 插入上浮，删除交换再下沉； 上浮不到顶，下沉不到底； 上浮比父母，下沉比双子； public class MaxPQ 1 && less(parent(k), k)) { //如果第k个元素比上层大 //将索引k中存储的元素换上去 each(parent(k), k); k = parent(k); } } /*下沉第k个元素，以维护最大堆性质*/ private void sink(int k) { //如果沉到堆底，就沉不下去了 while (left(k) Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter21/section11/":{"url":"chapter21/section11/","title":"21.11 子序列模板","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 模板1：一维dp（最长递增子序列） 模板2：二维dp（最长公共子序列、最长回文子序列） 子序列模板 模板1：一维dp（最长递增子序列） int n = array.length; int[] dp = new int[n]; for (int i = 1; i 模板2：二维dp（最长公共子序列、最长回文子序列） int n = arr.length; int[][] dp = new dp[n][n]; for (int i = 0; i Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter22/section1/":{"url":"chapter22/section1/","title":"22.1 理论","keywords":"","body":"理论 在分布式系统中，有很多复杂的理论，从CAP理论到BASE理论，我们不断的在可用性以及一致性之间做出抉择，每一部分都相当复杂，就分布式一致性而言，又有许多协议，从2PC到3PC再到paxos算法，到ZAB协议，再到Raft算法。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter22/section2/":{"url":"chapter22/section2/","title":"22.2 raft协议","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 复制状态机 协议的三个阶段 选主阶段 数据同步阶段 节点宕机 raft协议 复制状态机 复制状态机+一致性协议：解决了分布式系统中的高可用以及容错性，比如Zookeeper，HDFS等。 所谓复制状态机，就是说每一台服务器上维持着一份持久化Log，然后 通过一致性协议算法，保证每一个实例中的Log保持一致，并且顺序存放，这样客户端就可以在每一个实例中读取到相同的数据。 如上图所示，有一个Consensus Module就是一致性协议模块，它可以是Paxos算法的实现或者Raft算法。 重要概念 几个状态以及它的RPC调用，它主要有两个RPC通信，分别是 RequestVote RPC：负责选举 AppendEntries RPC：数据的交互。 这里需要着重理解Term，对于每一个leader，都会有一个Term，它会将这个term带到log日志中的entry中，代表当前entry是在哪一个term时期写入。 协议的三个阶段 选主阶段 日志复制阶段 安全状态 由上述图片例子开始描述各个阶段， 当前节点的term（时期）为4，state为leader（为主节点），commitIndex为0，总共有5个实例。 选主阶段 节点故障：主节点和其他子节点之间通过心跳机制保持联系，如果在一段时间内收不到心跳报告，则将该节点判为故障。 如果从节点故障，那么待故障恢复之后，就会去主节点同步日志进行故障恢复。 如果主节点故障，那么会重新进入选举阶段， 每一个实例会随机sleep一个timeout，timeout结束后，将当前的term加1，然后开始投票， 选举最大的serverid所在的那台机器, 如果自己接收到的投票小于自己的term，那么投反对票，即选举自己。 如果某台机器有超过半数以上的实例同意，那么将其选举为leader。 如果选举失败，则会将当前term再加1进行选举，直到选举成功。 之所以随机sleep一个time，是因为这样可以加快选举的流程，在一般情况下，只要网络状态良好，先timeout的实例先进行选举，这样只需要一轮选举就选举出leader，避免了由于相互选举而再次进入选举的情况。 数据同步阶段 选举完成之后， 客户端与leader交互写入数据entry，这时leader会在自己的log的第一个空位index中写入。 通过AppendEntries RPC把当前index的entry以及lastest commiteid（不是当前的commitId）发送给每一个follower从节点， 如果follower接收到的lastest commiteid等于当前实例的最新commitId，代表 如果超过半数的follower向leader返回true，那么代表当前entry写入成功。 返回false的实例，可能是因为网络原因或者故障恢复的原因，数据没有正确同步，此时leader会从最后一个entry开始向前遍历，知道找到故障实例对应的entry，然后开始恢复数据。 下图举例说明： leader的当前index=8，term为3，x=4，开始同步数据， 会收到第一个（包括自己），第三个和第五个实例的同意，大于半数的实例返回true，当前entry commit， 第二个和第四个实例将会返回false，此时leader会从最后一个entry开始从后向前遍历，将当前index发送给返回false的实例，直到它返回true开始同步数据。 比如刚开始leader发送index=8，term=3，x=4的数据给第二个实例，它将会返回false，接着发送前一个entry，也返回false，直到发送index=6，term=3，y=7的数据时返回true，开始正确同步数据，第四个实例也同理。 节点宕机 数据同步的时候节点发生宕机，如图所示： 对于a~f的实例，可能是因为某种故障而展现出的不同情况，它们都有可能成为leader。 以其中的（f）实例为例解释一下故障发生的原因，从而变成了从节点。 （f）实例之前可能在term=2时是leader节点，在写入数据的时候，它只写入了自己的log后就发生宕机， 在一个短暂的时间之后，它故障恢复，并且有再次被选举为leader，并且当前term=3，此时它写入数据，但是又在写入自己的log日志后但未发送给其他节点的时候发生故障宕机。 所以就造成了上述的现象，对于其他实例的故障也类似。 从上图可以看出，每一个实例都维护这一个最小committed index，代表着小于等于当前index的数据已经全部被commit，那么如果在收到leader的提交的index的时候会进行比较，此时会出现一个有意思的问题呢，之前提交的log日志可能被修改，或者更准确的说被覆盖。比如说(f)的term为1后面的term. Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter22/section3/":{"url":"chapter22/section3/","title":"22.3 分布式id","keywords":"","body":"分布式id 数据库的id主键采用分布式id算法：雪花算法slowflake https://blog.csdn.net/qq_39135287/article/details/88964572/ Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter22/section4/":{"url":"chapter22/section4/","title":"22.4 应用","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 nacos openFeign rocketMQ 启动rocketMQ 作用 副作用 模型选择 rocketMQ模型 rocketMQ架构 解决副作用 刷盘策略 存储机制 常见问题 应用 nacos openFeign rocketMQ 使用场景：https://www.cnblogs.com/leeego-123/p/10900256.html 资料: -ordinary-rocketmq: https://github.com/apache/rocketmq/blob/master/docs/cn/RocketMQ_Example.md【已实现】 -springboot-rocketmq: https://blog.csdn.net/zxl646801924/article/details/105659481 【已实现，还是使用的原生api】 -rocketmq-spring-boot-starter:【官网找的demo: rocketmq-spring-boot-samples，qgao项目参考的这个】 -springcloud-rocketmq: https://github.com/alibaba/spring-cloud-alibaba/blob/master/spring-cloud-alibaba-examples/rocketmq-example/readme-zh.md springcloud stream对rocketmq的相关配置属性：https://github.com/alibaba/spring-cloud-alibaba/wiki/RocketMQ-en 启动rocketMQ 开始下的4.9.0的服务端，结果启动mqnamesrv时报错找不到主类Files，解决不了问题，于是降低了版本，下了4.6.1的，成功启动。 在启动broker时又报找不到主类，这时将runbroker.cmd的classpath加上双引号就行了，但在之前的4.9是行不通的。 rocketmq服务端启动命令： mqnamesrv.cmd mqbroker.cmd -n localhost:9876 autoCreateTopicEnable=true 更改堆大小，默认是2g,2g,1g（我这个8g内存可受不了） rocketMQ的控制台：https://github.com/apache/rocketmq-externals 改一下端口 打包console: 打包完成后，找到target目录里的jar包，java –jar rocketmq-console-ng-2.0.0.jar 一个消费者同时订阅多个topic： https://blog.csdn.net/weixin\\_30844301/article/details/112814966 作用 异步：解决传统rpc同步调用带来的高延迟。 解耦：解决传统的方法内部调用多个方法的强耦合，改用生产者消费者模型，生产者只需要把消息发到特定的主题，自然有相应的消费者去获得该消息，进而改善业务方法内部的调用臃肿，也便于后期代码的维护。 削峰：类似于限流，即使有再多的qps，消费者通过恒定的速率从消息队列中取消息，降低了系统的压力，比如短信系统等不需要响应即时的系统。 副作用 系统可用性降低：mq挂了。 系统复杂度提高：保证高可用，集群。 重复消费：发送方以为发送失败了（其实并没有，网络波动或Broker意外重启等等导致响应接收失败），然后执行重试，这样就可能产生重复的消息，消费端则消费重复的消息，比如增加积分，带来麻烦。 顺序消费：严格要求消息的顺序执行，否则带来麻烦，如涉及到金额的操作。 分步式事务：不能这个系统我扣钱成功了你那积分系统积分没加吧。 消息堆积：削峰的场景在生产快，消费慢，也就意味着大量的消息堆积在队列中。 模型选择 主题模型解决队列模型产生的弊端（未完全解耦） 在队列模型中，生产者若将一个消息发送给多个消费者（广播），需要让 Producer 生产消息放入多个队列中，然后每个队列去对应每一个消费者。导致生产者需要知道具体消费者个数然后去复制对应数量的消息队列，这就违背我们消息中间件的 解耦 这一原则。 在主题模型中（发布订阅模型），存放消息的容器称为主题。 rocketMQ模型 生产者组，一般生产相同的消息。 消费者组，一般消费相同的消息。 主题中存在多个队列：提高并发。 集群消费模式下，一个队列只会被一个消费者组中的一个消费者消费。 消费者组中的消费者个数大于等于主题中队列个数：多的消费者是替补。 每个消费组在每个队列上维护一个消费位置：多个消费者组，那么消息被一个消费者组消费完之后是不会删除的(因为其它消费者组也需要呀)。 rocketMQ架构 Broker就是存储消息的服务器硬件。topic集群分布在多台消息服务器上，而一台服务器当然应该有多个不同类型的topic. 一个 Topic 分布在多个 Broker上，一个 Broker 可以配置多个 Topic ，它们是多对多的关系。 如果某个 Topic 消息量很大，应该给它多配置几个队列(上文中提到了提高并发能力)，并且 尽量多分布在不同 Broker 上，以减轻某个 Broker 的压力 。 NameServer:保证高可用，必然是要集群broker以达到负载均衡的目的，为避免producer(生产者)或consumer(消费者)与众多broker直连导致有可能修改某些broker或宕机时出现的耦合问题，需要用nameServer来管理这些broker，然后接管生产者或消费者到broker的路由方式。 总结： broker：集群，主从搭建，主挂了，从提供消费，但不支持写入。 nameServer：集群，去中心化搭建，单个broker长连接所有nameServer，30秒一次路由信息心跳。 producer：通过nameServer轮询获得某个broker，然后再轮询当前的topic中的不同队列。 consumer：同上，pull broker中的消息， 一个队列只会被一个消费者组中的一个消费者消费。 一个队列中的消息会被一个消费者组中的所有消费者重复消费。 解决副作用 rocketMQ的架构解决了高可用性 以上是普通顺序模式，为了让以上三条消息严格按顺序消费，可以在业务内使用Hash取模法，来保证同一个订单在同一个队列中就行了。 重复消费 消费者处理业务成功，但响应给队列失败（网络波动或Broker意外重启等等导致响应接收失败） 【幂等】：任意多次执行所产生的影响均与一次执行的影响相同。 对消费者实现幂等，也就是对同一个消息的处理结果，执行多少次都不变。 结合具体的业务，在真正的业务代码前： ①写入 Redis 来保证，因为 Redis 的 key 和 value 就是天然支持幂等的。 ②使用 数据库插入法 ，基于数据库的唯一键来保证重复数据不会被插入多条。 分布式事务（本地事务和存储消息到消息队列才是同一个事务。这样也就产生了事务的最终一致性） 事务消息+事务反查机制 事务反查机制：如果消息是half消息（事务消息），复制原消息的主题与消息消费队列，然后 改变主题 为RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费half类型的消息（对消费者不可见），然后RocketMQ会开启一个定时任务（上图第5步），从Topic为RMQ_SYS_TRANS_HALF_TOPIC中拉取消息进行消费，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。 消息堆积 生产者太快：限流、降级 消费者太慢：水平扩展，增加消费者，提高消费能力（别忘记增加topic的队列） 回溯消费 某种特定业务情况下，需要消费已经重复消费过的消息，而被消费过的消息并未被删除，因此可以通过向前移动指针做到回溯消费。例如由于 Consumer 系统故障，恢复后需要重新消费1小时前的数据，有幂等的情况下不怕存在错误消费的情况。 刷盘策略 同步刷盘和异步刷盘是在单个结点层面的（保证可靠性）。 异步刷盘采用后台异步线程提交的方式进行，只有在 Broker 意外宕机的时候会丢失部分数据，可以设置 Broker 的参数 FlushDiskType 来调整刷盘策略(ASYNC_FLUSH 或者 SYNC_FLUSH)。 -------------------------------- 同步复制和异步复制主要是指的 Borker 主从模式下，主节点返回响应给生产者（消息发布者）的时候是否需要同步从节点。（保证可用性） 同步复制： 也叫 “同步双写”，也就是说，只有消息同步双写到主从结点上时才返回写入成功 。 异步复制： 消息写入主节点之后就直接返回写入成功 。 异步复制时，在主节点broker挂掉之后，消费者可以自动切换到从节点进行消费，但生产者不能给从节点生产消息，只有等主节点重启之后，生产者才给主结点继续生产消息， 而在主结点挂掉期间，主节点和从结点会出现短暂的消息不一致的情况，而消费者会消费从节点的消息，降低了可用性，但主结点恢复后，从节点那部分未来得及复制的消息还会继续复制。 -------------------------------- 在单主从架构中，如果一个主节点挂掉了，那么也就意味着整个系统不能再生产了。 那就多主从架构，当前用的一个主结点挂掉，就切换另外的可用主结点提供写入功能。但这不能保证消息的严格顺序，因为挂掉的主结点中的队列必然和切换后的主结点的队列不同。 rocketMQ采用了Dledger多主从架构，要求写入消息的时候，至少消息复制到半数以上的其它主节点之后，才给客户端返回写⼊成功，并且它是⽀持通过选举来动态切换主节点的。在 Dledger 选举过程中是无法提供服务的，而且他必须要使用三个节点或以上，如果多数节点同时挂掉他也是无法保证可用性的， 要求消息复制半数以上主节点的效率，和直接异步复制还是有一定的差距的。 存储机制 commitLog：broker刷盘时存储的消息主体以及元数据的存储主体，消息主要是顺序写入日志文件，当文件满了，写入下一个文件。 ConsumeQueue：基于 topic 的 commitlog 索引文件，提高消息消费的性能（Consumer 即可根据 ConsumeQueue 来查找待消费的消息），具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。每个 ConsumeQueue文件大小约5.72M，由30W个条目组成，可以像数组一样随机访问每一个条目，每一个条目采取定长设计共20个字节，分别为8字节的 commitlog 物理偏移量、4字节的消息长度、8字节tag hashcode。 IndexFile：提供了一种可以通过key或时间区间来查询到commitLog中消息的方法。（了解即可） 消息是如何存储以及被消费到的： 生产者发送到broker的消息会指定 Topic 、QueueId 和具体消息内容， Broker全部顺序存储到了 CommitLog。根据生产者指定的 Topic 和 QueueId 将这条消息本身在 CommitLog 的偏移(offset)，消息本身大小，和tag的hash值存入到该队列对应的 ConsumeQueue 索引文件中。 每个队列中都保存了 ConsumeOffset 即每个消费者组的消费位置（存储的是消费到consumeQueue第几个条目了，只要使用它乘以条目固定长度20字节，就可以获得在consumeQueue中的位置，然后获得下一个20个字节的条目，根据它找到在commitLog中的真正需要被消费的消息内容）。 常见问题 防止消息丢失，每发送一个消息，同步落盘后才返回生产者消息发送成功。 FileChannel + DirectBuffer 池，使用堆外内存，加快内存拷贝，快速刷盘。 消息堆积时，消息定时转移或采用某种丢弃策略，或者对某些重要的 TAG 型（支付型）消息真正落库（添加到数据库）。 定时消息的原理是：创建特定时间精度的 MessageQueue，例如生产者需要定时1s之后被消费者消费，你只需要将此消息发送到特定的 Topic，例如：MessageQueue-1 表示这个 MessageQueue 里面的消息都会延迟一秒被消费，然后 Broker 会在 1s 后发送到消费者消费此消息，使用 newSingleThreadScheduledExecutor 实现。 顺序消费的前提是：消费者内部是串行的依次消费该 MessageQueue，引入锁来实现串行，前一个消费阻塞时后面都会被阻塞。 分布式事务消息原理： 生产者发送事务消息，假设该事务消息 Topic 为 Topic1-Trans， Broker 得到后首先更改该消息的 Topic 为 Topic1-Prepared，该 Topic1-Prepared 对消费者不可见。 然后定时回调生产者的本地事务A执行状态，根据本地事务A执行状态，来是否将该消息修改为 Topic1-Commit 或 Topic1-Rollback，消费者就可以正常找到该事务消息或者不执行等。 【最后回滚了，事务消息也不会物理删除，只会逻辑删除该消息】 push基于pull模式实现，Broker 定时任务每5s将消息推送到消费者，consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送过来的。 NameServer 集群间互不通信，它们之间的注册信息可能会不一致。 消息过滤器（Producer 发送消息到 Broker，Broker 存储消息信息，Consumer 消费时请求 Broker 端从磁盘文件查询消息文件时,在 Broker 端就使用过滤服务器进行过滤）。 组件通信间使用 Netty 的自定义协议。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "},"chapter23/section1/":{"url":"chapter23/section1/","title":"23.0 基础","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 大数据概念 1.1 数据存储单位 2 大数据5v特征 3 大数据业务分析基本步骤 基础 1 大数据概念 数据: 事实或观察的结果 对客观事物的逻辑归纳 用于表示客观事物的未经加工的原始素材 数据的产生: 对客观事物的计量和记录产生数据 1.1 数据存储单位 大单位 小单位 1 Byte 8 bit 1 KB 1024 Byte 1 MB 1024 KB 1 GB 1024 MB 1 T(太) 1024 G 1 P(拍) 1024 T 1 E(艾) 1024 P 1 Z(泽) 1024 E 1 Y(尧) 1024 Z 1 B(布) 1024 Y 1 N(诺) 1024 B 1 D(刀) 1024 N 2 大数据5v特征 Volume 数据体量大 采集数据量大 存储数据量大 计算数据量大 TB,PB级别起步 Varity 种类,来源多样化 种类: 结构化(mysql的表),半结构化(json数据),非结构化(完全无规则) 来源: 日志文本,图片,音频,视频 Value 价值密度低 信息海量但是价值密度低 深度复杂的挖掘分析需要机器学习参与 Velocity 速度快 数据增长速度快 获取数据速度快 数据处理速度快 Veracity 数据质量 数据准确性 数据可信赖度 3 大数据业务分析基本步骤 明确分析目的和思路 数据收集 数据预处理: 变成结构化数据 数据分析 数据应用: 使用图形或表格进行展示 报告撰写: 总结 加重的3项才是技术领域需要关注的点. Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-06-06 16:56:43 "}}